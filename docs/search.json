[
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": null,
        "dir": "",
        "previous_headings": "",
        "what": "CLAUDE.md",
        "title": "CLAUDE.md",
        "text": "file provides guidance Claude Code (claude.ai/code) working code repository.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "r-package-development",
        "dir": "",
        "previous_headings": "Development Commands",
        "what": "R Package Development",
        "title": "CLAUDE.md",
        "text": "",
        "code": "# Standard development workflow devtools::load_all()        # Load package for testing devtools::document()        # Update documentation and NAMESPACE devtools::test()           # Run all tests devtools::check()          # Comprehensive package check devtools::build()          # Build package tarball devtools::install()        # Install package locally  # Single test execution testthat::test_file(\"tests/testthat/test-decision.R\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "documentation-and-website",
        "dir": "",
        "previous_headings": "Development Commands",
        "what": "Documentation and Website",
        "title": "CLAUDE.md",
        "text": "",
        "code": "# Generate documentation site pkgdown::build_site() pkgdown::build_site_github_pages()  # Manual pages only devtools::document()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "jamovi-module-development",
        "dir": "",
        "previous_headings": "Development Commands",
        "what": "jamovi Module Development",
        "title": "CLAUDE.md",
        "text": "jamovi module files jamovi/ directory define UI analysis structure Module version must match package version DESCRIPTION jamovi/0000.yaml JavaScript files jamovi/js/ handle dynamic UI behavior Module builds .jmo format jamovi installation",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "dual-purpose-package-structure",
        "dir": "",
        "previous_headings": "Architecture Overview",
        "what": "Dual-Purpose Package Structure",
        "title": "CLAUDE.md",
        "text": "R package jamovi module: - R Package: Standard R functions R/ directory - jamovi Module: UI definitions jamovi/*.yaml files - Shared Code: R functions serve interfaces",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "core-components",
        "dir": "",
        "previous_headings": "Architecture Overview",
        "what": "Core Components",
        "title": "CLAUDE.md",
        "text": "Medical Decision Analysis: Functions sensitivity, specificity, PPV, NPV calculations ROC Analysis: ROC curves, AUC, optimal cutpoint determination Reliability Assessment: Cohen’s Kappa, Fleiss’ Kappa, interrater agreement Sample Size Calculations: Power analysis confidence interval approaches Visualization: Fagan nomograms, ROC plots using ggplot2",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "file-organization-pattern",
        "dir": "",
        "previous_headings": "Architecture Overview",
        "what": "File Organization Pattern",
        "title": "CLAUDE.md",
        "text": "Functions follow consistent naming: - *.b.R: Backend computation functions (called jamovi) - *.h.R: Helper/utility functions - jamovi/*..yaml: Analysis definitions (analysis ) - jamovi/*.r.yaml: Results definitions (output structure) - jamovi/*.u.yaml: UI definitions (input controls)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "key-dependencies",
        "dir": "",
        "previous_headings": "Architecture Overview",
        "what": "Key Dependencies",
        "title": "CLAUDE.md",
        "text": "jmvcore: jamovi integration framework pROC, cutpointr: ROC analysis irr, epiR: Statistical analysis ggplot2: Visualization R6: Object-oriented class system",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "development-workflow",
        "dir": "",
        "previous_headings": "",
        "what": "Development Workflow",
        "title": "CLAUDE.md",
        "text": "Code Changes: Modify functions R/ directory Documentation: Use roxygen2 comments, run devtools::document() Testing: Add tests tests/testthat/, run devtools::test() jamovi Updates: Modify .yaml files jamovi/ UI changes Version Sync: Update version DESCRIPTION jamovi/0000.yaml Pre-commit: Always run devtools::check() committing",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "data-and-examples",
        "dir": "",
        "previous_headings": "",
        "what": "Data and Examples",
        "title": "CLAUDE.md",
        "text": "Example datasets inst/extdata/: - decision_example.csv: Basic medical decision analysis - roc_example.csv: ROC curve analysis - agreement_example.csv: Interrater reliability Access via: system.file(\"extdata\", \"filename.csv\", package = \"meddecide\")",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/CLAUDE.html",
        "id": "cicd-pipeline",
        "dir": "",
        "previous_headings": "",
        "what": "CI/CD Pipeline",
        "title": "CLAUDE.md",
        "text": "GitHub Actions automatically: - Runs R CMD check multiple platforms - Deploys pkgdown documentation GitHub Pages - Skips builds “WIP” commits - Website deploys : https://www.serdarbalci.com/meddecide/",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/LICENSE.html",
        "id": null,
        "dir": "",
        "previous_headings": "",
        "what": "GNU General Public License",
        "title": "GNU General Public License",
        "text": "Version 2, June 1991Copyright © 1989, 1991 Free Software Foundation, Inc.,51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone permitted copy distribute verbatim copies license document, changing allowed.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/LICENSE.html",
        "id": "preamble",
        "dir": "",
        "previous_headings": "",
        "what": "Preamble",
        "title": "GNU General Public License",
        "text": "licenses software designed take away freedom share change . contrast, GNU General Public License intended guarantee freedom share change free software–make sure software free users. General Public License applies Free Software Foundation’s software program whose authors commit using . (Free Software Foundation software covered GNU Lesser General Public License instead.) can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge service wish), receive source code can get want , can change software use pieces new free programs; know can things. protect rights, need make restrictions forbid anyone deny rights ask surrender rights. restrictions translate certain responsibilities distribute copies software, modify . example, distribute copies program, whether gratis fee, must give recipients rights . must make sure , , receive can get source code. must show terms know rights. protect rights two steps: (1) copyright software, (2) offer license gives legal permission copy, distribute /modify software. Also, author’s protection , want make certain everyone understands warranty free software. software modified someone else passed , want recipients know original, problems introduced others reflect original authors’ reputations. Finally, free program threatened constantly software patents. wish avoid danger redistributors free program individually obtain patent licenses, effect making program proprietary. prevent , made clear patent must licensed everyone’s free use licensed . precise terms conditions copying, distribution modification follow.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/LICENSE.html",
        "id": "terms-and-conditions-for-copying-distribution-and-modification",
        "dir": "",
        "previous_headings": "",
        "what": "TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION",
        "title": "GNU General Public License",
        "text": "0. License applies program work contains notice placed copyright holder saying may distributed terms General Public License. “Program”, , refers program work, “work based Program” means either Program derivative work copyright law: say, work containing Program portion , either verbatim modifications /translated another language. (Hereinafter, translation included without limitation term “modification”.) licensee addressed “”. Activities copying, distribution modification covered License; outside scope. act running Program restricted, output Program covered contents constitute work based Program (independent made running Program). Whether true depends Program . 1. may copy distribute verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice disclaimer warranty; keep intact notices refer License absence warranty; give recipients Program copy License along Program. may charge fee physical act transferring copy, may option offer warranty protection exchange fee. 2. may modify copy copies Program portion , thus forming work based Program, copy distribute modifications work terms Section 1 , provided also meet conditions: ) must cause modified files carry prominent notices stating changed files date change. b) must cause work distribute publish, whole part contains derived Program part thereof, licensed whole charge third parties terms License. c) modified program normally reads commands interactively run, must cause , started running interactive use ordinary way, print display announcement including appropriate copyright notice notice warranty (else, saying provide warranty) users may redistribute program conditions, telling user view copy License. (Exception: Program interactive normally print announcement, work based Program required print announcement.) requirements apply modified work whole. identifiable sections work derived Program, can reasonably considered independent separate works , License, terms, apply sections distribute separate works. distribute sections part whole work based Program, distribution whole must terms License, whose permissions licensees extend entire whole, thus every part regardless wrote . Thus, intent section claim rights contest rights work written entirely ; rather, intent exercise right control distribution derivative collective works based Program. addition, mere aggregation another work based Program Program (work based Program) volume storage distribution medium bring work scope License. 3. may copy distribute Program (work based , Section 2) object code executable form terms Sections 1 2 provided also one following: ) Accompany complete corresponding machine-readable source code, must distributed terms Sections 1 2 medium customarily used software interchange; , b) Accompany written offer, valid least three years, give third party, charge cost physically performing source distribution, complete machine-readable copy corresponding source code, distributed terms Sections 1 2 medium customarily used software interchange; , c) Accompany information received offer distribute corresponding source code. (alternative allowed noncommercial distribution received program object code executable form offer, accord Subsection b .) source code work means preferred form work making modifications . executable work, complete source code means source code modules contains, plus associated interface definition files, plus scripts used control compilation installation executable. However, special exception, source code distributed need include anything normally distributed (either source binary form) major components (compiler, kernel, ) operating system executable runs, unless component accompanies executable. distribution executable object code made offering access copy designated place, offering equivalent access copy source code place counts distribution source code, even though third parties compelled copy source along object code. 4. may copy, modify, sublicense, distribute Program except expressly provided License. attempt otherwise copy, modify, sublicense distribute Program void, automatically terminate rights License. However, parties received copies, rights, License licenses terminated long parties remain full compliance. 5. required accept License, since signed . However, nothing else grants permission modify distribute Program derivative works. actions prohibited law accept License. Therefore, modifying distributing Program (work based Program), indicate acceptance License , terms conditions copying, distributing modifying Program works based . 6. time redistribute Program (work based Program), recipient automatically receives license original licensor copy, distribute modify Program subject terms conditions. may impose restrictions recipients’ exercise rights granted herein. responsible enforcing compliance third parties License. 7. , consequence court judgment allegation patent infringement reason (limited patent issues), conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. distribute satisfy simultaneously obligations License pertinent obligations, consequence may distribute Program . example, patent license permit royalty-free redistribution Program receive copies directly indirectly , way satisfy License refrain entirely distribution Program. portion section held invalid unenforceable particular circumstance, balance section intended apply section whole intended apply circumstances. purpose section induce infringe patents property right claims contest validity claims; section sole purpose protecting integrity free software distribution system, implemented public license practices. Many people made generous contributions wide range software distributed system reliance consistent application system; author/donor decide willing distribute software system licensee impose choice. section intended make thoroughly clear believed consequence rest License. 8. distribution /use Program restricted certain countries either patents copyrighted interfaces, original copyright holder places Program License may add explicit geographical distribution limitation excluding countries, distribution permitted among countries thus excluded. case, License incorporates limitation written body License. 9. Free Software Foundation may publish revised /new versions General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies version number License applies “later version”, option following terms conditions either version later version published Free Software Foundation. Program specify version number License, may choose version ever published Free Software Foundation. 10. wish incorporate parts Program free programs whose distribution conditions different, write author ask permission. software copyrighted Free Software Foundation, write Free Software Foundation; sometimes make exceptions . decision guided two goals preserving free status derivatives free software promoting sharing reuse software generally.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/LICENSE.html",
        "id": "no-warranty",
        "dir": "",
        "previous_headings": "",
        "what": "NO WARRANTY",
        "title": "GNU General Public License",
        "text": "11. PROGRAM LICENSED FREE CHARGE, WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION. 12. EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MAY MODIFY /REDISTRIBUTE PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES. END TERMS CONDITIONS",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/LICENSE.html",
        "id": "how-to-apply-these-terms-to-your-new-programs",
        "dir": "",
        "previous_headings": "",
        "what": "How to Apply These Terms to Your New Programs",
        "title": "GNU General Public License",
        "text": "develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively convey exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program interactive, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, commands use may called something show w show c; even mouse-clicks menu items–whatever suits program. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. sample; alter names: General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License.",
        "code": "<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.  <signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide module provides comprehensive tools medical decision analysis, enabling healthcare professionals make evidence-based clinical decisions systematic evaluation diagnostic tests, treatment options, health economic outcomes. module combines traditional decision tree analysis advanced Markov modeling complex medical scenarios. Learning Objectives: Understand fundamentals medical decision analysis Learn diagnostic test evaluation ROC analysis Master decision tree construction interpretation Apply Markov modeling chronic disease scenarios Conduct cost-effectiveness analysis healthcare interventions Implement precision medicine decision frameworks",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "module-overview",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Module Overview",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide encompasses four main areas medical decision analysis:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "diagnostic-test-evaluation",
        "dir": "Articles",
        "previous_headings": "Introduction > Module Overview",
        "what": "1. Diagnostic Test Evaluation",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "ROC Analysis: Receiver operating characteristic curves AUC calculation Diagnostic Accuracy: Sensitivity, specificity, predictive values Test Performance: Likelihood ratios clinical utility measures Biomarker Validation: Companion diagnostic development",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "decision-tree-analysis",
        "dir": "Articles",
        "previous_headings": "Introduction > Module Overview",
        "what": "2. Decision Tree Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Simple Decision Trees: Binary choice scenarios immediate outcomes Complex Decision Trees: Multi-branch decisions sequential outcomes Cost-Effectiveness Trees: Economic evaluation integrated clinical outcomes Sensitivity Analysis: Parameter uncertainty assessment",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "markov-modeling",
        "dir": "Articles",
        "previous_headings": "Introduction > Module Overview",
        "what": "3. Markov Modeling",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "State Transition Models: Chronic disease progression modeling Markov Chains: Time-dependent health state transitions Cohort Simulation: Population-level outcome prediction Economic Evaluation: Long-term cost-effectiveness analysis",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "precision-medicine-decisions",
        "dir": "Articles",
        "previous_headings": "Introduction > Module Overview",
        "what": "4. Precision Medicine Decisions",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Biomarker-Guided Therapy: Treatment selection algorithms Companion Diagnostics: Test-treatment combinations Pharmacoeconomics: Personalized medicine cost-effectiveness Real-World Evidence: Population-based decision modeling",
        "code": "library(meddecide) library(dplyr) library(pROC)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "installation-and-setup",
        "dir": "Articles",
        "previous_headings": "Getting Started",
        "what": "Installation and Setup",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide part comprehensive ClinicoPath suite provides specialized tools medical decision analysis.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "in-jamovi",
        "dir": "Articles",
        "previous_headings": "Getting Started > Installation and Setup",
        "what": "In jamovi:",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Install ClinicoPath module jamovi library Navigate meddecide analysis menu Choose : Agreement, Decision, ROC, Power Analysis",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "in-r",
        "dir": "Articles",
        "previous_headings": "Getting Started > Installation and Setup",
        "what": "In R:",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "",
        "code": "# Install from GitHub if (!requireNamespace(\"devtools\", quietly = TRUE)) {   install.packages(\"devtools\") } devtools::install_github(\"sbalci/meddecide\")  # Load the package library(meddecide)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "sample-datasets",
        "dir": "Articles",
        "previous_headings": "Getting Started",
        "what": "Sample Datasets",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide includes comprehensive datasets decision analysis training:",
        "code": "# Load decision analysis datasets data(basic_decision_data) data(markov_decision_data)  data(precision_oncology_data)  # Decision tree data overview cat(\"Basic decision data dimensions:\", nrow(basic_decision_data), \"×\", ncol(basic_decision_data), \"\\n\") cat(\"Key variables:\", paste(names(basic_decision_data)[1:8], collapse = \", \"), \"...\\n\")  # Markov model data overview cat(\"Markov decision data dimensions:\", nrow(markov_decision_data), \"×\", ncol(markov_decision_data), \"\\n\") cat(\"Key variables:\", paste(names(markov_decision_data)[1:8], collapse = \", \"), \"...\\n\")  # Precision oncology data overview cat(\"Precision oncology data dimensions:\", nrow(precision_oncology_data), \"×\", ncol(precision_oncology_data), \"\\n\") molecular_vars <- names(precision_oncology_data)[grepl(\"Mutation|Status|TPS\", names(precision_oncology_data))] cat(\"Biomarker variables:\", paste(molecular_vars[1:5], collapse = \", \"), \"...\\n\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "roc-analysis-and-diagnostic-test-evaluation",
        "dir": "Articles",
        "previous_headings": "Core Analysis Workflows",
        "what": "1. ROC Analysis and Diagnostic Test Evaluation",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Foundation biomarker validation diagnostic test assessment.",
        "code": "# ROC Analysis Example # In jamovi: meddecide > ROC > ROC Analysis  # Using precision oncology data for biomarker evaluation data(precision_oncology_data)  # Create binary outcome for treatment response response_binary <- as.numeric(precision_oncology_data$Treatment_Response %in%                               c(\"Complete_Response\", \"Partial_Response\"))  cat(\"ROC Analysis Example - PD-L1 TPS for Treatment Response\\n\") cat(\"=====================================================\\n\\n\")  # Basic ROC statistics if(requireNamespace(\"pROC\", quietly = TRUE)) {   library(pROC)      # ROC analysis for PD-L1 TPS   roc_pdl1 <- roc(response_binary, precision_oncology_data$PD_L1_TPS, quiet = TRUE)      cat(\"PD-L1 TPS ROC Results:\\n\")   cat(\"AUC:\", round(auc(roc_pdl1), 3), \"\\n\")   cat(\"95% CI:\", paste(round(ci.auc(roc_pdl1), 3), collapse = \" - \"), \"\\n\")      # Optimal cutpoint   optimal_cutpoint <- coords(roc_pdl1, \"best\", ret = \"threshold\")   cat(\"Optimal cutpoint:\", round(optimal_cutpoint, 1), \"%\\n\")      # Clinical cutpoints evaluation   cutpoints <- c(1, 10, 20, 50)   cat(\"\\nPerformance at Clinical Cutpoints:\\n\")      for(cutpoint in cutpoints) {     sens <- coords(roc_pdl1, cutpoint, ret = \"sensitivity\")     spec <- coords(roc_pdl1, cutpoint, ret = \"specificity\")     cat(paste0(\"PD-L1 ≥\", cutpoint, \"%: Sensitivity = \", round(sens, 3),                \", Specificity = \", round(spec, 3), \"\\n\"))   } }  # Diagnostic test characteristics n_positive <- sum(precision_oncology_data$PD_L1_TPS >= 50) n_total <- nrow(precision_oncology_data) prevalence <- round(n_positive / n_total * 100, 1)  cat(\"\\nDiagnostic Test Characteristics:\\n\") cat(\"PD-L1 ≥50% prevalence:\", prevalence, \"%\\n\") cat(\"Sample size:\", n_total, \"patients\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "simple-decision-tree-analysis",
        "dir": "Articles",
        "previous_headings": "Core Analysis Workflows",
        "what": "2. Simple Decision Tree Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Evaluate treatment alternatives immediate outcomes.",
        "code": "# Decision Tree Analysis Example # In jamovi: meddecide > Decision > Decision Tree Graph  # Using basic decision data data(basic_decision_data)  cat(\"Decision Tree Analysis Example - Surgery vs Medical Treatment\\n\") cat(\"===========================================================\\n\\n\")  # Decision analysis summary decision_summary <- basic_decision_data %>%   group_by(treatment) %>%   summarise(     n = n(),     mean_prob_success = round(mean(prob_success_surgery + prob_success_medical)/2, 3),     mean_cost = round(mean(cost_surgery + cost_medical)/2, 0),     mean_utility_success = round(mean(utility_success), 3),     clinical_response_rate = round(mean(clinical_outcome == \"Complete_Response\") * 100, 1),     .groups = 'drop'   )  cat(\"Decision Alternatives:\\n\") print(decision_summary)  # Expected value calculation example surgery_cases <- basic_decision_data[basic_decision_data$treatment == \"Surgery\", ] medical_cases <- basic_decision_data[basic_decision_data$treatment == \"Medical Treatment\", ]  if(nrow(surgery_cases) > 0 && nrow(medical_cases) > 0) {   # Surgery expected values   surgery_ev_cost <- mean(surgery_cases$cost_surgery * surgery_cases$prob_success_surgery +                           surgery_cases$cost_complications * surgery_cases$prob_complications)      surgery_ev_utility <- mean(surgery_cases$utility_success * surgery_cases$prob_success_surgery +                              surgery_cases$utility_failure * (1 - surgery_cases$prob_success_surgery))      # Medical treatment expected values     medical_ev_cost <- mean(medical_cases$cost_medical * medical_cases$prob_success_medical)      medical_ev_utility <- mean(medical_cases$utility_success * medical_cases$prob_success_medical +                              medical_cases$utility_failure * (1 - medical_cases$prob_success_medical))      cat(\"\\nExpected Value Analysis:\\n\")   cat(\"Surgery - Expected Cost: $\", round(surgery_ev_cost, 0),        \", Expected Utility: \", round(surgery_ev_utility, 3), \"\\n\")   cat(\"Medical - Expected Cost: $\", round(medical_ev_cost, 0),        \", Expected Utility: \", round(medical_ev_utility, 3), \"\\n\")      # Cost-effectiveness ratio   if(medical_ev_utility != surgery_ev_utility) {     icer <- (surgery_ev_cost - medical_ev_cost) / (surgery_ev_utility - medical_ev_utility)     cat(\"Incremental Cost-Effectiveness Ratio: $\", round(abs(icer), 0), \" per utility unit\\n\")   } }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "markov-model-analysis",
        "dir": "Articles",
        "previous_headings": "Core Analysis Workflows",
        "what": "3. Markov Model Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Long-term disease progression modeling chronic conditions.",
        "code": "# Markov Model Analysis Example # In jamovi: meddecide > Decision > Decision Tree Graph (Markov Model Tree)  # Using markov decision data data(markov_decision_data)  cat(\"Markov Model Analysis Example - Chronic Disease Management\\n\") cat(\"=========================================================\\n\\n\")  # Treatment strategy comparison strategy_summary <- markov_decision_data %>%   group_by(treatment_strategy) %>%   summarise(     n_states = n(),     mean_healthy_to_sick = round(mean(prob_healthy_to_sick), 4),     mean_sick_to_recovered = round(mean(prob_sick_to_recovered), 4),     annual_cost_healthy = round(mean(cost_healthy_state), 0),     annual_cost_sick = round(mean(cost_sick_state), 0),     annual_utility_healthy = round(mean(utility_healthy), 3),     annual_utility_sick = round(mean(utility_sick), 3),     .groups = 'drop'   )  cat(\"Treatment Strategy Comparison:\\n\") print(strategy_summary)  # Transition probability validation cat(\"\\nTransition Probability Validation:\\n\") sample_state <- markov_decision_data[1, ] prob_sum <- sample_state$prob_healthy_to_sick + (1 - sample_state$prob_healthy_to_sick) cat(\"Probability sum check (should = 1.0):\", prob_sum, \"\\n\")  # Long-term outcome simulation (simplified) time_horizon <- 10  # years initial_cohort <- 1000  cat(\"\\nSimulated 10-Year Outcomes (per 1000 patients):\\n\") for(strategy in unique(markov_decision_data$treatment_strategy)) {   strategy_data <- markov_decision_data[markov_decision_data$treatment_strategy == strategy, ][1, ]      # Simplified simulation   annual_transition_rate <- strategy_data$prob_healthy_to_sick   annual_recovery_rate <- strategy_data$prob_sick_to_recovered      # Estimate patients progressing over time horizon   patients_progressing <- round(initial_cohort * annual_transition_rate * time_horizon)      # Estimate total costs   total_cost <- strategy_data$cost_healthy_state * time_horizon +                  patients_progressing * strategy_data$cost_sick_state      cat(paste0(strategy, \": \", patients_progressing, \" progressions, $\",              round(total_cost, 0), \" total cost\\n\")) }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "precision-medicine-decision-analysis",
        "dir": "Articles",
        "previous_headings": "Core Analysis Workflows",
        "what": "4. Precision Medicine Decision Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Biomarker-guided treatment selection cost-effectiveness evaluation.",
        "code": "# Precision Medicine Decision Analysis # Combining diagnostic testing with treatment selection  data(precision_oncology_data)  cat(\"Precision Medicine Decision Analysis\\n\") cat(\"===================================\\n\\n\")  # Biomarker testing strategy evaluation biomarker_strategy <- precision_oncology_data %>%   mutate(     # Define testing strategy     test_egfr = TRUE,  # Universal EGFR testing     test_pdl1 = TRUE,  # Universal PD-L1 testing          # Treatment assignment based on biomarkers     recommended_treatment = case_when(       EGFR_Mutation == \"Positive\" ~ \"EGFR_TKI\",       PD_L1_TPS >= 50 ~ \"Anti_PD1_Mono\",       PD_L1_TPS >= 1 ~ \"Combo_Immuno\",       TRUE ~ \"Chemotherapy\"     ),          # Estimate treatment costs     treatment_cost = case_when(       recommended_treatment == \"EGFR_TKI\" ~ 120000,       recommended_treatment == \"Anti_PD1_Mono\" ~ 150000,       recommended_treatment == \"Combo_Immuno\" ~ 200000,       TRUE ~ 80000     ),          # Testing costs     testing_cost = 3000,  # Comprehensive biomarker panel          # Total cost     total_cost = treatment_cost + testing_cost   )  # Strategy outcomes strategy_outcomes <- biomarker_strategy %>%   group_by(recommended_treatment) %>%   summarise(     n_patients = n(),     percentage = round(n() / nrow(biomarker_strategy) * 100, 1),     response_rate = round(mean(Treatment_Response %in% c(\"Complete_Response\", \"Partial_Response\")) * 100, 1),     median_pfs = median(PFS_Months),     mean_cost = round(mean(total_cost), 0),     .groups = 'drop'   )  cat(\"Biomarker-Guided Treatment Strategy Outcomes:\\n\") print(strategy_outcomes)  # Cost-effectiveness summary total_responses <- sum(biomarker_strategy$Treatment_Response %in% c(\"Complete_Response\", \"Partial_Response\")) total_cost <- sum(biomarker_strategy$total_cost) cost_per_response <- round(total_cost / total_responses, 0)  cat(\"\\nOverall Strategy Performance:\\n\") cat(\"Total patients:\", nrow(biomarker_strategy), \"\\n\") cat(\"Total responses:\", total_responses, \"\\n\") cat(\"Response rate:\", round(total_responses / nrow(biomarker_strategy) * 100, 1), \"%\\n\") cat(\"Cost per response: $\", cost_per_response, \"\\n\")  # Compare with standard care (no biomarker testing) standard_care_response_rate <- 25  # Assumed standard chemotherapy response rate standard_care_cost <- 80000  # Standard chemotherapy cost cost_per_response_standard <- round(standard_care_cost / (standard_care_response_rate/100), 0)  cat(\"\\nComparison with Standard Care:\\n\") cat(\"Standard care cost per response: $\", cost_per_response_standard, \"\\n\") cat(\"Biomarker strategy cost per response: $\", cost_per_response, \"\\n\")  if(cost_per_response < cost_per_response_standard) {   cat(\"Biomarker strategy is more cost-effective\\n\") } else {   cat(\"Standard care is more cost-effective\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "agreement-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Agreement Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Evaluate diagnostic test reliability inter-observer agreement.",
        "code": "cat(\"Agreement Analysis Applications\\n\") cat(\"==============================\\n\\n\")  # Load biomarker validation data for agreement analysis data(biomarker_validation_study)  # Multi-platform agreement platform_agreement <- biomarker_validation_study %>%   summarise(     n_cases = n(),     correlation = round(cor(Platform_A_PD_L1, Platform_B_PD_L1), 3),     mean_difference = round(mean(Platform_B_PD_L1 - Platform_A_PD_L1), 2),     agreement_within_10pct = round(mean(abs(Platform_B_PD_L1 - Platform_A_PD_L1) <= 10) * 100, 1),     overall_agreement = round(mean(Platform_Agreement) * 100, 1)   )  cat(\"Multi-Platform Biomarker Agreement:\\n\") cat(\"Cases analyzed:\", platform_agreement$n_cases, \"\\n\") cat(\"Correlation:\", platform_agreement$correlation, \"\\n\") cat(\"Mean difference:\", platform_agreement$mean_difference, \"%\\n\") cat(\"Agreement within ±10%:\", platform_agreement$agreement_within_10pct, \"%\\n\") cat(\"Overall agreement:\", platform_agreement$overall_agreement, \"%\\n\")  # Clinical significance if(platform_agreement$correlation >= 0.90 && platform_agreement$overall_agreement >= 85) {   cat(\"Conclusion: Platforms show excellent agreement for clinical use\\n\") } else {   cat(\"Conclusion: Platform harmonization may be needed\\n\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "power-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Power Analysis",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Sample size statistical power calculations diagnostic studies.",
        "code": "cat(\"\\nPower Analysis for Diagnostic Studies\\n\") cat(\"====================================\\n\\n\")  # Sample size calculation for ROC analysis # Based on AUC difference detection  auc_null <- 0.5      # Null hypothesis (no discrimination) auc_alternative <- 0.75  # Alternative hypothesis (good discrimination) alpha <- 0.05        # Type I error rate power <- 0.80        # Desired power  # Simplified sample size estimation # Using normal approximation for AUC z_alpha <- qnorm(1 - alpha/2)  # 1.96 for 95% confidence z_beta <- qnorm(power)         # 0.84 for 80% power  # Approximate sample size (simplified formula) estimated_n <- ((z_alpha + z_beta)^2 * 2) / ((auc_alternative - auc_null)^2 * 4)  cat(\"Sample Size Estimation for ROC Study:\\n\") cat(\"Null AUC:\", auc_null, \"\\n\") cat(\"Alternative AUC:\", auc_alternative, \"\\n\")  cat(\"Alpha:\", alpha, \"\\n\") cat(\"Power:\", power, \"\\n\") cat(\"Estimated sample size:\", round(estimated_n), \"per group\\n\") cat(\"Total sample size:\", round(estimated_n * 2), \"\\n\")  # Recommendations if(estimated_n < 50) {   cat(\"Recommendation: Small study feasible\\n\") } else if(estimated_n < 200) {   cat(\"Recommendation: Moderate-sized study required\\n\") } else {   cat(\"Recommendation: Large study required, consider multi-center collaboration\\n\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "integration-with-other-modules",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Integration with Other Modules",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide works seamlessly ClinicoPath modules:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "connection-to-clinicopathdescriptives",
        "dir": "Articles",
        "previous_headings": "Integration with Other Modules",
        "what": "Connection to ClinicoPathDescriptives",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Descriptive statistics inform decision model parameters Quality metrics validate input data reliability Baseline characteristics define patient populations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "connection-to-jsurvival",
        "dir": "Articles",
        "previous_headings": "Integration with Other Modules",
        "what": "Connection to jsurvival",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Survival analysis provides time--event data Markov models Hazard ratios inform transition probabilities Survival curves validate decision model outcomes",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "connection-to-jjstatsplot",
        "dir": "Articles",
        "previous_headings": "Integration with Other Modules",
        "what": "Connection to jjstatsplot",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Statistical plots support decision analysis communication ROC curves forest plots enhance interpretation Sensitivity analysis visualization",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "decision-model-development",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Decision Model Development",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Problem Definition: Clearly define decision context alternatives Model Structure: Choose appropriate model type (tree vs. Markov) Parameter Estimation: Use high-quality data sources Validation: Test model predictions real-world outcomes Sensitivity Analysis: Assess parameter uncertainty impact",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "roc-analysis-guidelines",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "ROC Analysis Guidelines",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Study Design: Prospective cohort appropriate controls Sample Size: Adequate power clinically meaningful differences Cutpoint Selection: Balance sensitivity specificity based clinical needs Validation: Independent validation cohort required Clinical Utility: Demonstrate impact patient outcomes",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "economic-evaluation",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Economic Evaluation",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Perspective: Clearly state economic perspective (payer, societal) Time Horizon: Appropriate capture relevant costs benefits Discounting: Apply standard discount rates future costs/benefits Uncertainty: Comprehensive sensitivity scenario analysis Transparency: Report assumptions data sources",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "meddecide module provides comprehensive tools evidence-based medical decision making, simple diagnostic test evaluation complex health economic modeling. integration traditional decision analysis modern precision medicine applications makes essential tool contemporary healthcare research practice.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Next Steps",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "explore specific applications detail: Precision Oncology: See meddecide-precision-oncology-biomarkers.Rmd ROC Analysis: See meddecide-roc-analysis.Rmd Decision Trees: See meddecide-decision-tree-examples.Rmd Markov Modeling: See meddecide-decision-tree-vs-markov-analysis.Rmd",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/01-introduction.html",
        "id": "support-and-resources",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Support and Resources",
        "title": "MedDecide 01: Introduction to Medical Decision Analysis for Pathologists",
        "text": "Comprehensive Documentation: Detailed function references Real-World Examples: Clinical case studies applications Best Practice Guidelines: Evidence-based recommendations Community Support: Active user forums expert guidance introduction provides foundation using meddecide medical decision analysis. Explore detailed vignettes specific techniques advanced applications.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "meddecide: Medical Decision Making in R",
        "text": "meddecide package provides comprehensive tools medical decision-making, including: ROC Analysis: Receiver Operating Characteristic curve analysis optimal cutpoint determination Diagnostic Test Evaluation: Sensitivity, specificity, predictive values, likelihood ratios Interrater Reliability: Cohen’s kappa Fleiss’ kappa agreement analysis Power Analysis: Sample size calculations kappa statistics",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "ROC (Receiver Operating Characteristic) analysis fundamental evaluating diagnostic tests. psychopdaROC function provides comprehensive ROC analysis multiple methods determining optimal cutpoints.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "basic-usage",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Basic Usage",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "library(meddecide)  # Load example data data(cancer_biomarker)  # Hypothetical dataset  # Basic ROC analysis roc_result <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",           # Test variable   classVar = \"cancer_status\",      # Binary outcome (0/1)   positiveClass = \"1\"              # Which level is positive )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "understanding-roc-curves",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Understanding ROC Curves",
        "title": "meddecide: Medical Decision Making in R",
        "text": "ROC curve plots sensitivity (true positive rate) 1-specificity (false positive rate) across possible cutpoints. area curve (AUC) summarizes overall diagnostic accuracy: AUC = 0.5: discrimination (diagonal line) AUC = 0.7-0.8: Acceptable discrimination AUC = 0.8-0.9: Excellent discrimination AUC > 0.9: Outstanding discrimination",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "optimal-cutpoint-methods",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Optimal Cutpoint Methods",
        "title": "meddecide: Medical Decision Making in R",
        "text": "package offers several methods determine optimal cutpoints:",
        "code": "# Method 1: Maximize Youden's Index (default) roc_youden <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   method = \"maximize_metric\",   metric = \"youden\"  # Sensitivity + Specificity - 1 )  # Method 2: Cost-benefit optimization roc_cost <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   method = \"oc_cost_ratio\",   costratioFP = 2.5  # False positives cost 2.5x more than false negatives )  # Method 3: Equal sensitivity and specificity roc_equal <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   method = \"oc_equal_sens_spec\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "comparing-multiple-tests",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Comparing Multiple Tests",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Compare multiple biomarkers roc_comparison <- psychopdaROC(   data = cancer_biomarker,   dependentVars = c(\"PSA\", \"CA125\", \"CEA\"),  # Multiple tests   classVar = \"cancer_status\",   positiveClass = \"1\",   combinePlots = TRUE,        # Show all curves in one plot   delongTest = TRUE           # Statistical comparison of AUCs )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "advanced-features",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Advanced Features",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Bootstrap confidence intervals roc_bootstrap <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   bootstrapCI = TRUE,   bootstrapReps = 2000 )  # Partial AUC (focus on high specificity region) roc_partial <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   partialAUC = TRUE,   partialAUCfrom = 0.8,  # Specificity range 80-100%   partialAUCto = 1.0 )  # Net Reclassification Index (NRI) and IDI roc_nri <- psychopdaROC(   data = cancer_biomarker,   dependentVars = c(\"PSA\", \"NewBiomarker\"),   classVar = \"cancer_status\",   positiveClass = \"1\",   calculateIDI = TRUE,   calculateNRI = TRUE,   refVar = \"PSA\",  # Compare NewBiomarker against PSA   nriThresholds = \"0.2,0.5\"  # Risk categories: <20%, 20-50%, >50% )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "visualization-options",
        "dir": "Articles",
        "previous_headings": "Vignette 1: ROC Analysis with psychopdaROC",
        "what": "Visualization Options",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Publication-ready plots roc_publication <- psychopdaROC(   data = cancer_biomarker,   dependentVars = c(\"PSA\", \"CA125\"),   classVar = \"cancer_status\",   positiveClass = \"1\",   plotROC = TRUE,   cleanPlot = TRUE,           # Clean plot for publications   showOptimalPoint = TRUE,    # Mark optimal cutpoint   legendPosition = \"bottomright\" )  # Additional diagnostic plots roc_diagnostic <- psychopdaROC(   data = cancer_biomarker,   dependentVars = \"PSA\",   classVar = \"cancer_status\",   positiveClass = \"1\",   showCriterionPlot = TRUE,   # Sensitivity/Specificity vs threshold   showPrevalencePlot = TRUE,  # PPV/NPV vs prevalence   showDotPlot = TRUE          # Distribution by class )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-1",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "decision function evaluates diagnostic test performance gold standard, calculating sensitivity, specificity, predictive values, likelihood ratios.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "basic-analysis",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Basic Analysis",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Evaluate a new rapid test against gold standard decision_result <- decision(   data = diagnostic_data,   gold = \"pcr_result\",        # Gold standard test   goldPositive = \"positive\",   # Positive level of gold standard   newtest = \"rapid_test\",      # New test to evaluate   testPositive = \"positive\"    # Positive level of new test )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "understanding-the-output",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Understanding the Output",
        "title": "meddecide: Medical Decision Making in R",
        "text": "function provides: Confusion Matrix: True positives, false positives, true negatives, false negatives Sensitivity: Proportion true positives correctly identified Specificity: Proportion true negatives correctly identified PPV: Probability disease given positive test NPV: Probability disease given negative test Likelihood ratios: much test result changes disease probability",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "using-prior-probability",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Using Prior Probability",
        "title": "meddecide: Medical Decision Making in R",
        "text": "study population differs target population:",
        "code": "# Adjust for population prevalence decision_adjusted <- decision(   data = diagnostic_data,   gold = \"pcr_result\",   goldPositive = \"positive\",   newtest = \"rapid_test\",   testPositive = \"positive\",   pp = TRUE,                  # Use prior probability   pprob = 0.05                # 5% prevalence in general population )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "confidence-intervals",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Confidence Intervals",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Add 95% confidence intervals decision_ci <- decision(   data = diagnostic_data,   gold = \"pcr_result\",   goldPositive = \"positive\",   newtest = \"rapid_test\",   testPositive = \"positive\",   ci = TRUE                   # Calculate confidence intervals )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "fagan-nomogram",
        "dir": "Articles",
        "previous_headings": "Vignette 2: Diagnostic Test Evaluation with decision",
        "what": "Fagan Nomogram",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Visualize test results change disease probability:",
        "code": "# Create Fagan nomogram decision_fagan <- decision(   data = diagnostic_data,   gold = \"pcr_result\",   goldPositive = \"positive\",   newtest = \"rapid_test\",   testPositive = \"positive\",   fagan = TRUE                # Generate Fagan nomogram )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-2",
        "dir": "Articles",
        "previous_headings": "Vignette 3: Decision Calculator with decisioncalculator",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "summary statistics instead raw data, use decisioncalculator.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "basic-usage-1",
        "dir": "Articles",
        "previous_headings": "Vignette 3: Decision Calculator with decisioncalculator",
        "what": "Basic Usage",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# From a published 2x2 table calc_result <- decisioncalculator(   TP = 85,    # True positives   FP = 15,    # False positives     FN = 10,    # False negatives   TN = 90     # True negatives )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "adjusting-for-prevalence",
        "dir": "Articles",
        "previous_headings": "Vignette 3: Decision Calculator with decisioncalculator",
        "what": "Adjusting for Prevalence",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Adjust for different population prevalence calc_adjusted <- decisioncalculator(   TP = 85,   FP = 15,   FN = 10,   TN = 90,   pp = TRUE,   pprob = 0.02  # 2% prevalence in screening population )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "interpreting-results",
        "dir": "Articles",
        "previous_headings": "Vignette 3: Decision Calculator with decisioncalculator",
        "what": "Interpreting Results",
        "title": "meddecide: Medical Decision Making in R",
        "text": "calculator provides: - Accuracy: Overall correct classification rate - Prevalence: Disease frequency study - Post-test probabilities: Updated disease probability testing - Likelihood ratios: Diagnostic test strength",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-3",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "agreement function assesses well multiple raters agree classifying subjects.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "two-raters-cohens-kappa",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Two Raters (Cohen’s Kappa)",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Two pathologists rating tumor grades kappa_result <- agreement(   data = pathology_data,   vars = c(\"pathologist1\", \"pathologist2\") )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "interpretation",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Interpretation:",
        "title": "meddecide: Medical Decision Making in R",
        "text": "κ < 0.00: Poor agreement κ = 0.00-0.20: Slight agreement κ = 0.21-0.40: Fair agreement κ = 0.41-0.60: Moderate agreement κ = 0.61-0.80: Substantial agreement κ = 0.81-1.00: Almost perfect agreement",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "weighted-kappa-for-ordinal-data",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Weighted Kappa for Ordinal Data",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# For ordinal categories (e.g., grades 1-5) weighted_kappa <- agreement(   data = pathology_data,   vars = c(\"pathologist1\", \"pathologist2\"),   wght = \"squared\"  # Squared weights for ordinal data )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "multiple-raters-fleiss-kappa",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Multiple Raters (Fleiss’ Kappa)",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Three or more raters fleiss_kappa <- agreement(   data = radiology_data,   vars = c(\"radiologist1\", \"radiologist2\", \"radiologist3\", \"radiologist4\") )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "exact-kappa",
        "dir": "Articles",
        "previous_headings": "Vignette 4: Interrater Reliability with agreement",
        "what": "Exact Kappa",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# For small samples with 3+ raters exact_kappa <- agreement(   data = small_study,   vars = c(\"rater1\", \"rater2\", \"rater3\"),   exct = TRUE  # Use exact method )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-4",
        "dir": "Articles",
        "previous_headings": "Vignette 5: Power Analysis for Kappa with kappaSizePower",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Plan sample sizes interrater reliability studies.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "basic-sample-size-calculation",
        "dir": "Articles",
        "previous_headings": "Vignette 5: Power Analysis for Kappa with kappaSizePower",
        "what": "Basic Sample Size Calculation",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Sample size for binary outcome sample_size <- kappaSizePower(   outcome = \"2\",           # Binary outcome   kappa0 = 0.4,           # Null hypothesis: fair agreement   kappa1 = 0.6,           # Alternative: moderate agreement   props = \"0.3, 0.7\",     # 30% positive, 70% negative   raters = \"2\",           # Two raters   alpha = 0.05,           # Type I error rate   power = 0.80            # Statistical power )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "multiple-categories",
        "dir": "Articles",
        "previous_headings": "Vignette 5: Power Analysis for Kappa with kappaSizePower",
        "what": "Multiple Categories",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Sample size for 3-category outcome sample_size_3cat <- kappaSizePower(   outcome = \"3\",   kappa0 = 0.4,   kappa1 = 0.6,   props = \"0.2, 0.5, 0.3\",  # Category proportions   raters = \"2\",   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "multiple-raters",
        "dir": "Articles",
        "previous_headings": "Vignette 5: Power Analysis for Kappa with kappaSizePower",
        "what": "Multiple Raters",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Sample size for 3 raters sample_size_3raters <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.4,   kappa1 = 0.6,   props = \"0.4, 0.6\",   raters = \"3\",             # Three raters   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-5",
        "dir": "Articles",
        "previous_headings": "Vignette 6: Confidence Interval Approach with kappaSizeCI",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Calculate sample size based desired confidence interval width.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "basic-usage-2",
        "dir": "Articles",
        "previous_headings": "Vignette 6: Confidence Interval Approach with kappaSizeCI",
        "what": "Basic Usage",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Sample size for precise kappa estimation ci_sample_size <- kappaSizeCI(   outcome = \"2\",   kappa0 = 0.6,      # Expected kappa   kappaL = 0.4,      # Lower CI bound   kappaU = 0.8,      # Upper CI bound   props = \"0.2, 0.8\",   raters = \"2\",   alpha = 0.05 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "planning-for-publication",
        "dir": "Articles",
        "previous_headings": "Vignette 6: Confidence Interval Approach with kappaSizeCI",
        "what": "Planning for Publication",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Narrow CI for publication standards publication_size <- kappaSizeCI(   outcome = \"2\",   kappa0 = 0.7,      # Expected substantial agreement   kappaL = 0.6,      # Lower bound still substantial   kappaU = 0.8,      # Upper bound   props = \"0.3, 0.7\",   raters = \"2\",   alpha = 0.05 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "introduction-6",
        "dir": "Articles",
        "previous_headings": "Vignette 7: Fixed Sample Size Analysis with kappaSizeFixedN",
        "what": "Introduction",
        "title": "meddecide: Medical Decision Making in R",
        "text": "sample size predetermined, calculate expected kappa precision.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "usage",
        "dir": "Articles",
        "previous_headings": "Vignette 7: Fixed Sample Size Analysis with kappaSizeFixedN",
        "what": "Usage",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# What kappa precision with 100 subjects? fixed_n_result <- kappaSizeFixedN(   outcome = \"2\",   kappa0 = 0.5,       # Expected kappa   props = \"0.4, 0.6\",   raters = \"2\",   alpha = 0.05,   n = 100             # Fixed sample size )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "feasibility-assessment",
        "dir": "Articles",
        "previous_headings": "Vignette 7: Fixed Sample Size Analysis with kappaSizeFixedN",
        "what": "Feasibility Assessment",
        "title": "meddecide: Medical Decision Making in R",
        "text": "",
        "code": "# Check if available sample provides adequate precision feasibility <- kappaSizeFixedN(   outcome = \"3\",   kappa0 = 0.6,   props = \"0.3, 0.4, 0.3\",   raters = \"2\",   alpha = 0.05,   n = 50              # Available subjects )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "roc-analysis",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "1. ROC Analysis",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Always verify positive class specification Consider clinical costs choosing cutpoints Use bootstrap CIs small samples Report sensitivity specificity chosen cutpoint",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "diagnostic-test-evaluation",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "2. Diagnostic Test Evaluation",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Account spectrum bias study design Adjust target population prevalence Report confidence intervals Consider clinical context interpretation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "interrater-reliability",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "3. Interrater Reliability",
        "title": "meddecide: Medical Decision Making in R",
        "text": "Use appropriate kappa variant (weighted ordinal data) Ensure raters properly trained Consider prevalence effects kappa Report percentage agreement alongside kappa",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "power-analysis",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "4. Power Analysis",
        "title": "meddecide: Medical Decision Making in R",
        "text": "realistic expected agreement levels Consider dropout rates Account category imbalance Plan pilot studies parameters uncertain",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/02-comprehensive-guide.html",
        "id": "references",
        "dir": "Articles",
        "previous_headings": "",
        "what": "References",
        "title": "meddecide: Medical Decision Making in R",
        "text": "DeLong ER, DeLong DM, Clarke-Pearson DL (1988). Comparing areas two correlated receiver operating characteristic curves: nonparametric approach. Biometrics 44:837-845. Cohen J (1960). coefficient agreement nominal scales. Educational Psychological Measurement 20:37-46. Fleiss JL (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin 76:378-382. Pencina MJ, D’Agostino RB Sr, D’Agostino RB Jr, Vasan RS (2008). Evaluating added predictive ability new marker: area ROC curve reclassification beyond. Statistics Medicine 27:157-172. Fagan TJ (1975). Nomogram Bayes theorem. New England Journal Medicine 293:257.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "vignette demonstrates advanced features agreement function ClinicoPath, focusing specialized analysis methods pathology applications. features go beyond basic kappa statistics provide insights diagnostic patterns, rater characteristics, pathology-specific metrics.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "key-advanced-features",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Key Advanced Features",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Diagnostic Style Clustering (Usubutun et al. 2012 method) Pathology-Specific Analysis diagnostic accuracy metrics Krippendorff’s Alpha complex data types Outlier Case Analysis quality improvement Rater Characteristic Analysis understanding bias patterns",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "dataset-overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Dataset Overview",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "’ll use histopathology dataset contains ratings multiple observers.",
        "code": "# Load the histopathology dataset data(histopathology)  # Check available rater variables rater_vars <- c(\"Rater 1\", \"Rater 2\", \"Rater 3\", \"Rater A\", \"Rater B\") cat(\"Available rater variables and their values:\\n\") for (var in rater_vars) {   if (var %in% names(histopathology)) {     values <- unique(histopathology[[var]])     cat(sprintf(\"%s: %s\\n\", var, paste(values[!is.na(values)], collapse = \", \")))   } }  # Overview of the dataset cat(sprintf(\"\\nDataset: %d cases, %d variables\\n\", nrow(histopathology), ncol(histopathology)))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-1-standard-kappa-analysis",
        "dir": "Articles",
        "previous_headings": "Basic Agreement Analysis",
        "what": "Example 1: Standard Kappa Analysis",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Basic agreement analysis with Cohen's kappa (2 raters) basic_agreement <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\"),   showInterpretation = TRUE,   heatmap = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-2-fleiss-kappa-for-multiple-raters",
        "dir": "Articles",
        "previous_headings": "Basic Agreement Analysis",
        "what": "Example 2: Fleiss’ Kappa for Multiple Raters",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Agreement analysis with Fleiss' kappa (3+ raters) fleiss_agreement <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\"),   exct = TRUE,  # Use exact calculation   pairwiseAnalysis = TRUE,   categoryAnalysis = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-3-intraclass-correlation-coefficient-icc",
        "dir": "Articles",
        "previous_headings": "Advanced Reliability Measures",
        "what": "Example 3: Intraclass Correlation Coefficient (ICC)",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# ICC analysis for ordinal data icc_analysis <- agreement(   data = histopathology,   vars = c(\"Rater A\", \"Rater B\"),  # Ordinal raters (1, 2, 3)   icc = TRUE,   iccType = \"ICC2k\",  # Average measures, consistency   confidenceLevel = 0.95 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-4-krippendorffs-alpha",
        "dir": "Articles",
        "previous_headings": "Advanced Reliability Measures",
        "what": "Example 4: Krippendorff’s Alpha",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Krippendorff's alpha for generalized reliability kripp_analysis <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\"),   kripp = TRUE,   krippMethod = \"nominal\",   bootstrap = TRUE  # Bootstrap confidence intervals )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "diagnostic-style-clustering-usubutun-method",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Diagnostic Style Clustering (Usubutun Method)",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Usubutun method (Usubutun et al. 2012) identifies diagnostic “schools” “styles” among pathologists using hierarchical clustering based diagnostic patterns.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-5-basic-diagnostic-style-analysis",
        "dir": "Articles",
        "previous_headings": "Diagnostic Style Clustering (Usubutun Method)",
        "what": "Example 5: Basic Diagnostic Style Analysis",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Basic diagnostic style clustering style_analysis <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\", \"Rater A\", \"Rater B\"),   diagnosticStyleAnalysis = TRUE,   styleClusterMethod = \"ward\",  # Ward's linkage (original Usubutun method)   styleDistanceMetric = \"agreement\",  # Percentage agreement distance   numberOfStyleGroups = 3 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-6-advanced-style-analysis-with-rater-characteristics",
        "dir": "Articles",
        "previous_headings": "Diagnostic Style Clustering (Usubutun Method)",
        "what": "Example 6: Advanced Style Analysis with Rater Characteristics",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Advanced style analysis including rater characteristics advanced_style <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\", \"Rater A\", \"Rater B\"),   diagnosticStyleAnalysis = TRUE,   styleClusterMethod = \"ward\",   styleDistanceMetric = \"agreement\",   numberOfStyleGroups = 3,   identifyDiscordantCases = TRUE,   raterCharacteristics = TRUE,   experienceVar = \"Age\",      # Use Age as proxy for experience   trainingVar = \"Group\",      # Use Group as proxy for training background   institutionVar = \"Race\",    # Use Race as proxy for institution   specialtyVar = \"Sex\"        # Use Sex as proxy for specialty )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-7-different-clustering-methods-comparison",
        "dir": "Articles",
        "previous_headings": "Diagnostic Style Clustering (Usubutun Method)",
        "what": "Example 7: Different Clustering Methods Comparison",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Compare different clustering methods clustering_methods <- c(\"ward\", \"complete\", \"average\") distance_metrics <- c(\"agreement\", \"correlation\", \"euclidean\")  # Ward's method with agreement distance (original Usubutun) usubutun_original <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\"),   diagnosticStyleAnalysis = TRUE,   styleClusterMethod = \"ward\",   styleDistanceMetric = \"agreement\",   numberOfStyleGroups = 3 )  # Complete linkage with correlation distance complete_corr <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\"),   diagnosticStyleAnalysis = TRUE,   styleClusterMethod = \"complete\",   styleDistanceMetric = \"correlation\",   numberOfStyleGroups = 3 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-8-diagnostic-accuracy-analysis",
        "dir": "Articles",
        "previous_headings": "Pathology-Specific Analysis",
        "what": "Example 8: Diagnostic Accuracy Analysis",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Pathology-specific analysis with gold standard pathology_analysis <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\"),   pathologyContext = TRUE,   diagnosisVar = \"Outcome\",  # Gold standard diagnosis   categoryAnalysis = TRUE,   outlierAnalysis = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-9-biomarker-scoring-agreement",
        "dir": "Articles",
        "previous_headings": "Pathology-Specific Analysis",
        "what": "Example 9: Biomarker Scoring Agreement",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Simulate biomarker scoring data for demonstration set.seed(123) biomarker_data <- data.frame(   case_id = 1:100,   pathologist_1 = sample(0:3, 100, replace = TRUE, prob = c(0.3, 0.3, 0.3, 0.1)),   pathologist_2 = sample(0:3, 100, replace = TRUE, prob = c(0.25, 0.35, 0.3, 0.1)),   pathologist_3 = sample(0:3, 100, replace = TRUE, prob = c(0.2, 0.4, 0.3, 0.1)),   gold_standard = sample(0:3, 100, replace = TRUE, prob = c(0.2, 0.4, 0.3, 0.1)) )  # Agreement analysis for biomarker scoring biomarker_agreement <- agreement(   data = biomarker_data,   vars = c(\"pathologist_1\", \"pathologist_2\", \"pathologist_3\"),   wght = \"squared\",  # Weighted kappa for ordinal scores   pathologyContext = TRUE,   diagnosisVar = \"gold_standard\",   categoryAnalysis = TRUE,   confidenceLevel = 0.95 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-10-identifying-problematic-cases",
        "dir": "Articles",
        "previous_headings": "Outlier and Quality Control Analysis",
        "what": "Example 10: Identifying Problematic Cases",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Comprehensive outlier analysis outlier_analysis <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\", \"Rater A\", \"Rater B\"),   outlierAnalysis = TRUE,   diagnosticStyleAnalysis = TRUE,   identifyDiscordantCases = TRUE,   pathologyContext = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-11-quality-assurance-monitoring",
        "dir": "Articles",
        "previous_headings": "Outlier and Quality Control Analysis",
        "what": "Example 11: Quality Assurance Monitoring",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Create synthetic QA data for demonstration set.seed(456) qa_data <- data.frame(   case_id = 1:200,   staff_pathologist = sample(c(\"Benign\", \"Malignant\", \"Atypical\"), 200,                             replace = TRUE, prob = c(0.6, 0.3, 0.1)),   resident_month_1 = sample(c(\"Benign\", \"Malignant\", \"Atypical\"), 200,                            replace = TRUE, prob = c(0.5, 0.35, 0.15)),   resident_month_6 = sample(c(\"Benign\", \"Malignant\", \"Atypical\"), 200,                            replace = TRUE, prob = c(0.58, 0.32, 0.1)),   consensus_diagnosis = sample(c(\"Benign\", \"Malignant\", \"Atypical\"), 200,                               replace = TRUE, prob = c(0.65, 0.28, 0.07)) )  # QA analysis comparing resident progress qa_analysis <- agreement(   data = qa_data,   vars = c(\"staff_pathologist\", \"resident_month_1\", \"resident_month_6\"),   pathologyContext = TRUE,   diagnosisVar = \"consensus_diagnosis\",   pairwiseAnalysis = TRUE,   categoryAnalysis = TRUE,   outlierAnalysis = TRUE,   showInterpretation = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-12-grading-agreement-with-weighted-kappa",
        "dir": "Articles",
        "previous_headings": "Weighted Kappa for Ordinal Data",
        "what": "Example 12: Grading Agreement with Weighted Kappa",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Create tumor grading data grading_data <- data.frame(   case_id = 1:150,   pathologist_1 = sample(1:3, 150, replace = TRUE, prob = c(0.4, 0.4, 0.2)),   pathologist_2 = sample(1:3, 150, replace = TRUE, prob = c(0.35, 0.45, 0.2)),   expert_consensus = sample(1:3, 150, replace = TRUE, prob = c(0.3, 0.5, 0.2)) )  # Convert to ordered factors for proper weighted kappa grading_data$pathologist_1 <- factor(grading_data$pathologist_1,                                      levels = 1:3, ordered = TRUE) grading_data$pathologist_2 <- factor(grading_data$pathologist_2,                                      levels = 1:3, ordered = TRUE) grading_data$expert_consensus <- factor(grading_data$expert_consensus,                                         levels = 1:3, ordered = TRUE)  # Weighted kappa analysis weighted_analysis <- agreement(   data = grading_data,   vars = c(\"pathologist_1\", \"pathologist_2\"),   wght = \"squared\",  # Squared weights for ordinal data   pathologyContext = TRUE,   diagnosisVar = \"expert_consensus\",   categoryAnalysis = TRUE,   confidenceLevel = 0.95 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "example-13-comprehensive-multi-rater-study",
        "dir": "Articles",
        "previous_headings": "Complex Multi-Rater Scenarios",
        "what": "Example 13: Comprehensive Multi-Rater Study",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "",
        "code": "# Comprehensive analysis with all features comprehensive_analysis <- agreement(   data = histopathology,   vars = c(\"Rater 1\", \"Rater 2\", \"Rater 3\", \"Rater A\", \"Rater B\"),      # Basic agreement measures   exct = TRUE,   icc = TRUE,   iccType = \"ICC2k\",   kripp = TRUE,   krippMethod = \"nominal\",      # Pathology-specific features   pathologyContext = TRUE,   diagnosisVar = \"Outcome\",      # Advanced analysis   pairwiseAnalysis = TRUE,   categoryAnalysis = TRUE,   outlierAnalysis = TRUE,      # Diagnostic style clustering   diagnosticStyleAnalysis = TRUE,   styleClusterMethod = \"ward\",   styleDistanceMetric = \"agreement\",   numberOfStyleGroups = 3,   identifyDiscordantCases = TRUE,   raterCharacteristics = TRUE,      # Visualization and interpretation   heatmap = TRUE,   heatmapDetails = TRUE,   showInterpretation = TRUE,   sft = TRUE,      # Statistical settings   confidenceLevel = 0.95,   minAgreement = 0.6 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "understanding-diagnostic-style-results",
        "dir": "Articles",
        "previous_headings": "Interpretation and Clinical Applications",
        "what": "Understanding Diagnostic Style Results",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "diagnostic style clustering analysis (Usubutun method) provides insights : Style Groups: Identification pathologists share similar diagnostic patterns Experience Patterns: Whether diagnostic styles correlate experience levels Training Effects: Whether pathologists similar training backgrounds cluster together Institutional Bias: Whether pathologists institution show similar patterns Discordant Cases: Specific cases distinguish different diagnostic styles",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "quality-assurance",
        "dir": "Articles",
        "previous_headings": "Interpretation and Clinical Applications > Clinical Applications",
        "what": "Quality Assurance",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Monitor consistency pathologists Identify cases requiring consensus review Track improvement training programs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "research-applications",
        "dir": "Articles",
        "previous_headings": "Interpretation and Clinical Applications > Clinical Applications",
        "what": "Research Applications",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Validate new diagnostic criteria Assess inter-observer reliability clinical trials Study sources diagnostic variation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "education",
        "dir": "Articles",
        "previous_headings": "Interpretation and Clinical Applications > Clinical Applications",
        "what": "Education",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Identify learning objectives residents Monitor progress diagnostic skills Compare different training approaches",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "data-preparation",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Data Preparation",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Ensure Complete Cases: Remove cases missing ratings Standardize Categories: Use consistent diagnostic categories across raters Appropriate Sample Size: Minimum 50 cases reliable kappa estimates",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "analysis-selection",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Analysis Selection",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Cohen’s vs Fleiss’ Kappa: Use Cohen’s 2 raters, Fleiss’ 3+ Weighted Kappa: Use ordinal data (grades, stages) ICC: Use continuous ordinal measurements Krippendorff’s Alpha: Use complex designs missing data",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "kappa-values",
        "dir": "Articles",
        "previous_headings": "Best Practices > Interpretation Guidelines",
        "what": "Kappa Values",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "< 0.20: Poor agreement 0.21-0.40: Fair agreement 0.41-0.60: Moderate agreement 0.61-0.80: Substantial agreement 0.81-1.00: Almost perfect agreement",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "clinical-significance",
        "dir": "Articles",
        "previous_headings": "Best Practices > Interpretation Guidelines",
        "what": "Clinical Significance",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Consider statistical significance clinical importance Account prevalence effects interpretation Use confidence intervals decision making",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "common-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting",
        "what": "Common Issues",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Low Agreement: Check systematic bias, category definitions, training needs Convergence Problems: Reduce model complexity increase sample size Missing Data: Use appropriate handling methods Krippendorff’s alpha",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "performance-optimization",
        "dir": "Articles",
        "previous_headings": "Troubleshooting",
        "what": "Performance Optimization",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Large Datasets: Use sampling diagnostic style analysis Many Raters: Consider pairwise analysis first Complex Models: Start basic analysis adding advanced features",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "advanced features ClinicoPath’s agreement function provide comprehensive tools understanding inter-rater reliability pathology. Usubutun diagnostic style clustering method offers unique insights pathologist behavior patterns, pathology-specific metrics ensure clinical relevance. Key advantages include: Comprehensive Analysis: Multiple reliability measures one tool Pathology Focus: Specialized features diagnostic applications Style Analysis: Understanding diagnostic patterns bias Quality Control: Tools ongoing monitoring improvement Research Support: Robust methods reliability studies tools support evidence-based quality assurance, training program evaluation, research diagnostic pathology.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-advanced-features.html",
        "id": "references",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "References",
        "title": "Advanced Features in Interrater Agreement Analysis",
        "text": "Usubutun, ., et al. (2012). “Diagnostic agreement patterns pathology: cluster analysis approach.” Journal Clinical Pathology, 65(12), 1108-1112. Landis, J. R., & Koch, G. G. (1977). “measurement observer agreement categorical data.” Biometrics, 33(1), 159-174. Krippendorff, K. (2004). “Reliability content analysis: common misconceptions recommendations.” Human Communication Research, 30(3), 411-433. information ClinicoPath capabilities, visit ClinicoPath GitHub repository.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "Inter-rater agreement reliability analysis fundamental pathology practice, quality assurance, research. comprehensive guide covers agreement analysis pathologists, basic Cohen’s kappa advanced methods complex study designs. Learning Objectives: Understand types agreement measures appropriate use Master interpretation kappa statistics pathological contexts Learn design power agreement studies Apply agreement analysis different pathological scenarios Implement quality assurance programs using agreement metrics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "clinical-applications-in-pathology",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Clinical Applications in Pathology",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "Agreement analysis essential : Diagnostic Consistency: Evaluating inter-pathologist agreement diagnoses Biomarker Scoring: Assessing concordance IHC, FISH, molecular markers Grading Systems: Validating tumor grading staging protocols Digital Pathology: Comparing traditional vs. digital diagnosis Training Programs: Monitoring resident fellow progress Quality Assurance: Establishing institutional benchmarks",
        "code": "library(meddecide) library(dplyr) library(ggplot2) library(knitr) library(irr)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "comprehensive-agreement-datasets",
        "dir": "Articles",
        "previous_headings": "Dataset Overview",
        "what": "Comprehensive Agreement Datasets",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "package includes multiple datasets different agreement scenarios:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "breast-cancer-agreement-study",
        "dir": "Articles",
        "previous_headings": "Dataset Overview > Comprehensive Agreement Datasets",
        "what": "Breast Cancer Agreement Study",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "dataset represents multi-institutional study breast cancer diagnosis agreement : - 3 pathologists different experience levels - 200 cases including various breast lesions - 4 diagnostic categories: Benign, Atypical, DCIS, Invasive Carcinoma - Institutional variability across academic community settings",
        "code": "# Load breast cancer pathologist agreement data data(breast_agreement_data)  # Overview of the study str(breast_agreement_data) cat(\"Study includes:\", nrow(breast_agreement_data), \"cases from\",      length(unique(breast_agreement_data$Institution)), \"institutions\\n\")  # Preview the data structure head(breast_agreement_data)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "melanoma-agreement-study",
        "dir": "Articles",
        "previous_headings": "Dataset Overview > Comprehensive Agreement Datasets",
        "what": "Melanoma Agreement Study",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Load melanoma agreement data for histologic features data(melanoma_agreement_data)  # Study characteristics table(melanoma_agreement_data$Histologic_Subtype) table(melanoma_agreement_data$Breslow_Category)"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "basic-two-rater-agreement",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 1. Binary Classifications (Cohen’s Kappa)",
        "what": "Basic Two-Rater Agreement",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Evaluate agreement between two experienced pathologists agreement_result <- agreement(   data = breast_agreement_data,   rater1_var = \"Pathologist_1_Diagnosis\",   rater2_var = \"Pathologist_2_Diagnosis\",   agreement_type = \"kappa\",   conf_level = 0.95 )  # View results print(agreement_result)  # Interpretation if (agreement_result$kappa > 0.81) {   cat(\"Agreement is ALMOST PERFECT (κ >0.81)\") } else if (agreement_result$kappa > 0.61) {   cat(\"Agreement is SUBSTANTIAL (κ 0.61-0.80)\") } else if (agreement_result$kappa > 0.41) {   cat(\"Agreement is MODERATE (κ 0.41-0.60)\") } else {   cat(\"Agreement needs improvement (κ ≤0.40)\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "weighted-kappa-for-ordinal-categories",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 1. Binary Classifications (Cohen’s Kappa)",
        "what": "Weighted Kappa for Ordinal Categories",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# For ordinal variables like tumor grades # Convert to ordered factors if needed breast_agreement_data$Grade_1 <- factor(breast_agreement_data$Grade_Pathologist_1,                                          levels = 1:3, ordered = TRUE) breast_agreement_data$Grade_2 <- factor(breast_agreement_data$Grade_Pathologist_2,                                          levels = 1:3, ordered = TRUE)  # Weighted kappa accounts for degree of disagreement weighted_agreement <- agreement(   data = breast_agreement_data,   rater1_var = \"Grade_1\",   rater2_var = \"Grade_2\",    agreement_type = \"weighted_kappa\",   weights = \"quadratic\",  # Penalizes larger disagreements more   conf_level = 0.95 )  print(weighted_agreement)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "three-pathologist-study-design",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 2. Multiple Raters (Fleiss’ Kappa)",
        "what": "Three-Pathologist Study Design",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Reshape data for multiple raters library(dplyr)  # Create matrix format required for Fleiss' kappa multi_rater_data <- breast_agreement_data %>%   select(Case_ID, Pathologist_1_Diagnosis, Pathologist_2_Diagnosis, Pathologist_3_Diagnosis)  # Calculate Fleiss' kappa fleiss_result <- agreement(   data = multi_rater_data,   rater_vars = c(\"Pathologist_1_Diagnosis\", \"Pathologist_2_Diagnosis\", \"Pathologist_3_Diagnosis\"),   agreement_type = \"fleiss\",   conf_level = 0.95 )  print(fleiss_result)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "category-specific-agreement",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 2. Multiple Raters (Fleiss’ Kappa)",
        "what": "Category-Specific Agreement",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Examine agreement for each diagnostic category category_agreement <- agreement(   data = multi_rater_data,   rater_vars = c(\"Pathologist_1_Diagnosis\", \"Pathologist_2_Diagnosis\", \"Pathologist_3_Diagnosis\"),   agreement_type = \"fleiss\",   category_specific = TRUE )  # Plot category-specific kappa values plot(category_agreement, type = \"category\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "intraclass-correlation-coefficient",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 3. Continuous Measurements (ICC)",
        "what": "Intraclass Correlation Coefficient",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# For continuous measurements like Ki-67 percentages icc_result <- icccoeff(   data = breast_agreement_data,   vars = c(\"Ki67_Pathologist_1\", \"Ki67_Pathologist_2\", \"Ki67_Pathologist_3\"),   icc_type = \"icc2_k\",  # Two-way random effects, average measures   confidence_level = \"0.95\" )  print(icc_result)  # ICC interpretation: # < 0.50: Poor reliability # 0.50-0.75: Moderate reliability   # 0.75-0.90: Good reliability # > 0.90: Excellent reliability"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "bland-altman-analysis",
        "dir": "Articles",
        "previous_headings": "Types of Agreement Analysis > 3. Continuous Measurements (ICC)",
        "what": "Bland-Altman Analysis",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# For method comparison studies bland_altman_plot <- agreement(   data = breast_agreement_data,   method1 = \"Ki67_Pathologist_1\",   method2 = \"Ki67_Pathologist_2\",   analysis_type = \"bland_altman\",   plot_type = \"difference\",   limits_of_agreement = TRUE )  print(bland_altman_plot)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "experience-level-analysis",
        "dir": "Articles",
        "previous_headings": "Factors Affecting Agreement",
        "what": "Experience Level Analysis",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Compare agreement by pathologist experience experience_comparison <- breast_agreement_data %>%   group_by(Pathologist_Experience) %>%   summarise(     agreement_with_consensus = agreement(       rater1_var = \"Pathologist_Diagnosis\",       rater2_var = \"Consensus_Diagnosis\",       agreement_type = \"kappa\"     )$kappa,     .groups = \"drop\"   )  print(experience_comparison)  # Visualize experience effect ggplot(experience_comparison, aes(x = Pathologist_Experience, y = agreement_with_consensus)) +   geom_bar(stat = \"identity\", fill = \"steelblue\") +   labs(title = \"Agreement with Consensus by Experience Level\",        x = \"Pathologist Experience\",         y = \"Kappa Coefficient\") +   theme_minimal()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "case-difficulty-analysis",
        "dir": "Articles",
        "previous_headings": "Factors Affecting Agreement",
        "what": "Case Difficulty Analysis",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Examine agreement by case difficulty difficulty_analysis <- breast_agreement_data %>%   mutate(     case_difficulty = case_when(       Consensus_Confidence >= 4 ~ \"Easy\",       Consensus_Confidence == 3 ~ \"Moderate\",        Consensus_Confidence <= 2 ~ \"Difficult\"     )   ) %>%   group_by(case_difficulty) %>%   summarise(     kappa = agreement(       rater1_var = \"Pathologist_1_Diagnosis\",       rater2_var = \"Pathologist_2_Diagnosis\",        agreement_type = \"kappa\"     )$kappa,     n_cases = n(),     .groups = \"drop\"   )  print(difficulty_analysis)"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "binary-outcomes",
        "dir": "Articles",
        "previous_headings": "Study Design and Sample Size Planning > Power Analysis for Agreement Studies",
        "what": "Binary Outcomes",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Calculate sample size for detecting moderate vs substantial agreement power_analysis <- kappaSizePower(   outcome = \"2\",           # Binary outcome   kappa0 = 0.4,           # Null hypothesis (moderate agreement)     kappa1 = 0.6,           # Alternative hypothesis (substantial agreement)   props = \"0.3, 0.7\",     # Expected proportions (30% positive, 70% negative)   raters = \"2\",           # Two raters   alpha = 0.05,           # Type I error   power = 0.80            # Statistical power )  print(power_analysis)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "multiple-categories",
        "dir": "Articles",
        "previous_headings": "Study Design and Sample Size Planning > Power Analysis for Agreement Studies",
        "what": "Multiple Categories",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Sample size for 4-category diagnostic classification power_multicat <- kappaSizePower(   outcome = \"4\",   kappa0 = 0.5,   kappa1 = 0.7,    props = \"0.25, 0.25, 0.25, 0.25\",  # Equal proportions   raters = \"2\",   alpha = 0.05,   power = 0.80 )  print(power_multicat)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "confidence-interval-approach",
        "dir": "Articles",
        "previous_headings": "Study Design and Sample Size Planning > Precision-Based Sample Size",
        "what": "Confidence Interval Approach",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Sample size for desired precision (CI width) precision_analysis <- kappaSizeCI(   outcome = \"2\",   kappa0 = 0.6,          # Expected kappa   conf_level = 0.95,     # Confidence level   width = 0.2,           # Desired CI width (±0.1 around kappa)   props = \"0.4, 0.6\",   raters = \"2\" )  print(precision_analysis)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "fixed-sample-size-analysis",
        "dir": "Articles",
        "previous_headings": "Study Design and Sample Size Planning > Precision-Based Sample Size",
        "what": "Fixed Sample Size Analysis",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# What precision can we achieve with available sample? fixed_n_result <- kappaSizeFixedN(   outcome = \"2\",   kappa0 = 0.6,   props = \"0.3, 0.7\",    raters = \"2\",   conf_level = 0.95,   n = 150               # Available sample size )  print(fixed_n_result)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "conditional-kappa-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Conditional Kappa Analysis",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Agreement conditional on true positive/negative status conditional_agreement <- agreement(   data = breast_agreement_data,   rater1_var = \"Pathologist_1_Diagnosis\",   rater2_var = \"Pathologist_2_Diagnosis\",   truth_var = \"Gold_Standard\",   analysis_type = \"conditional_kappa\" )  print(conditional_agreement)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "multi-level-agreement-hierarchical",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Multi-Level Agreement (Hierarchical)",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Account for clustering by institution library(lme4)  multilevel_model <- agreement(   data = breast_agreement_data,   rater1_var = \"Pathologist_1_Diagnosis\",   rater2_var = \"Pathologist_2_Diagnosis\",    cluster_var = \"Institution\",   analysis_type = \"multilevel_kappa\" )  print(multilevel_model)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "longitudinal-agreement-test-retest",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Longitudinal Agreement (Test-Retest)",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Agreement across time points test_retest <- agreement(   data = breast_agreement_data,   time1_var = \"Initial_Diagnosis\",   time2_var = \"Repeat_Diagnosis\",   subject_id = \"Case_ID\",   analysis_type = \"test_retest\" )  print(test_retest)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "establishing-qa-benchmarks",
        "dir": "Articles",
        "previous_headings": "Quality Assurance Applications",
        "what": "Establishing QA Benchmarks",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Set institutional benchmarks qa_standards <- list(   diagnostic_agreement = list(     minimum_kappa = 0.6,     target_kappa = 0.8,     benchmark_cases = 100   ),   biomarker_scoring = list(     minimum_icc = 0.75,     target_icc = 0.90,     benchmark_cases = 50   ) )  # Monitor ongoing performance current_performance <- agreement(   data = breast_agreement_data,   rater1_var = \"Pathologist_1_Diagnosis\",   rater2_var = \"Consensus_Diagnosis\",   agreement_type = \"kappa\" )  # Check against benchmark if (current_performance$kappa >= qa_standards$diagnostic_agreement$target_kappa) {   cat(\"✓ Performance EXCEEDS target benchmark\") } else if (current_performance$kappa >= qa_standards$diagnostic_agreement$minimum_kappa) {   cat(\"⚠ Performance meets minimum but below target\") } else {   cat(\"✗ Performance BELOW minimum standard - intervention needed\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "training-assessment",
        "dir": "Articles",
        "previous_headings": "Quality Assurance Applications",
        "what": "Training Assessment",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Monitor trainee progress over time trainee_progress <- breast_agreement_data %>%   filter(Pathologist_Level == \"Resident\") %>%   group_by(Training_Month) %>%   summarise(     agreement_with_attending = agreement(       rater1_var = \"Resident_Diagnosis\",       rater2_var = \"Attending_Diagnosis\",        agreement_type = \"kappa\"     )$kappa,     .groups = \"drop\"   )  # Plot learning curve ggplot(trainee_progress, aes(x = Training_Month, y = agreement_with_attending)) +   geom_line(size = 1.2) +   geom_point(size = 3) +   geom_hline(yintercept = 0.6, linetype = \"dashed\", color = \"red\",               alpha = 0.7) +   annotate(\"text\", x = max(trainee_progress$Training_Month) * 0.8, y = 0.65,             label = \"Minimum Standard\", color = \"red\") +   labs(title = \"Resident Training Progress: Agreement with Attending\",        x = \"Training Month\",         y = \"Kappa Coefficient\") +   theme_minimal()"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "clinical-significance-vs-statistical-significance",
        "dir": "Articles",
        "previous_headings": "Interpretation Guidelines",
        "what": "Clinical Significance vs Statistical Significance",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Large sample may show statistical significance for clinically unimportant differences large_study_result <- agreement(   data = large_agreement_dataset,  # Hypothetical large dataset   rater1_var = \"Rater1\",    rater2_var = \"Rater2\",   agreement_type = \"kappa\" )  # Consider both p-value AND effect size cat(\"Statistical significance: p =\", large_study_result$p_value, \"\\n\") cat(\"Clinical significance: κ =\", large_study_result$kappa, \"\\n\")  if (large_study_result$p_value < 0.05 & large_study_result$kappa < 0.4) {   cat(\"Statistically significant but clinically inadequate agreement\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "reporting-standards",
        "dir": "Articles",
        "previous_headings": "Interpretation Guidelines",
        "what": "Reporting Standards",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "",
        "code": "# Template for reporting agreement results agreement_report <- function(result) {   cat(\"Agreement Analysis Report\\n\")   cat(\"========================\\n\\n\")   cat(\"Sample size:\", result$n, \"cases\\n\")   cat(\"Kappa coefficient:\", round(result$kappa, 3),        \"(95% CI:\", round(result$ci_lower, 3), \"-\", round(result$ci_upper, 3), \")\\n\")   cat(\"P-value:\", format.pval(result$p_value), \"\\n\")   cat(\"Interpretation:\", result$interpretation, \"\\n\")   cat(\"Recommendation:\", result$recommendation, \"\\n\") }  # Example usage main_result <- agreement(   data = breast_agreement_data,   rater1_var = \"Pathologist_1_Diagnosis\",   rater2_var = \"Pathologist_2_Diagnosis\",   agreement_type = \"kappa\" )  agreement_report(main_result)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "study-design-considerations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Study Design Considerations",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "Use power analysis hypothesis testing Use precision analysis descriptive studies Account expected agreement levels prevalence Include raters representative intended users Balance experience levels appropriately Ensure adequate training study Include full spectrum difficulty Ensure adequate representation categories Consider enrichment rare categories",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "statistical-considerations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Statistical Considerations",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "Cohen’s kappa: Two raters, nominal/ordinal data Weighted kappa: Ordinal data meaningful ordering Fleiss’ kappa: Multiple raters, nominal data ICC: Continuous measurements Kappa can low even high percentage agreement prevalence extreme Report kappa percentage agreement Consider prevalence-adjusted kappa appropriate Adjust p-values testing multiple agreements Focus clinically important comparisons Report confidence intervals rather just p-values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-agreement-analysis.html",
        "id": "regulatory-considerations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Regulatory Considerations",
        "title": "Inter-Rater Agreement and Reliability Analysis in Pathology",
        "text": "Document predefined acceptable agreement levels Include appropriate statistical analysis plan Consider regulatory precedents similar devices/tests Establish ongoing monitoring procedures Define trigger levels intervention Document corrective action procedures comprehensive guide provides pathologists clinical researchers tools knowledge needed conduct rigorous agreement studies, initial planning final interpretation quality assurance implementation.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-roc-analysis.html",
        "id": "loading-the-data",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Loading the Data",
        "title": "ROC Curve Analysis",
        "text": "",
        "code": "df_roc <- read.csv(system.file(\"extdata\", \"roc_example.csv\", package = \"meddecide\")) head(df_roc)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-roc-analysis.html",
        "id": "creating-the-roc-curve",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Creating the ROC Curve",
        "title": "ROC Curve Analysis",
        "text": "resulting plot shows ROC curve along area curve (AUC). can extract AUC value statistics result object.",
        "code": "roc_res <- psychopdaROC(data = df_roc, class = df_roc$class, value = df_roc$value) roc_res$plot roc_res$AUC"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/03-roc-analysis.html",
        "id": "bootstrapping-and-confidence-intervals",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Bootstrapping and Confidence Intervals",
        "title": "ROC Curve Analysis",
        "text": "pROC package provides robust methods computing confidence intervals diagnostic metrics. methods provide statistically sound confidence intervals ROC analysis.",
        "code": "# Calculate AUC confidence intervals using pROC library(pROC) roc_obj <- roc(response = outcome, predictor = biomarker) pROC::ci.auc(roc_obj, method = \"bootstrap\")  # Calculate threshold-specific confidence intervals pROC::ci.thresholds(roc_obj)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Medical Decision Tree module specifically designed pathology oncology research, providing clinically-relevant decision support tools appropriate performance metrics interpretations.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-performance-metrics",
        "dir": "Articles",
        "previous_headings": "Key Features for Medical Research",
        "what": "1. Clinical Performance Metrics",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Sensitivity & Specificity: Core diagnostic performance measures Predictive Values (PPV/NPV): Adjusted disease prevalence Likelihood Ratios: Evidence-based medicine metrics Clinical Utility Scores: Cost-benefit analysis Confidence Intervals: Statistical uncertainty quantification",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "medical-data-handling",
        "dir": "Articles",
        "previous_headings": "Key Features for Medical Research",
        "what": "2. Medical Data Handling",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Missing Data: Imputation within disease groups Class Imbalance: Handles rare diseases appropriately Biomarker Scaling: Standardizes different measurement units Quality Checks: Validates clinical data ranges",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-context-awareness",
        "dir": "Articles",
        "previous_headings": "Key Features for Medical Research",
        "what": "3. Clinical Context Awareness",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Screening: High sensitivity prioritized Diagnosis: Balanced accuracy Staging: Specificity emphasis Prognosis: Risk stratification focus Treatment: Utility-based decisions",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "example-1-cancer-biomarker-panel",
        "dir": "Articles",
        "previous_headings": "Practical Examples",
        "what": "Example 1: Cancer Biomarker Panel",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Expected Output: - Optimal biomarker panel cutoff values - Individual biomarker importance rankings - Clinical performance metrics CI - Cost-effectiveness analysis",
        "code": "Clinical Context: Biomarker Discovery Target: Cancer diagnosis (Yes/No) Continuous Variables: PSA, CA-125, CEA levels Categorical Variables: Age group, Family history Training Cohort: Discovery cohort Options:  - Balance Classes: Yes (for rare cancers) - Clinical Metrics: Yes - Feature Importance: Yes"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "example-2-pathology-staging-system",
        "dir": "Articles",
        "previous_headings": "Practical Examples",
        "what": "Example 2: Pathology Staging System",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Expected Output: - Multi-factor staging algorithm - Risk group classifications - Treatment recommendations per risk group - Validation metrics across cohorts",
        "code": "Clinical Context: Cancer Staging Target: Advanced stage (III-IV vs I-II) Continuous Variables: Tumor size, Ki-67 index, Mitotic count Categorical Variables: Grade, Histology, Lymph node status Options: - Impute Missing: Yes - Risk Stratification: Yes - Population Adjustment: Yes (if study ≠ target population)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "example-3-treatment-response-prediction",
        "dir": "Articles",
        "previous_headings": "Practical Examples",
        "what": "Example 3: Treatment Response Prediction",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Expected Output: - Treatment response probability patient - Key predictive factors - Clinical decision thresholds - Personalized treatment recommendations",
        "code": "Clinical Context: Treatment Response Target: Complete response (Yes/No) Continuous Variables: Baseline tumor markers, Age Categorical Variables: Stage, Prior treatments, Molecular subtype Training Cohort: Training vs Validation sets Options: - Scale Features: Yes (different biomarker units) - Clinical Interpretation: Yes - Export Predictions: Yes"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "performance-thresholds",
        "dir": "Articles",
        "previous_headings": "Clinical Interpretation Guidelines",
        "what": "Performance Thresholds",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Excellent: Sensitivity/Specificity ≥ 0.90 Good: Sensitivity/Specificity ≥ 0.80 Adequate: Sensitivity/Specificity ≥ 0.70 Poor: Sensitivity/Specificity < 0.70",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "likelihood-ratio-interpretation",
        "dir": "Articles",
        "previous_headings": "Clinical Interpretation Guidelines",
        "what": "Likelihood Ratio Interpretation",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "LR+ ≥ 10: Strong evidence disease LR+ 5-10: Moderate evidence disease LR+ 2-5: Weak evidence disease LR+ < 2: Minimal diagnostic value LR- ≤ 0.1: Strong evidence disease LR- 0.1-0.2: Moderate evidence disease LR- 0.2-0.5: Weak evidence disease LR- > 0.5: Minimal diagnostic value",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "cancer-screening",
        "dir": "Articles",
        "previous_headings": "Clinical Interpretation Guidelines > Clinical Context Recommendations",
        "what": "Cancer Screening",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Priority: High sensitivity (≥ 0.90) Acceptable: Lower specificity (≥ 0.70) Rationale: Missing cancer cases severe consequences",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "diagnostic-confirmation",
        "dir": "Articles",
        "previous_headings": "Clinical Interpretation Guidelines > Clinical Context Recommendations",
        "what": "Diagnostic Confirmation",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Priority: High specificity (≥ 0.90) Acceptable: Moderate sensitivity (≥ 0.80) Rationale: Avoid unnecessary treatments/anxiety",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "prognosis-assessment",
        "dir": "Articles",
        "previous_headings": "Clinical Interpretation Guidelines > Clinical Context Recommendations",
        "what": "Prognosis Assessment",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Priority: Balanced accuracy Focus: Risk stratification capability Metrics: C-index, calibration, discrimination",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "minimum-requirements",
        "dir": "Articles",
        "previous_headings": "Quality Assurance",
        "what": "Minimum Requirements",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Sample Size: ≥ 50 cases reliable trees Events: ≥ 10 per predictor variable Validation: Independent test set cross-validation Missing Data: < 20% per variable",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "red-flags",
        "dir": "Articles",
        "previous_headings": "Quality Assurance",
        "what": "Red Flags",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Low Prevalence: < 5% (consider oversampling) Perfect Separation: May indicate overfitting Extreme Outliers: > 5 SD mean High Missing Data: > 50% key variables",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "data-preparation",
        "dir": "Articles",
        "previous_headings": "Implementation Steps",
        "what": "1. Data Preparation",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Clean validate clinical data Ensure appropriate coding outcomes Check systematic missing patterns Validate biomarker ranges",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "model-development",
        "dir": "Articles",
        "previous_headings": "Implementation Steps",
        "what": "2. Model Development",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Select appropriate clinical context Choose relevant performance metrics Set validation strategy Consider class imbalance",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-validation",
        "dir": "Articles",
        "previous_headings": "Implementation Steps",
        "what": "3. Clinical Validation",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Test independent cohort Assess calibration across subgroups Evaluate clinical utility Compare existing methods",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-implementation",
        "dir": "Articles",
        "previous_headings": "Implementation Steps",
        "what": "4. Clinical Implementation",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Establish quality control procedures Train clinical staff Monitor performance time Update model needed",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "for-diagnostic-tools",
        "dir": "Articles",
        "previous_headings": "Regulatory Considerations",
        "what": "For Diagnostic Tools",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "FDA guidance AI/ML-based medical devices Clinical validation requirements Performance monitoring protocols Documentation standards",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "for-research-applications",
        "dir": "Articles",
        "previous_headings": "Regulatory Considerations",
        "what": "For Research Applications",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "IRB approval retrospective analysis Data privacy compliance (HIPAA) Publication guidelines Reproducibility standards",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "common-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting",
        "what": "Common Issues",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Low Performance: Check data quality, feature relevance Overfitting: Reduce tree depth, increase minimum cases Poor Calibration: Consider calibration methods Class Imbalance: Use appropriate sampling/weighting",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "performance-optimization",
        "dir": "Articles",
        "previous_headings": "Troubleshooting",
        "what": "Performance Optimization",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Feature selection based clinical relevance Cross-validation hyperparameter tuning Ensemble methods improved stability Regular model retraining new data",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "precision-medicine-applications",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Applications",
        "what": "Precision Medicine Applications",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Example: Personalized Cancer Treatment Selection Target: Treatment Response (Complete/Partial/Progressive) Variables:  - Genomic markers (mutations, expression levels) - Clinical factors (age, stage, performance status) - Histopathological features (grade, subtype) - Previous treatments (type, response, duration)  Clinical Impact: - Avoid ineffective treatments - Reduce treatment toxicity - Optimize resource allocation - Improve patient outcomes"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "multi-modal-pathology-integration",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Applications",
        "what": "Multi-Modal Pathology Integration",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Example: AI-Assisted Pathology Diagnosis Target: Histological Diagnosis (Benign/Malignant/Uncertain) Variables: - Quantitative histology metrics - Immunohistochemistry scores - Molecular markers - Clinical presentation data  Benefits: - Standardized diagnostic criteria - Reduced inter-observer variability - Enhanced diagnostic accuracy - Training tool for pathologists"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "longitudinal-outcome-prediction",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Applications",
        "what": "Longitudinal Outcome Prediction",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Example: Disease Progression Monitoring Target: 5-year survival (High/Medium/Low risk) Variables: - Baseline clinical parameters - Treatment response markers - Serial biomarker measurements - Quality of life indicators  Applications: - Treatment intensity adjustment - Follow-up scheduling optimization - Patient counseling support - Clinical trial stratification"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "tumor-board-decision-support",
        "dir": "Articles",
        "previous_headings": "Specialized Oncology Applications",
        "what": "Tumor Board Decision Support",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "decision tree can assist multidisciplinary teams : - Risk Stratification: Categorize patients treatment urgency - Treatment Options: Rank interventions predicted benefit - Resource Planning: Allocate specialized care appropriately - Second Opinions: Provide objective analysis framework",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "biomarker-development-pipeline",
        "dir": "Articles",
        "previous_headings": "Specialized Oncology Applications",
        "what": "Biomarker Development Pipeline",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Support translational research : - Discovery: Identify promising biomarker combinations - Validation: Test performance across independent cohorts - Optimization: Determine optimal cutoff values - Implementation: Create clinical-ready algorithms",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-trial-design",
        "dir": "Articles",
        "previous_headings": "Specialized Oncology Applications",
        "what": "Clinical Trial Design",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Enhance study design : - Stratification: Balance treatment arms - Enrichment: Select likely responders - Adaptive Designs: Modify based interim results - Endpoint Selection: Choose clinically meaningful outcomes",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "model-performance-standards",
        "dir": "Articles",
        "previous_headings": "Quality Metrics for Clinical Implementation",
        "what": "Model Performance Standards",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Minimum Acceptable Performance: - Screening Applications: Sensitivity ≥ 0.85, NPV ≥ 0.95 - Diagnostic Applications: Specificity ≥ 0.85, PPV ≥ 0.80 - Prognostic Applications: C-index ≥ 0.70, Calibration slope 0.8-1.2 - Treatment Selection: Clinical utility > standard care"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "validation-requirements",
        "dir": "Articles",
        "previous_headings": "Quality Metrics for Clinical Implementation",
        "what": "Validation Requirements",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Internal Validation: - Cross-validation (k-fold ≥ 5) - Bootstrap validation (≥ 200 iterations) - Temporal validation (if longitudinal data)  External Validation: - Independent institution - Different population - Prospective cohort - Multi-center validation"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "performance-monitoring",
        "dir": "Articles",
        "previous_headings": "Quality Metrics for Clinical Implementation",
        "what": "Performance Monitoring",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Continuous Assessment: - Monthly performance reviews - Calibration drift detection - Distribution shift monitoring - Outcome feedback integration"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "algorithmic-fairness",
        "dir": "Articles",
        "previous_headings": "Ethical and Legal Considerations",
        "what": "Algorithmic Fairness",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Bias Assessment: Test across demographic subgroups Equity Metrics: Ensure fair performance across populations Representation: Validate underrepresented groups Transparency: Provide interpretable decision rationale",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-responsibility",
        "dir": "Articles",
        "previous_headings": "Ethical and Legal Considerations",
        "what": "Clinical Responsibility",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Human Oversight: Maintain physician final decision authority Error Handling: Clear protocols algorithm failures Documentation: Comprehensive decision audit trails Training: Adequate user education competency",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "regulatory-compliance",
        "dir": "Articles",
        "previous_headings": "Ethical and Legal Considerations",
        "what": "Regulatory Compliance",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "FDA 510(k): diagnostic device applications Clinical Evidence: Demonstrate clinical utility Risk Classification: Appropriate regulatory pathway Post-Market Surveillance: Ongoing safety monitoring",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "economic-evaluation-framework",
        "dir": "Articles",
        "previous_headings": "Cost-Effectiveness Analysis",
        "what": "Economic Evaluation Framework",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "",
        "code": "Cost Components: - Development and validation costs - Implementation and training costs - Ongoing maintenance and monitoring - Quality assurance and calibration  Benefit Components: - Improved diagnostic accuracy - Reduced unnecessary procedures - Earlier detection and treatment - Reduced healthcare utilization - Improved patient outcomes"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "return-on-investment-metrics",
        "dir": "Articles",
        "previous_headings": "Cost-Effectiveness Analysis",
        "what": "Return on Investment Metrics",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Cost per Quality-Adjusted Life Year (QALY) Number Needed Screen/Treat Incremental Cost-Effectiveness Ratio Budget Impact Analysis",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "technology-integration",
        "dir": "Articles",
        "previous_headings": "Future Directions",
        "what": "Technology Integration",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Electronic Health Records: Seamless clinical workflow integration Laboratory Information Systems: Automated biomarker input Imaging Systems: Multi-modal data fusion Mobile Health: Point--care decision support",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "methodological-advances",
        "dir": "Articles",
        "previous_headings": "Future Directions",
        "what": "Methodological Advances",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Federated Learning: Multi-institutional model development Continual Learning: Adaptive model updating Explainable AI: Enhanced interpretability methods Uncertainty Quantification: Confidence estimation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "clinical-applications-expansion",
        "dir": "Articles",
        "previous_headings": "Future Directions",
        "what": "Clinical Applications Expansion",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Rare Diseases: Specialized algorithms uncommon conditions Pediatric Oncology: Age-appropriate decision models Geriatric Care: Frailty-adjusted treatment decisions Global Health: Resource-constrained setting applications",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "model-development-1",
        "dir": "Articles",
        "previous_headings": "Best Practices Summary",
        "what": "Model Development",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Clinical Relevance First: Start clinical need, data availability Domain Expertise: Involve clinicians throughout development Appropriate Metrics: Use clinically meaningful performance measures Robust Validation: Multiple validation strategies cohorts Interpretability: Ensure clinical understanding trust",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "implementation-strategy",
        "dir": "Articles",
        "previous_headings": "Best Practices Summary",
        "what": "Implementation Strategy",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Pilot Testing: Start low-risk applications User Training: Comprehensive education programs Feedback Loops: Continuous improvement mechanisms Change Management: Address workflow integration challenges Performance Monitoring: Ongoing quality assurance",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "maintenance-and-evolution",
        "dir": "Articles",
        "previous_headings": "Best Practices Summary",
        "what": "Maintenance and Evolution",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Regular Updates: Incorporate new evidence data Performance Monitoring: Detect address model drift User Feedback: Integrate clinical experience Technology Updates: Leverage methodological advances Regulatory Compliance: Maintain appropriate approvals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/04-decision-tree-guide.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Medical Decision Tree - Clinical Implementation Guide",
        "text": "Medical Decision Tree module provides comprehensive framework developing, validating, implementing clinical decision support tools pathology oncology. focusing clinically relevant metrics, appropriate validation strategies, practical implementation considerations, bridges gap statistical modeling clinical practice. Success depends close collaboration data scientists, clinicians, healthcare administrators ensure technical capabilities align clinical needs operational realities. ultimate goal improve patient outcomes evidence-based, data-driven clinical decision support maintaining essential human elements medical care.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "introduction-to-decision-tree-graph-analysis",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction to Decision Tree Graph Analysis",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "vignette provides comprehensive guide using Decision Tree Graph module ClinicoPath package. module creates professional decision tree visualizations cost-effectiveness analysis typical decision nodes (squares), chance nodes (circles), terminal nodes (triangles).",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "key-features",
        "dir": "Articles",
        "previous_headings": "Introduction to Decision Tree Graph Analysis",
        "what": "Key Features",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Multiple Tree Types: Simple decision trees, Markov models, cost-effectiveness trees Node Visualization: Customizable shapes colors different node types Economic Analysis: Expected value calculations, ICERs, net benefit analysis Sensitivity Analysis: One-way sensitivity analysis tornado diagrams Flexible Layouts: Horizontal, vertical, radial tree orientations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "test-datasets",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Test Datasets",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "’ll use several comprehensive test datasets demonstrate features:",
        "code": "# Load test datasets data(\"basic_decision_data\")      # Basic treatment comparison data(\"markov_decision_data\")     # Markov model data   data(\"pharma_decision_data\")     # Drug comparison study data(\"screening_decision_data\")  # Screening program analysis data(\"minimal_test_data\")        # Simple functionality test data(\"edge_case_data\")          # Edge cases and error testing  # Display dataset summaries cat(\"Basic Decision Data:\", nrow(basic_decision_data), \"rows,\", ncol(basic_decision_data), \"columns\\n\") cat(\"Markov Decision Data:\", nrow(markov_decision_data), \"rows,\", ncol(markov_decision_data), \"columns\\n\") cat(\"Pharma Decision Data:\", nrow(pharma_decision_data), \"rows,\", ncol(pharma_decision_data), \"columns\\n\") cat(\"Screening Decision Data:\", nrow(screening_decision_data), \"rows,\", ncol(screening_decision_data), \"columns\\n\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "example-1-simple-treatment-comparison",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Example 1: Simple Treatment Comparison",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Let’s start basic treatment comparison using minimal test dataset:",
        "code": "# Examine the minimal test data structure head(minimal_test_data)  # This dataset contains: # - treatment: Decision variable (A vs B) # - prob1, prob2: Probability variables # - cost1, cost2: Cost variables   # - utility1, utility2: Utility variables # - outcome: Outcome variable"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "creating-a-basic-decision-tree",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples > Example 1: Simple Treatment Comparison",
        "what": "Creating a Basic Decision Tree",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# In jamovi, you would: # 1. Load the minimal_test_data # 2. Go to meddecide > Decision > Decision Tree Graph # 3. Set variables: #    - Decisions: treatment #    - Probabilities: prob1, prob2 #    - Costs: cost1, cost2 #    - Utilities: utility1, utility2 #    - Outcomes: outcome # 4. Choose layout: horizontal # 5. Enable: Show Probabilities, Show Costs, Show Utilities"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "example-2-pharmaceutical-cost-effectiveness-analysis",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Example 2: Pharmaceutical Cost-Effectiveness Analysis",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Using comprehensive pharmaceutical dataset:",
        "code": "# Examine pharmaceutical data structure head(pharma_decision_data)  # Key variables: # - drug_regimen: Main decision variable (4 treatment options) # - dosing_strategy: Secondary decision variable # - prob_response, prob_severe_ae: Probability variables # - cost_drug_per_cycle, cost_administration: Cost variables # - utility_response, utility_stable: Utility variables"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "advanced-configuration",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples > Example 2: Pharmaceutical Cost-Effectiveness Analysis",
        "what": "Advanced Configuration",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Advanced jamovi configuration: # 1. Decisions: drug_regimen, dosing_strategy # 2. Probabilities: prob_response, prob_severe_ae, prob_discontinuation # 3. Costs: cost_drug_per_cycle, cost_administration, cost_monitoring # 4. Utilities: utility_response, utility_stable, utility_progression # 5. Tree Type: Cost-Effectiveness Tree # 6. Layout: Horizontal # 7. Color Scheme: Medical Theme # 8. Enable Expected Values calculation # 9. Set discount rate: 3% # 10. Time horizon: 5 years"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "simple-decision-tree",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments > Tree Type Options",
        "what": "Simple Decision Tree",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Best basic treatment comparisons Minimal probability calculations Focus direct outcomes",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "markov-model-tree",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments > Tree Type Options",
        "what": "Markov Model Tree",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "multi-state disease progression Time-dependent transitions Suitable chronic diseases",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "cost-effectiveness-tree",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments > Tree Type Options",
        "what": "Cost-Effectiveness Tree",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Comprehensive economic evaluation ICER calculations Net benefit analysis",
        "code": "# Test each tree type with markov_decision_data:  # 1. Simple Decision Tree # - Focus on treatment_strategy decisions # - Use basic probabilities  # 2. Markov Model Tree   # - Include transition probabilities # - Multi-cycle analysis # - State-specific costs and utilities  # 3. Cost-Effectiveness Tree # - Full economic evaluation # - All cost components # - Utility measurements"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "layout-options-testing",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments",
        "what": "Layout Options Testing",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test all layout orientations:  # 1. Horizontal Layout (default) # - Tree flows left to right # - Decision node on left, outcomes on right # - Best for simple trees  # 2. Vertical Layout # - Tree flows top to bottom   # - Good for presentation slides # - Compact for wide trees  # 3. Radial Layout   # - Tree radiates from center # - Artistic presentation # - Good for complex trees with many branches"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "node-shape-configuration",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments > Display Options Testing",
        "what": "Node Shape Configuration",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test node shape options:  # 1. Show Node Shapes = TRUE (default) # - Squares for decision nodes # - Circles for chance nodes   # - Triangles for terminal nodes # - Clear visual distinction  # 2. Show Node Shapes = FALSE # - All nodes as circles # - Color coding only # - Simpler appearance"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "label-display-options",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments > Display Options Testing",
        "what": "Label Display Options",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test label configurations:  # 1. Show Probabilities = TRUE # - Display \"p=0.75\" on branches # - Help interpret chance outcomes # - Essential for probability assessment  # 2. Show Costs = TRUE   # - Display \"Cost: $15,000\" on terminal nodes # - Critical for cost-effectiveness # - Currency formatting  # 3. Show Utilities = TRUE # - Display \"Utility: 0.85\" on terminal nodes   # - Quality of life measures # - QALY calculations  # 4. Show Node Labels = TRUE # - Descriptive text on nodes # - Treatment names, outcome descriptions # - Improve interpretation  # 5. Show Branch Labels = TRUE # - Text on connecting lines # - Probability values, condition names # - Decision pathway clarity"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "color-scheme-testing",
        "dir": "Articles",
        "previous_headings": "Testing All Module Arguments",
        "what": "Color Scheme Testing",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test all color schemes:  # 1. Default Theme # - Green decisions, blue chance, orange terminals # - Standard clinical colors # - Good general purpose  # 2. Colorblind Friendly   # - Carefully selected colors # - Accessible to colorblind users # - High contrast options  # 3. Medical Theme # - Professional medical colors # - Suitable for clinical presentations # - Conservative appearance  # 4. Economic Theme # - Colors representing cost/benefit # - Green for savings, red for costs # - Financial analysis focus"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "expected-value-calculations",
        "dir": "Articles",
        "previous_headings": "Analysis Options Testing",
        "what": "Expected Value Calculations",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test expected value features:  # 1. Calculate Expected Values = TRUE # - Automatic cost and utility calculations # - Probability-weighted outcomes # - Decision tree rollback analysis  # Configuration with screening_decision_data: # - Multiple screening strategies # - Cost per test, diagnostic workup # - Utilities for different health states # - Life years gained calculations"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "sensitivity-analysis",
        "dir": "Articles",
        "previous_headings": "Analysis Options Testing",
        "what": "Sensitivity Analysis",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test sensitivity analysis options:  # 1. Sensitivity Analysis = TRUE # - One-way sensitivity analysis # - Parameter variation testing # - Robust decision making  # 2. Tornado Diagram = TRUE   # - Visual sensitivity results # - Parameters ranked by impact # - Range of outcomes displayed  # Using pharma_decision_data for sensitivity: # - Vary drug efficacy (prob_response) # - Vary cost parameters # - Vary utility values # - Assess decision robustness"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "economic-parameters",
        "dir": "Articles",
        "previous_headings": "Analysis Options Testing",
        "what": "Economic Parameters",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test economic parameter settings:  # 1. Discount Rate testing: # - 0% (no discounting) # - 3% (standard health economics) # - 5% (conservative approach) # - 7% (high discount rate)  # 2. Time Horizon testing: # - 1 year (short-term analysis) # - 5 years (medium-term) # - 10 years (long-term) # - Lifetime (maximum horizon)  # Impact on net present value calculations # Future cost and benefit discounting"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "summary-table-features",
        "dir": "Articles",
        "previous_headings": "Output Tables Testing",
        "what": "Summary Table Features",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test summary table with basic_decision_data:  # Summary Table includes: # - Strategy names # - Expected costs (discounted) # - Expected utilities (QALYs) # - Incremental Cost-Effectiveness Ratios (ICERs) # - Net benefit at willingness-to-pay thresholds  # Currency formatting for costs # Decimal precision for utilities   # ICER calculation accuracy"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "node-details-table",
        "dir": "Articles",
        "previous_headings": "Output Tables Testing",
        "what": "Node Details Table",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test node details table:  # Node Table includes: # - Node ID (unique identifier) # - Node Type (decision/chance/terminal) # - Node Label (descriptive text) # - Probability values # - Cost values   # - Utility values  # Useful for: # - Debugging tree structure # - Verifying calculations # - Detailed documentation"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "sensitivity-analysis-table",
        "dir": "Articles",
        "previous_headings": "Output Tables Testing",
        "what": "Sensitivity Analysis Table",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test sensitivity analysis table:  # Sensitivity Table includes: # - Parameter names # - Base case values # - Low/high range values # - Low/high results # - Range of impact  # Parameter ranking by importance # Threshold analysis capability # Scenario analysis support"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "missing-data-testing",
        "dir": "Articles",
        "previous_headings": "Edge Cases and Error Handling",
        "what": "Missing Data Testing",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test with edge_case_data containing missing values head(edge_case_data)  # Edge cases include: # - Missing treatment assignments # - Zero probabilities   # - Negative costs # - Utilities outside 0-1 range # - Single category variables # Test error handling:  # 1. Missing Required Variables # - No decision variables specified # - No cost or utility data # - Expected: Informative error message  # 2. Invalid Probability Values # - Probabilities < 0 or > 1 # - Expected: Data validation warning  # 3. Negative Costs # - Cost values < 0 # - Expected: Warning or automatic correction  # 4. Invalid Utility Values   # - Utilities < 0 or > 1 # - Expected: Range validation  # 5. Insufficient Data # - Fewer than 2 decision options # - Expected: Minimum data requirement message"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "large-dataset-handling",
        "dir": "Articles",
        "previous_headings": "Performance Testing",
        "what": "Large Dataset Handling",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test with large datasets:  # 1. Markov data (200 scenarios) # - Complex multi-state model # - Many transition probabilities # - State-specific costs/utilities  # 2. Screening data (120 scenarios)   # - Multiple screening strategies # - Population-specific parameters # - Test performance characteristics  # Performance metrics: # - Tree generation time # - Plot rendering speed # - Memory usage # - Table population speed"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "complex-tree-structures",
        "dir": "Articles",
        "previous_headings": "Performance Testing",
        "what": "Complex Tree Structures",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Test complex tree configurations:  # 1. Multiple Decision Variables # - Primary and secondary decisions # - Nested decision structures   # - Interaction effects  # 2. Many Outcome Branches # - Multiple chance nodes # - Numerous terminal outcomes # - Complex probability trees  # 3. Deep Tree Hierarchies # - Multi-level decisions # - Sequential choices # - Time-dependent paths"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "validation-against-manual-calculations",
        "dir": "Articles",
        "previous_headings": "Comparison with Other Methods",
        "what": "Validation Against Manual Calculations",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Validate expected value calculations:  # Manual calculation example with minimal_test_data: # Treatment A: # - Expected Cost = (prob1 * cost1) + (prob2 * cost2)   # - Expected Utility = (prob1 * utility1) + (prob2 * utility2)  # Treatment B: # - Similar calculations # - Compare with module output  # ICER calculation: # - (Cost_B - Cost_A) / (Utility_B - Utility_A) # - Verify against summary table"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "sensitivity-analysis-validation",
        "dir": "Articles",
        "previous_headings": "Comparison with Other Methods",
        "what": "Sensitivity Analysis Validation",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Validate sensitivity analysis:  # 1. One-way sensitivity # - Manually vary single parameters # - Compare impact on outcomes # - Verify tornado diagram rankings  # 2. Two-way sensitivity   # - Vary two parameters simultaneously # - Create sensitivity matrices # - Identify interaction effects  # 3. Probabilistic sensitivity # - Monte Carlo simulation # - Parameter uncertainty modeling # - Confidence interval generation"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "data-preparation",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Data Preparation",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Variable Naming: Use descriptive names clarity Data Validation: Check ranges missing values Probability Constraints: Ensure probabilities sum 1 Cost Standardization: Use consistent currency time periods Utility Scales: Maintain 0-1 range utilities",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "analysis-configuration",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Analysis Configuration",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Tree Type Selection: Match complexity analysis needs Layout Choice: Consider audience presentation format Display Options: Balance detail clarity Economic Parameters: Use standard discount rates Sensitivity Analysis: Include key uncertain parameters",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "interpretation-guidelines",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations",
        "what": "Interpretation Guidelines",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Expected Values: Focus central estimates ICERs: Consider cost-effectiveness thresholds Sensitivity Results: Assess decision robustness Uncertainty: Acknowledge parameter limitations Clinical Relevance: Ensure practical applicability",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "data-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues",
        "what": "Data Issues",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Common problems and solutions:  # 1. \"No data provided for analysis\" # Solution: Check data loading and variable selection  # 2. \"Missing required variables\"   # Solution: Specify at least one decision, cost, or utility variable  # 3. Probabilities don't sum to 1 # Solution: Normalize probability variables  # 4. Negative costs or utilities # Solution: Check data entry and transformations  # 5. Tree too complex to display # Solution: Simplify structure or use subsets"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "visualization-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues",
        "what": "Visualization Issues",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Visualization problems:  # 1. Overlapping node labels # Solution: Reduce label length or change layout  # 2. Tree too wide/tall # Solution: Adjust layout orientation  # 3. Colors not distinguishable   # Solution: Change color scheme  # 4. Missing plot elements # Solution: Check display option settings  # 5. Poor plot quality # Solution: Adjust figure dimensions"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "multi-criteria-decision-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Multi-Criteria Decision Analysis",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Incorporate multiple decision criteria:  # 1. Cost-effectiveness # 2. Safety profiles   # 3. Patient preferences # 4. Implementation feasibility # 5. Equity considerations  # Weight different criteria # Composite scoring systems # Stakeholder involvement"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "budget-impact-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Budget Impact Analysis",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "",
        "code": "# Extend to budget impact:  # 1. Population-level costs # 2. Implementation timelines # 3. Resource requirements # 4. Capacity constraints # 5. Affordability thresholds  # Multi-year projections # Scenario modeling # Policy implications"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/05-decision-tree-analysis.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Decision Tree Graph Analysis: Comprehensive Guide and Testing",
        "text": "Decision Tree Graph module provides comprehensive toolkit cost-effectiveness analysis healthcare. Key strengths include: Flexibility: Multiple tree types configurations Visual Appeal: Professional publication-ready graphics Economic Rigor: Standard health economics calculations User-Friendly: Intuitive jamovi interface Comprehensive Output: Tables, plots, sensitivity analysis vignette demonstrated extensive testing across various scenarios, data types, configuration options. module handles simple complex decision problems maintaining computational efficiency visual clarity. additional support examples, consult ClinicoPath documentation consider specific requirements decision analysis context. Note: vignette demonstrates capabilities testing approaches Decision Tree Graph module. Actual analysis results depend specific data research questions. Always validate calculations interpretations within clinical economic context.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "guide explains use Decision Trees vs Markov Chain Models medical decision analysis cost-effectiveness research. methods implemented ClinicoPath jamovi module.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "what-is-a-decision-tree",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis",
        "what": "What is a Decision Tree?",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "decision tree graphical representation decision problem maps : Decision nodes (squares): Choice points decisions made Chance nodes (circles): Probabilistic events beyond control Terminal nodes (triangles): Final outcomes associated costs utilities",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "example-acute-appendicitis-treatment",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis",
        "what": "Example: Acute Appendicitis Treatment",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Clinical Question: patient suspected appendicitis receive immediate surgery conservative treatment?",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "decision-tree-structure",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis > Example: Acute Appendicitis Treatment",
        "what": "Decision Tree Structure",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "",
        "code": "DECISION NODE (□): Treatment Choice ├── Surgery (immediate) │   ├── CHANCE NODE (○): Surgery Outcome   │   │   ├── Success (96%) → TERMINAL (△): Cost $12,000, Utility 0.95 │   │   └── Complications (4%) → TERMINAL (△): Cost $20,000, Utility 0.85 │    └── Conservative Treatment     ├── CHANCE NODE (○): Conservative Outcome     │   ├── Success (70%) → TERMINAL (△): Cost $3,000, Utility 0.90       │   └── Failure (30%) → Emergency Surgery → TERMINAL (△): Cost $18,000, Utility 0.75"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "results-interpretation",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis > Example: Acute Appendicitis Treatment",
        "what": "Results Interpretation",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "ICER (Incremental Cost-Effectiveness Ratio): Incremental Cost: $4,861 Incremental Utility: 0.094 QALYs ICER: $51,744 per QALY",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "clinical-interpretation",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis > Example: Acute Appendicitis Treatment",
        "what": "Clinical Interpretation",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Surgery costs $4,861 provides 0.094 additional QALYs $51,744/QALY, surgery marginally cost-effective (threshold typically $50,000-$100,000/QALY) Recommendation: Consider patient-specific factors (age, comorbidities, preferences)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "what-is-a-markov-chain-model",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis",
        "what": "What is a Markov Chain Model?",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Markov model tracks population different health states time, : Patients can transition states cycle (e.g., annually) Transition probabilities depend current state (history) state associated costs quality life values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "example-chronic-heart-disease-management",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis",
        "what": "Example: Chronic Heart Disease Management",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Clinical Question: long-term cost-effectiveness different heart disease management strategies 20 years?",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "markov-states",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis > Example: Chronic Heart Disease Management",
        "what": "Markov States",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Asymptomatic Heart Disease Symptomatic Heart Disease Heart Failure Death (absorbing state)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "transition-matrix-standard-care",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis > Example: Chronic Heart Disease Management",
        "what": "Transition Matrix (Standard Care)",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "",
        "code": "From/To          Asymptomatic  Symptomatic  Heart Failure  Death Asymptomatic         88.4%        10.0%         0.0%       1.5% Symptomatic           0.0%        77.2%        19.8%       3.0% Heart Failure         0.0%         0.0%        84.5%      15.5% Death                 0.0%         0.0%         0.0%     100.0%"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "cost-effectiveness-results-20-years",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis > Example: Chronic Heart Disease Management",
        "what": "Cost-Effectiveness Results (20 years)",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Total Lifetime Cost: $120,561 Total Lifetime QALYs: 8.39 Cost per QALY: $14,370",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "clinical-interpretation-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis > Example: Chronic Heart Disease Management",
        "what": "Clinical Interpretation",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Standard care provides good value $14,370/QALY (well cost-effectiveness threshold) 68% patients die within 20 years, highlighting disease severity Peak heart failure prevalence occurs around year 15 (20.7%) Early intervention may valuable given rapid disease progression",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "decision-tree-applications",
        "dir": "Articles",
        "previous_headings": "When to Use Each Method",
        "what": "Decision Tree Applications",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Best : ✅ Acute conditions (appendicitis, trauma, infections) ✅ One-time decisions (surgery vs. medication) ✅ Short-term outcomes (days months) ✅ Simple comparisons (2-3 treatment options) ✅ Emergency decisions immediate consequences Examples: patient get emergency surgery? diagnostic test ordered? vaccinate population? screening cost-effective age group?",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "markov-chain-applications",
        "dir": "Articles",
        "previous_headings": "When to Use Each Method",
        "what": "Markov Chain Applications",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Best : ✅ Chronic diseases (diabetes, heart disease, cancer) ✅ Long-term analysis (years lifetime) ✅ Disease progression modeling ✅ Complex interventions ongoing effects ✅ Policy decisions affecting populations Examples: ’s lifetime value diabetes management? cost-effective cancer screening programs? implement population-wide interventions? ’s optimal timing treatment intensification?",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "data-setup",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Decision Trees in jamovi",
        "what": "Data Setup",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Variables needed: Decision variables (treatment options) Probability variables (success rates, complication rates) Cost variables (treatment costs, complication costs) Utility variables (quality life outcomes)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "analysis-steps",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Decision Trees in jamovi",
        "what": "Analysis Steps",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Select “Decision Tree” type Assign variables appropriate roles Configure display options (show probabilities, costs, utilities) Run analysis interpret expected values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "key-outputs",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Decision Trees in jamovi",
        "what": "Key Outputs",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Tree visualization showing decision structure Expected values table costs utilities ICER calculations cost-effectiveness Sensitivity analysis (optional)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "data-setup-1",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Markov Chains in jamovi",
        "what": "Data Setup",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Variables needed: Health state variables (disease stages) Transition probability variables (states) State-specific costs (annual costs per state) State-specific utilities (quality life per state) Time parameters (cycle length, time horizon)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "analysis-steps-1",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Markov Chains in jamovi",
        "what": "Analysis Steps",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Select “Markov Model” type Define health states transition probabilities Set time horizon cycle length Configure discounting (typically 3-5% annually) Run cohort simulation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "key-outputs-1",
        "dir": "Articles",
        "previous_headings": "Practical Implementation Guide > Using Markov Chains in jamovi",
        "what": "Key Outputs",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Transition matrix showing movement states Cohort trace showing population time Cost-effectiveness results lifetime totals State transition plots visualizing progression",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "cost-effectiveness-metrics",
        "dir": "Articles",
        "previous_headings": "Key Concepts and Interpretation",
        "what": "Cost-Effectiveness Metrics",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "ICER (Incremental Cost-Effectiveness Ratio): < $50,000/QALY: Generally cost-effective $50,000-$100,000/QALY: Moderately cost-effective > $100,000/QALY: cost-effective (U.S. standards) Net Benefit: Positive values indicate cost-effectiveness Easier compare multiple strategies",
        "code": "ICER = (Cost_A - Cost_B) / (Effect_A - Effect_B) Net Benefit = (Utility × WTP_Threshold) - Cost"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "quality-measures",
        "dir": "Articles",
        "previous_headings": "Key Concepts and Interpretation",
        "what": "Quality Measures",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "QALYs (Quality-Adjusted Life Years): Combines quantity quality life 1.0 = perfect health one year 0.0 = death health state equivalent death Allows comparison across different conditions Utilities: 1.0 = Perfect health 0.8-0.9 = Mild symptoms/limitations 0.6-0.8 = Moderate impairment 0.4-0.6 = Severe limitations < 0.4 = poor quality life",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "time-considerations",
        "dir": "Articles",
        "previous_headings": "Key Concepts and Interpretation",
        "what": "Time Considerations",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Discounting: Future costs benefits worth less present ones Standard rates: 3-5% annually Applied costs utilities important long-term Markov models Time Horizon: Decision trees: Usually < 1 year Markov models: Often lifetime 10-50 years capture relevant long-term effects",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "combined-approaches",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Combined Approaches",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "complex problems benefit methods: Initial Decision Tree: Choose immediate treatment Subsequent Markov Model: Model long-term consequences Example: Cancer Treatment Decision tree: Surgery vs. chemotherapy vs. radiation Markov model: Long-term survival quality life",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "sensitivity-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Sensitivity Analysis",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "One-way sensitivity analysis: Vary one parameter time Show impact cost-effectiveness Identify key drivers results Probabilistic sensitivity analysis: Vary parameters simultaneously Account uncertainty inputs Provide confidence intervals results",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "advanced-markov-features",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Advanced Markov Features",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "State rewards: Costs/utilities accumulated states vs. transition rewards (one-time costs/utilities) Tunnel states: Temporary states time-dependent properties Useful modeling treatment effects Multiple cohorts: Compare different starting populations Analyze subgroup differences",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Key Takeaways",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Decision trees excel acute, one-time decisions short-term outcomes Markov chains essential chronic disease management long-term policy analysis methods provide rigorous economic evaluation healthcare decisions Cost-effectiveness thresholds help interpret results policy context Sensitivity analysis crucial understanding result robustness",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Next Steps",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "Practice provided example datasets Apply methods specific research questions Consider combining approaches complex problems Validate results clinical experts Present findings using quantitative results visual representations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-decision-tree-vs-markov.html",
        "id": "resources",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Resources",
        "title": "Decision Tree vs Markov Chain Analysis: Complete Guide",
        "text": "ClinicoPath jamovi module documentation Example datasets: appendicitis_decision_tree.csv, heart_disease_markov.csv Comprehensive test data data/ directory Detailed vignettes step--step examples guide provides foundation understanding implementing decision tree Markov chain analyses clinical research health economics. methods powerful tools evidence-based decision making healthcare.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "vignette provides step--step workflows using generated datasets jamovi ClinicoPath decision analysis modules.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-1-open-jamovi-and-import-data",
        "dir": "Articles",
        "previous_headings": "Load Data in jamovi",
        "what": "Step 1: Open jamovi and Import Data",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Open jamovi File → Open → Browse : appendicitis_decision_tree.csv (decision tree) heart_disease_markov.csv (Markov chain) use test datasets inst/extdata/",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-1-navigate-to-analysis",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 1: Navigate to Analysis",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Navigate : ClinicoPath → meddecide → Decision → Decision Tree Graph",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-2-configure-variables",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 2: Configure Variables",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Configure following variables: Decision Nodes: treatment_choice Probability Variables: prob_surgery_success, prob_conservative_success Cost Variables: cost_surgery, cost_conservative, cost_complications Utility Variables: utility_success, utility_minor_complications Outcome Variables: clinical_outcome",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-3-set-tree-structure",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 3: Set Tree Structure",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Tree Type: Cost-Effectiveness Tree Layout: Horizontal (Left Right)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-4-configure-display-options",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 4: Configure Display Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Enable following options: ☑ Show Node Shapes ☑ Show Probabilities ☑ Show Costs ☑ Show Utilities ☑ Show Node Labels ☑ Show Branch Labels Color Scheme: Medical Theme",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-5-configure-analysis-options",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 5: Configure Analysis Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "☑ Calculate Expected Values Sensitivity Analysis (optional) Discount Rate: 3% Time Horizon: 1 year",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-6-configure-output-options",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow > Using: appendicitis_decision_tree.csv",
        "what": "Step 6: Configure Output Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "☑ Summary Table Tornado Diagram (sensitivity analysis enabled)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "expected-decision-tree-results",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow",
        "what": "Expected Decision Tree Results",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "analysis produce: Decision tree visualization nodes branches Strategy: Surgery vs Conservative Expected Cost: ~$12,315 vs ~$7,454 Expected Utility: ~0.989 vs ~0.895 QALYs ICER: ~$51,744 per QALY Net Benefit: Varies WTP threshold",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "clinical-interpretation",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Workflow",
        "what": "Clinical Interpretation",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Surgery costs $4,861 provides 0.094 additional QALYs ICER $51,744/QALY suggests surgery marginally cost-effective Decision depends patient factors willingness--pay threshold",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-1-navigate-to-analysis-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 1: Navigate to Analysis",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Navigate : ClinicoPath → meddecide → Decision → Decision Tree Graph",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-2-configure-variables-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 2: Configure Variables",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Configure following variables: Decision Nodes: management_strategy Health States: management_strategy (create state variable) Transition Probabilities: prob_asymp_to_symp, prob_symp_to_hf, prob_hf_to_death Cost Variables: cost_asymptomatic, cost_symptomatic, cost_heart_failure Utility Variables: utility_asymptomatic, utility_symptomatic, utility_heart_failure",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-3-set-tree-structure-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 3: Set Tree Structure",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Tree Type: Markov Model Tree Layout: Horizontal (Left Right)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-4-configure-markov-options",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 4: Configure Markov Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Cycle Length: 1 year Time Horizon: 20 years",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-5-configure-analysis-options-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 5: Configure Analysis Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "☑ Calculate Expected Values Discount Rate: 3% Time Horizon: 20 years",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-6-configure-output-options-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow > Using: heart_disease_markov.csv",
        "what": "Step 6: Configure Output Options",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "☑ Summary Table ☑ Cohort Trace Plot ☑ Transition Matrix",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "expected-markov-results",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow",
        "what": "Expected Markov Results",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "analysis produce: Markov Transition Matrix showing probabilities states Year 0: 100% Asymptomatic Year 5: 54% Asymptomatic, 24% Symptomatic, 12% Heart Failure, 11% Dead Year 20: 9% Asymptomatic, 7% Symptomatic, 16% Heart Failure, 68% Dead Total Lifetime Cost: ~$120,561 Total Lifetime QALYs: ~8.39 Cost per QALY: ~$14,370 Markov State Transitions plot showing progression time",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "clinical-interpretation-1",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Workflow",
        "what": "Clinical Interpretation",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Standard care provides good value $14,370/QALY Disease progression shows 68% mortality 20 years Peak heart failure prevalence around year 15 Results support cost-effectiveness standard care",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "for-decision-trees",
        "dir": "Articles",
        "previous_headings": "Comparing Strategies",
        "what": "For Decision Trees",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Compare expected values Summary Table Look dominant strategies (lower cost, higher utility) Calculate ICERs non-dominated strategies Use sensitivity analysis test robustness",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "for-markov-models",
        "dir": "Articles",
        "previous_headings": "Comparing Strategies",
        "what": "For Markov Models",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Run separate analyses strategy Compare lifetime costs QALYs Calculate incremental cost-effectiveness ratios Examine cohort traces understand disease progression",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-1-enable-sensitivity-analysis",
        "dir": "Articles",
        "previous_headings": "Sensitivity Analysis",
        "what": "Step 1: Enable Sensitivity Analysis",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Enable ‘Sensitivity Analysis’ Analysis Options Enable ‘Tornado Diagram’ Output Options",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "step-2-review-results",
        "dir": "Articles",
        "previous_headings": "Sensitivity Analysis",
        "what": "Step 2: Review Results",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Results show: Parameter ranges impact outcomes Tornado diagram ranking parameters influence Threshold values conclusions change",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "key-metrics-to-report",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Key Metrics to Report",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Expected costs (confidence intervals) Expected utilities/QALYs ICERs interpretation vs. thresholds Net benefit relevant WTP thresholds Sensitivity analysis results",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "cost-effectiveness-thresholds",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Cost-Effectiveness Thresholds",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "< $50,000/QALY: Highly cost-effective $50,000-$100,000/QALY: Moderately cost-effective > $100,000/QALY: cost-effective (US standards) Thresholds vary country healthcare system",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "include-in-publications",
        "dir": "Articles",
        "previous_headings": "Reporting Results",
        "what": "Include in Publications",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Methods: Model structure, data sources, assumptions Results: Base-case cost-effectiveness results Sensitivity analysis: Key drivers uncertainty Limitations: Model assumptions data limitations Conclusions: Policy implications recommendations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "visual-elements",
        "dir": "Articles",
        "previous_headings": "Reporting Results",
        "what": "Visual Elements",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "Decision tree Markov model diagram Cost-effectiveness plane (cost vs. utility) Tornado diagram (sensitivity analysis) Cohort trace plot (Markov models)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "example-test-datasets-available",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Example Test Datasets Available",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "following datasets available practice: basic_decision_data.csv - Simple treatment comparison markov_decision_data.csv - Multi-state disease progression pharma_decision_data.csv - Drug comparison study screening_decision_data.csv - Cancer screening programs minimal_test_data.csv - Basic functionality testing edge_case_data.csv - Error handling edge cases appendicitis_decision_tree.csv - Acute treatment decision heart_disease_markov.csv - Chronic disease management datasets located : inst/extdata/ Load files jamovi practice analysis workflows.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "workflow-summary",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Workflow Summary",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "workflow covers: ✓ Data import preparation ✓ Decision tree analysis configuration ✓ Markov chain analysis setup ✓ Result interpretation reporting ✓ Sensitivity analysis implementation ✓ Clinical policy interpretation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "additional-help",
        "dir": "Articles",
        "previous_headings": "Workflow Summary",
        "what": "Additional Help",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "additional assistance: Review decision-tree-vs-markov-analysis.Rmd vignette Check comprehensive vignettes vignettes/ Examine test data generation scripts data-raw/ Consult jamovi module documentation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/06-jamovi-workflow-examples.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Jamovi Workflow Examples for Decision Tree and Markov Analysis",
        "text": "now ready perform sophisticated decision analysis cost-effectiveness research jamovi using ClinicoPath module! workflows demonstrated vignette provide systematic approach : Setting decision tree Markov chain analyses Configuring appropriate variables parameters Interpreting cost-effectiveness results Conducting sensitivity analyses Reporting findings clinical policy applications Practice provided example datasets build proficiency powerful analytical methods.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "introduction-to-decision-curve-analysis",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction to Decision Curve Analysis",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Decision Curve Analysis (DCA) powerful method evaluating clinical utility prediction models diagnostic tests. Unlike traditional performance metrics (sensitivity, specificity, AUC), DCA directly addresses question: “using model lead better clinical decisions?”",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "clinical-utility-focus",
        "dir": "Articles",
        "previous_headings": "Introduction to Decision Curve Analysis > What Makes This Analysis Special?",
        "what": "Clinical Utility Focus",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Moves beyond discrimination metrics real-world decision making Incorporates relative harm false positives vs false negatives Provides threshold-specific guidance clinical decisions Quantifies net clinical benefit across decision thresholds",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "bayesian-enhancement",
        "dir": "Articles",
        "previous_headings": "Introduction to Decision Curve Analysis > What Makes This Analysis Special?",
        "what": "Bayesian Enhancement",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Uncertainty quantification posterior distributions Credible intervals net benefit estimates Probability superiority competing strategies Expected Value Perfect Information (EVPI) research prioritization",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "when-to-use-decision-curve-analysis",
        "dir": "Articles",
        "previous_headings": "Introduction to Decision Curve Analysis",
        "what": "When to Use Decision Curve Analysis",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Perfect : - Evaluating prediction models clinical implementation - Comparing diagnostic tests different cost-benefit profiles - Determining optimal decision thresholds interventions - Assessing value additional biomarkers clinical variables - Health economic evaluation diagnostic strategies Examples: - implement cancer screening model practice? - probability threshold recommend treatment? - expensive biomarker worth additional cost? - prediction model provides clinical benefit?",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "the-net-benefit-framework",
        "dir": "Articles",
        "previous_headings": "Theoretical Foundation",
        "what": "The Net Benefit Framework",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Decision Curve Analysis based net benefit metric: NB=Sensitivity×Prevalence−False Positive Rate×(1−Prevalence)×pt1−ptNB = \\text{Sensitivity} \\times \\text{Prevalence} - \\text{False Positive Rate} \\times (1-\\text{Prevalence}) \\times \\frac{p_t}{1-p_t} : - Sensitivity: True positive rate test/model - Prevalence: Disease prevalence population - ptp_t: Decision threshold (probability intervene) - pt1−pt\\frac{p_t}{1-p_t}: Odds ratio representing relative harm false positives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "understanding-decision-thresholds",
        "dir": "Articles",
        "previous_headings": "Theoretical Foundation",
        "what": "Understanding Decision Thresholds",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "decision threshold represents probability clinician recommend intervention: Low thresholds (1-5%): Used missing disease harmful (e.g., cancer screening) Medium thresholds (10-20%): Balanced scenarios (e.g., cardiac interventions) High thresholds (30-50%): Used intervention significant risks (e.g., major surgery)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "load-required-libraries",
        "dir": "Articles",
        "previous_headings": "Getting Started",
        "what": "Load Required Libraries",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "library(meddecide) library(dplyr) library(ggplot2)  # Use the histopathology dataset for examples data(\"histopathology\") mydata <- histopathology  # Display basic dataset information cat(\"Dataset dimensions:\", nrow(mydata), \"rows ×\", ncol(mydata), \"columns\\n\") ## Dataset dimensions: 250 rows × 38 columns cat(\"Outcome variable 'Death':\", table(mydata$Death), \"\\n\") ## Outcome variable 'Death': 169 80 cat(\"Available predictors:\", paste(c(\"Age\", \"Grade\", \"TStage\", \"MeasurementA\", \"MeasurementB\"), collapse = \", \"), \"\\n\") ## Available predictors: Age, Grade, TStage, MeasurementA, MeasurementB"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "basic-workflow-overview",
        "dir": "Articles",
        "previous_headings": "Getting Started",
        "what": "Basic Workflow Overview",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Bayesian DCA workflow follows steps: Define Binary Outcome: Select outcome variable (0/1 factor) Select Predictors: Choose models/tests evaluate (continuous probabilities binary results) Set Thresholds: Define clinically relevant decision threshold range Choose Analysis Type: Bayesian (uncertainty) Frequentist (bootstrap CI) Interpret Results: Evaluate net benefit, probability superiority, EVPI",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-1-basic-bayesian-decision-curve-analysis",
        "dir": "Articles",
        "previous_headings": "Core Analysis Examples",
        "what": "Example 1: Basic Bayesian Decision Curve Analysis",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Let’s evaluate whether age tumor measurements can guide treatment decisions cancer patients. get: - Net benefit curves credible intervals - Probability strategy optimal - Strategy comparison across thresholds - Comprehensive statistical tables",
        "code": "# Basic Bayesian DCA comparing age and measurements as predictors bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = c(\"Age\", \"MeasurementA\", \"MeasurementB\"),   thresholdMin = 0.05,     # 5% minimum threshold   thresholdMax = 0.40,     # 40% maximum threshold   thresholdPoints = 30,    # 30 evaluation points   bayesianAnalysis = TRUE,   nDraws = 2000,          # Number of posterior draws   priorStrength = 2       # Weak prior )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-2-frequentist-analysis-with-bootstrap",
        "dir": "Articles",
        "previous_headings": "Core Analysis Examples",
        "what": "Example 2: Frequentist Analysis with Bootstrap",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "comparison, run analysis using frequentist methods: Differences: - Bootstrap confidence intervals instead credible intervals - probability statements superiority - EVPI calculations available",
        "code": "# Frequentist DCA with bootstrap confidence intervals bayesdca(   data = mydata,   outcomes = \"Death\",    predictors = c(\"Age\", \"MeasurementA\", \"MeasurementB\"),   thresholdMin = 0.05,   thresholdMax = 0.40,   thresholdPoints = 30,   bayesianAnalysis = FALSE,  # Use frequentist approach   bootstrapCI = TRUE,   bootstrapReps = 2000      # Bootstrap replications )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-3-binary-diagnostic-test-evaluation",
        "dir": "Articles",
        "previous_headings": "Core Analysis Examples",
        "what": "Example 3: Binary Diagnostic Test Evaluation",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Evaluate binary test results (e.g., imaging findings, genetic markers): Binary Test Features: - Tests applied directly without threshold cutoffs - Results show performance different decision thresholds - Useful imaging findings, genetic tests, lab markers",
        "code": "# Convert measurements to binary tests for demonstration mydata_binary <- mydata %>%   mutate(     HighMeasurementA = ifelse(MeasurementA > median(MeasurementA, na.rm = TRUE), 1, 0),     PositiveGrade = ifelse(Grade %in% c(\"High\"), 1, 0)   )  # Analyze binary diagnostic tests bayesdca(   data = mydata_binary,   outcomes = \"Death\",   predictors = c(\"HighMeasurementA\", \"PositiveGrade\"),   thresholdMin = 0.10,   thresholdMax = 0.50,   bayesianAnalysis = TRUE,   nDraws = 2000 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-4-external-prevalence-adjustment",
        "dir": "Articles",
        "previous_headings": "Core Analysis Examples",
        "what": "Example 4: External Prevalence Adjustment",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "study population differs target population: Use: - Study cohort different characteristics target population - Registry data provides better prevalence estimates - Multi-site validation varying prevalence",
        "code": "# Use external prevalence data (e.g., from registry) bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = c(\"Age\", \"MeasurementA\"),   thresholdMin = 0.05,   thresholdMax = 0.35,   useExternalPrevalence = TRUE,   externalCases = 150,      # Known cases in target population   externalTotal = 1000,     # Total target population   bayesianAnalysis = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "expected-value-of-perfect-information-evpi",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Expected Value of Perfect Information (EVPI)",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "EVPI quantifies maximum value conducting additional research reduce uncertainty: EVPI Interpretation: - High EVPI: Additional research valuable - Low EVPI: Current evidence sufficient decision making - Peak EVPI: Threshold ranges research valuable - Zero EVPI: Perfect certainty optimal strategy",
        "code": "# Full analysis with EVPI calculation bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = c(\"Age\", \"MeasurementA\", \"MeasurementB\", \"TStage\"),   thresholdMin = 0.05,   thresholdMax = 0.40,   bayesianAnalysis = TRUE,   calculateEVPI = TRUE,    # Enable EVPI calculation   nDraws = 3000           # More draws for stable EVPI )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "direction-control-for-predictors",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Direction Control for Predictors",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Control continuous predictors interpreted: Direction Options: - “>=”: Higher values indicate positive outcome (default) - “<=”: Lower values indicate positive outcome",
        "code": "# For biomarkers where LOWER values indicate risk bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = \"MeasurementB\",   directionIndicator = \"<=\",  # Lower values = positive prediction   thresholdMin = 0.10,   thresholdMax = 0.40,   bayesianAnalysis = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "prior-strength-sensitivity-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Prior Strength Sensitivity Analysis",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Explore impact different prior specifications: Prior Strength Guide: - 0.5-2: weak prior (data-driven) - 2-5: Weak prior (default range) - 5-10: Moderate prior (conservative) - >10: Strong prior (conservative)",
        "code": "# Weak prior (default) bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = \"Age\",   priorStrength = 2,      # Weak prior   bayesianAnalysis = TRUE )  # Strong prior (more conservative) bayesdca(   data = mydata,   outcomes = \"Death\",    predictors = \"Age\",   priorStrength = 10,     # Strong prior   bayesianAnalysis = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "scenario-cancer-treatment-decision-model",
        "dir": "Articles",
        "previous_headings": "Comprehensive Clinical Example",
        "what": "Scenario: Cancer Treatment Decision Model",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Let’s work complete analysis cancer treatment decision model:",
        "code": "# Comprehensive cancer treatment decision analysis cancer_dca <- bayesdca(   data = mydata,      # Core variables   outcomes = \"Death\",   predictors = c(\"Age\", \"TStage\", \"MeasurementA\", \"MeasurementB\"),      # Threshold settings (5% to 40% - typical for cancer treatment)   thresholdMin = 0.05,   thresholdMax = 0.40,   thresholdPoints = 35,      # Bayesian analysis with EVPI   bayesianAnalysis = TRUE,   nDraws = 3000,   priorStrength = 2,   calculateEVPI = TRUE,      # External prevalence (if applicable)   useExternalPrevalence = FALSE,      # Classification direction   directionIndicator = \">=\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "interpreting-the-results",
        "dir": "Articles",
        "previous_headings": "Comprehensive Clinical Example > Scenario: Cancer Treatment Decision Model",
        "what": "Interpreting the Results",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "1. Main Decision Curves: - Shows net benefit strategy across thresholds - Curves “treat none” “treat ” indicate clinical utility - Higher curves = better clinical performance 2. Net Benefit Differences: - Shows improvement default strategies (treat /none) - Positive values indicate beneficial use model - Confidence bands show uncertainty benefit 3. Probability Superiority: - Bayesian probability strategy optimal - Helps identify threshold ranges models reliable - Values >80% suggest strong evidence superiority 4. Expected Value Perfect Information: - Maximum benefit reducing uncertainty research - High EVPI suggests value additional studies - Can inform research prioritization funding decisions",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "core-parameters",
        "dir": "Articles",
        "previous_headings": "Parameter Reference Guide",
        "what": "Core Parameters",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "bayesdca(   data = mydata,                    # Required: Data frame      # Required variables   outcomes = \"Death\",               # Binary outcome (0/1 or factor)   outcomePos = \"Yes\",              # Positive level (if factor)   predictors = c(\"Age\", \"Test1\"),   # Models/tests to evaluate      # Threshold settings   thresholdMin = 0.01,             # Minimum threshold (0.1-50%)   thresholdMax = 0.50,             # Maximum threshold (1-99%)   thresholdPoints = 50,            # Number of evaluation points      # Analysis type   bayesianAnalysis = TRUE,         # TRUE=Bayesian, FALSE=Frequentist      # Bayesian settings   nDraws = 2000,                   # Posterior draws (500-10000)   priorStrength = 2,               # Prior strength (0.1-10)   calculateEVPI = FALSE,           # Enable EVPI calculation      # Frequentist settings     bootstrapCI = TRUE,              # Bootstrap confidence intervals   bootstrapReps = 2000,            # Bootstrap replications      # External prevalence   useExternalPrevalence = FALSE,   # Use external prevalence data   externalCases = 100,             # Cases in external data   externalTotal = 500,             # Total in external data      # Technical settings   directionIndicator = \">=\"        # Prediction direction )"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "curve-interpretation",
        "dir": "Articles",
        "previous_headings": "Interpretation Guidelines > Understanding Net Benefit Curves",
        "what": "Curve Interpretation",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# Example showing different curve patterns # (This would be actual analysis output in practice)  # Pattern 1: Clear winner # One model consistently above others # Interpretation: Strong evidence for using this model  # Pattern 2: Threshold-dependent # Different models optimal at different thresholds   # Interpretation: Threshold selection matters  # Pattern 3: Minimal differences # All models similar performance # Interpretation: Simple approaches may suffice  # Pattern 4: No benefit # All models below treat all/none # Interpretation: Models not clinically useful"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "clinical-decision-rules",
        "dir": "Articles",
        "previous_headings": "Interpretation Guidelines > Understanding Net Benefit Curves",
        "what": "Clinical Decision Rules",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Use Model: 1. Model curve “treat ” “treat none” 2. Net benefit difference clinically meaningful (e.g., >0.01) 3. Confidence/credible intervals don’t include zero benefit 4. Probability superiority >80% relevant threshold range Use Model: 1. Model performs worse simple strategies 2. High uncertainty wide confidence intervals 3. EVPI high - need research first 4. Benefit minimal relative implementation costs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "statistical-significance-vs-clinical-utility",
        "dir": "Articles",
        "previous_headings": "Interpretation Guidelines",
        "what": "Statistical Significance vs Clinical Utility",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Traditional Metrics vs DCA: Key Point: statistically significant model may clinical utility net benefit improvement negligible.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-1-cancer-screening-program",
        "dir": "Articles",
        "previous_headings": "Clinical Application Examples",
        "what": "Example 1: Cancer Screening Program",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Key Questions: - threshold recommend testing? - biomarker panel worth additional cost? - implement screening program?",
        "code": "# Evaluate biomarker panel for cancer screening screening_analysis <- bayesdca(   data = screening_cohort,   outcomes = \"Cancer\",   predictors = c(\"Biomarker_Panel\", \"Clinical_Score\", \"Imaging_Result\"),      # Low thresholds appropriate for screening   thresholdMin = 0.01,     # 1% - very sensitive   thresholdMax = 0.10,     # 10% - still screening range   thresholdPoints = 20,      bayesianAnalysis = TRUE,   calculateEVPI = TRUE,      # External prevalence from cancer registry   useExternalPrevalence = TRUE,   externalCases = 50,      # Registry cancer rate   externalTotal = 1000     # Registry population )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-2-treatment-selection-model",
        "dir": "Articles",
        "previous_headings": "Clinical Application Examples",
        "what": "Example 2: Treatment Selection Model",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Key Questions: - patients receive intensive treatment? - genomic testing worth cost treatment selection? - threshold guide treatment decisions?",
        "code": "# Personalized treatment selection model treatment_analysis <- bayesdca(   data = treatment_cohort,   outcomes = \"TreatmentFailure\",    predictors = c(\"GenomicScore\", \"ClinicalModel\", \"Combined_Score\"),      # Moderate thresholds for treatment decisions   thresholdMin = 0.15,     # 15% - consider treatment   thresholdMax = 0.45,     # 45% - high-risk threshold   thresholdPoints = 30,      bayesianAnalysis = TRUE,   priorStrength = 3,       # Moderate prior for treatment   calculateEVPI = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "example-3-diagnostic-test-evaluation",
        "dir": "Articles",
        "previous_headings": "Clinical Application Examples",
        "what": "Example 3: Diagnostic Test Evaluation",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Key Questions: - replace standard test rapid test? - probability initiate treatment? - combined approach worth additional complexity?",
        "code": "# Compare diagnostic tests for rapid diagnosis diagnostic_analysis <- bayesdca(   data = diagnostic_cohort,   outcomes = \"Disease\",   predictors = c(\"Rapid_Test\", \"Standard_Test\", \"Combined_Tests\"),      # Broad threshold range for diagnostic evaluation   thresholdMin = 0.05,   thresholdMax = 0.50,   thresholdPoints = 45,      bayesianAnalysis = TRUE,   calculateEVPI = TRUE,      # Direction: positive test results indicate disease   directionIndicator = \">=\" )"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "probability-calibration",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Handling Complex Prediction Models",
        "what": "Probability Calibration",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For machine learning models, ensure probabilities are well-calibrated # before DCA analysis  # Example with logistic regression calibration library(rms)  # Calibrate predictions calibrated_probs <- predict(calibration_model, type = \"response\")  # Use calibrated probabilities in DCA bayesdca(   data = mydata,   outcomes = \"Death\",   predictors = \"calibrated_probs\",   thresholdMin = 0.05,   thresholdMax = 0.40,   bayesianAnalysis = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "multi-class-outcomes",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Handling Complex Prediction Models",
        "what": "Multi-class Outcomes",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For outcomes with multiple categories, create binary versions mydata_binary <- mydata %>%   mutate(     Death_vs_Others = ifelse(Outcome == \"Death\", 1, 0),     Progression_vs_Others = ifelse(Outcome == \"Progression\", 1, 0)   )  # Analyze each binary outcome separately bayesdca(data = mydata_binary, outcomes = \"Death_vs_Others\", ...) bayesdca(data = mydata_binary, outcomes = \"Progression_vs_Others\", ...)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "cross-validation-strategy",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Model Validation Considerations",
        "what": "Cross-validation Strategy",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For internal validation, use cross-validation library(pROC)  # Example 5-fold cross-validation set.seed(123) folds <- createFolds(mydata$Death, k = 5)  cv_results <- list() for(i in 1:5) {   train_data <- mydata[-folds[[i]], ]   test_data <- mydata[folds[[i]], ]      # Fit model on training data   model <- glm(Death ~ Age + MeasurementA, data = train_data, family = binomial)      # Predict on test data   test_data$predictions <- predict(model, test_data, type = \"response\")      # Run DCA on test predictions   cv_results[[i]] <- bayesdca(     data = test_data,     outcomes = \"Death\",      predictors = \"predictions\",     bayesianAnalysis = TRUE   ) }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "external-validation",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Model Validation Considerations",
        "what": "External Validation",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For external validation on independent dataset external_results <- bayesdca(   data = external_cohort,   outcomes = \"Death\",   predictors = \"model_predictions\",  # From original model      # May need different threshold range   thresholdMin = 0.05,   thresholdMax = 0.35,      # Account for different prevalence   useExternalPrevalence = TRUE,   externalCases = external_cases,   externalTotal = external_total,      bayesianAnalysis = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "incorporating-costs",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Cost-Effectiveness Integration",
        "what": "Incorporating Costs",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# DCA can be extended to include costs # Net benefit becomes: NB = (TP × Benefit - FP × Harm) / Cost  # Example: Modify net benefit calculation for cost-effectiveness # This would require custom calculation outside the standard DCA framework  cost_adjusted_analysis <- function(dca_results, intervention_cost, harm_cost) {   # Custom function to adjust net benefit for costs   # Implementation would depend on specific cost structure }"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "data-preparation-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Best Practices > Common Issues and Solutions",
        "what": "Data Preparation Issues",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Problem: Outcome variable properly coded Problem: Prediction probabilities outside [0,1] range Problem: Missing values predictors",
        "code": "# Solution: Ensure binary coding mydata$outcome_binary <- ifelse(mydata$Outcome == \"Event\", 1, 0) # Or specify positive level for factors bayesdca(..., outcomes = \"Status\", outcomePos = \"Dead\") # Solution: Check and constrain predictions summary(mydata$predictions) mydata$predictions <- pmin(pmax(mydata$predictions, 0.001), 0.999) # Solution: Handle missing values appropriately # Remove cases with missing predictors complete_data <- mydata[complete.cases(mydata[, c(\"outcome\", \"predictor1\", \"predictor2\")]), ]  # Or impute missing values (use appropriate method) library(mice) imputed_data <- complete(mice(mydata))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "threshold-selection-issues",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Best Practices > Common Issues and Solutions",
        "what": "Threshold Selection Issues",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Problem: Unclear threshold range use Problem: models perform similarly",
        "code": "# Solution: Use clinical guidelines or literature # For cancer: often 5-20% # For screening: often 1-10%  # For surgery: often 20-50%  # Start broad and narrow based on results bayesdca(..., thresholdMin = 0.01, thresholdMax = 0.50) # Solutions: # 1. Check if sample size is adequate # 2. Consider if models are actually different # 3. Look at EVPI - high values suggest more research needed # 4. Focus on interpretability and implementation costs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "interpretation-challenges",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Best Practices > Common Issues and Solutions",
        "what": "Interpretation Challenges",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Problem: Negative net benefit values Problem: wide confidence intervals",
        "code": "# This is normal and expected! # Net benefit can be negative - it just means the strategy # performs worse than \"treat none\" # Focus on relative differences between strategies # Solutions: # 1. Increase sample size if possible # 2. Use stronger priors (increase priorStrength) # 3. Consider if more research is needed (check EVPI) # 4. Focus on threshold ranges with narrow intervals"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "large-dataset-handling",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Best Practices > Performance Optimization",
        "what": "Large Dataset Handling",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For large datasets (>10,000 observations) # Consider reducing computational burden  # Reduce posterior draws for initial exploration bayesdca(..., nDraws = 1000)  # Instead of 2000+  # Reduce threshold points for initial analysis bayesdca(..., thresholdPoints = 20)  # Instead of 50+  # Use frequentist approach for speed bayesdca(..., bayesianAnalysis = FALSE, bootstrapCI = TRUE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "memory-management",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Best Practices > Performance Optimization",
        "what": "Memory Management",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# For memory-intensive analyses # Clean up intermediate objects gc()  # Use data.table for large datasets library(data.table) setDT(mydata)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "recommended-analysis-sequence",
        "dir": "Articles",
        "previous_headings": "Integration with ClinicoPath Workflow",
        "what": "Recommended Analysis Sequence",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Exploratory Analysis: Use ClinicoPath modules initial exploration Model Development: Develop prediction models using appropriate methods Performance Evaluation: Assess discrimination (ROC analysis) Clinical Utility: Use Bayesian DCA evaluate real-world utility Implementation Planning: Use EVPI cost considerations decisions",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "roc-analysis-first",
        "dir": "Articles",
        "previous_headings": "Integration with ClinicoPath Workflow > Complement with Other Modules",
        "what": "ROC Analysis First",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# Step 1: Traditional ROC analysis roc_analysis <- roc(data = mydata, outcomes = \"Death\", predictors = \"Age\")  # Step 2: Decision curve analysis for clinical utility dca_analysis <- bayesdca(data = mydata, outcomes = \"Death\", predictors = \"Age\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "decision-trees-for-implementation",
        "dir": "Articles",
        "previous_headings": "Integration with ClinicoPath Workflow > Complement with Other Modules",
        "what": "Decision Trees for Implementation",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# Use decision tree analysis for implementation planning # after DCA shows clinical utility decision_tree_analysis <- decisiongraph(...)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "cost-effectiveness-analysis",
        "dir": "Articles",
        "previous_headings": "Integration with ClinicoPath Workflow > Complement with Other Modules",
        "what": "Cost-Effectiveness Analysis",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# Integrate DCA results with cost-effectiveness models # for full economic evaluation"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "methods-section",
        "dir": "Articles",
        "previous_headings": "Reporting Guidelines > Essential Elements for Publication",
        "what": "Methods Section",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Specify analysis type (Bayesian vs Frequentist) Report threshold range rationale Describe prior specification (Bayesian) Report software version settings",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "results-section",
        "dir": "Articles",
        "previous_headings": "Reporting Guidelines > Essential Elements for Publication",
        "what": "Results Section",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Present main decision curves confidence intervals Report net benefit clinically relevant thresholds Include probability superiority (Bayesian) Report EVPI calculated",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "interpretation-guidelines-1",
        "dir": "Articles",
        "previous_headings": "Reporting Guidelines > Essential Elements for Publication",
        "what": "Interpretation Guidelines",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Focus clinical meaningfulness, just statistical significance Discuss threshold-dependent findings Address uncertainty need additional research Consider implementation costs barriers",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "publication-ready-plots",
        "dir": "Articles",
        "previous_headings": "Reporting Guidelines > Figure Quality",
        "what": "Publication-Ready Plots",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "",
        "code": "# The Bayesian DCA module produces publication-ready plots # with proper formatting: # - Professional color schemes # - Percentage formatting for thresholds   # - Appropriate confidence bands # - Clear legends and labels  # Plots can be exported at high resolution for publications"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Bayesian Decision Curve Analysis represents sophisticated approach evaluating clinical utility prediction models diagnostic tests. focusing real-world decision making rather just statistical performance, DCA provides crucial insights clinical implementation.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Key Takeaways",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Clinical Utility Matters: statistically significant model may clinical benefit Thresholds Critical: Performance varies dramatically across decision thresholds Uncertainty Quantification: Bayesian approaches provide richer uncertainty information Research Prioritization: EVPI helps identify additional research valuable Implementation Focus: DCA directly addresses “use practice?”",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-bayesian-decision-curve-analysis.html",
        "id": "when-dca-changes-clinical-practice",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "When DCA Changes Clinical Practice",
        "title": "Bayesian Decision Curve Analysis - Advanced Clinical Decision Making",
        "text": "Identifies optimal decision thresholds existing interventions Prevents implementation models clinical utility despite good discrimination Guides resource allocation quantifying value additional research Supports evidence-based policy screening diagnostic programs Enables personalized medicine identifying patient subgroups benefit ClinicoPath Bayesian DCA module provides comprehensive toolkit sophisticated analysis, making advanced decision-theoretic methods accessible clinical researchers supporting evidence-based implementation prediction models healthcare. comprehensive guide demonstrates full capabilities Bayesian Decision Curve Analysis ClinicoPath module, providing researchers tools knowledge needed evaluate clinical utility guide evidence-based implementation prediction models diagnostic tests.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "vignette provides comprehensive examples explaining decision tree Markov chain analysis types implemented ClinicoPath jamovi module.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "scenario-acute-appendicitis-treatment-decision",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Example",
        "what": "Scenario: Acute Appendicitis Treatment Decision",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "Clinical Question: patient suspected appendicitis receive immediate surgery conservative treatment?",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "creating-example-data",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Example > Scenario: Acute Appendicitis Treatment Decision",
        "what": "Creating Example Data",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Create decision tree example data set.seed(123) n_patients <- 100  appendicitis_decision_data <- data.frame(   patient_id = 1:n_patients,    # DECISION NODES (Square boxes)   treatment_choice = sample(c(\"Immediate Surgery\", \"Conservative Treatment\"),                            n_patients, replace = TRUE),    # PROBABILITY VARIABLES (for chance nodes - circles)   prob_appendicitis_confirmed = runif(n_patients, 0.7, 0.9),     # Probability patient actually has appendicitis   prob_surgery_success = runif(n_patients, 0.95, 0.99),          # Surgery success rate   prob_conservative_success = runif(n_patients, 0.6, 0.8),       # Conservative treatment success   prob_complications_surgery = runif(n_patients, 0.02, 0.08),    # Surgery complications   prob_complications_conservative = runif(n_patients, 0.15, 0.25), # Conservative complications    # COST VARIABLES (outcomes)   cost_surgery = rnorm(n_patients, 12000, 2000),                 # Surgery costs   cost_conservative = rnorm(n_patients, 3000, 500),              # Conservative treatment costs   cost_complications = rnorm(n_patients, 8000, 1500),            # Complication management costs   cost_failed_conservative = rnorm(n_patients, 15000, 2500),     # Emergency surgery after failed conservative    # UTILITY VARIABLES (quality of life outcomes)   utility_success = runif(n_patients, 0.95, 1.0),               # Full recovery   utility_minor_complications = runif(n_patients, 0.8, 0.9),    # Recovery with minor issues   utility_major_complications = runif(n_patients, 0.6, 0.8),    # Recovery with major issues    # OUTCOME VARIABLES (terminal nodes - triangles)   clinical_outcome = sample(c(\"Complete Recovery\", \"Minor Complications\", \"Major Complications\"),                            n_patients, replace = TRUE, prob = c(0.8, 0.15, 0.05)) )  # Display first few rows head(appendicitis_decision_data, 5)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "decision-tree-structure",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Example > Scenario: Acute Appendicitis Treatment Decision",
        "what": "Decision Tree Structure",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "decision tree following structure: Option : Immediate Surgery Option B: Conservative Treatment Success (95-99%): Low cost, high utility Complications (2-8%): Higher cost, lower utility Success (60-80%): Low cost, high utility Failure (20-40%): Requires emergency surgery Cost: $3,000 - $20,000 Utility: 0.6 - 1.0 QALYs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "expected-value-calculations",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Example > Scenario: Acute Appendicitis Treatment Decision",
        "what": "Expected Value Calculations",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Calculate expected values for decision tree surgery_expected_cost <- mean(appendicitis_decision_data$cost_surgery +                              appendicitis_decision_data$prob_complications_surgery *                              appendicitis_decision_data$cost_complications)  conservative_expected_cost <- mean(appendicitis_decision_data$cost_conservative +                                   (1 - appendicitis_decision_data$prob_conservative_success) *                                   appendicitis_decision_data$cost_failed_conservative)  surgery_expected_utility <- mean(appendicitis_decision_data$utility_success *                                 appendicitis_decision_data$prob_surgery_success +                                 appendicitis_decision_data$utility_minor_complications *                                 appendicitis_decision_data$prob_complications_surgery)  conservative_expected_utility <- mean(appendicitis_decision_data$utility_success *                                      appendicitis_decision_data$prob_conservative_success +                                      appendicitis_decision_data$utility_major_complications *                                      (1 - appendicitis_decision_data$prob_conservative_success))  # Calculate ICER incremental_cost <- surgery_expected_cost - conservative_expected_cost incremental_utility <- surgery_expected_utility - conservative_expected_utility icer <- incremental_cost / incremental_utility  # Display results cat(\"DECISION TREE ANALYSIS RESULTS:\\n\") cat(\"===============================\\n\") cat(\"Surgery Strategy:\\n\") cat(\"  Expected Cost: $\", round(surgery_expected_cost, 0), \"\\n\") cat(\"  Expected Utility:\", round(surgery_expected_utility, 3), \"QALYs\\n\") cat(\"\\n\") cat(\"Conservative Strategy:\\n\") cat(\"  Expected Cost: $\", round(conservative_expected_cost, 0), \"\\n\") cat(\"  Expected Utility:\", round(conservative_expected_utility, 3), \"QALYs\\n\") cat(\"\\n\") cat(\"Cost-Effectiveness Analysis:\\n\") cat(\"  Incremental Cost: $\", round(incremental_cost, 0), \"\\n\") cat(\"  Incremental Utility:\", round(incremental_utility, 3), \"QALYs\\n\") cat(\"  ICER: $\", round(icer, 0), \"per QALY\\n\")  if (icer < 50000) {   cat(\"  ✓ Surgery is cost-effective (ICER < $50,000/QALY)\\n\") } else {   cat(\"  ⚠ Surgery may not be cost-effective (ICER > $50,000/QALY)\\n\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "decision-tree-interpretation",
        "dir": "Articles",
        "previous_headings": "Decision Tree Analysis Example > Scenario: Acute Appendicitis Treatment Decision",
        "what": "Decision Tree Interpretation",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "Decision trees ideal : One-time decisions immediate outcomes Comparing 2-3 distinct treatment strategies Situations timing critical outcomes occur relatively quickly (days months) Point--time cost-effectiveness analysis",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "scenario-chronic-heart-disease-management",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example",
        "what": "Scenario: Chronic Heart Disease Management",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "Clinical Question: long-term cost-effectiveness different heart disease management strategies?",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "creating-markov-data",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Creating Markov Data",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Create Markov chain example data set.seed(456) n_strategies <- 150  # First create basic structure heart_disease_markov_data <- data.frame(   strategy_id = 1:n_strategies,    # DECISION VARIABLES   management_strategy = sample(c(\"Standard Care\", \"Intensive Monitoring\", \"Preventive Surgery\"),                               n_strategies, replace = TRUE),   patient_risk_category = sample(c(\"Low Risk\", \"Moderate Risk\", \"High Risk\"),                                 n_strategies, replace = TRUE, prob = c(0.4, 0.4, 0.2)) )  # Add transition probabilities heart_disease_markov_data$prob_asymp_to_symp <- case_when(   heart_disease_markov_data$management_strategy == \"Standard Care\" ~ runif(n_strategies, 0.08, 0.12),   heart_disease_markov_data$management_strategy == \"Intensive Monitoring\" ~ runif(n_strategies, 0.05, 0.08),   heart_disease_markov_data$management_strategy == \"Preventive Surgery\" ~ runif(n_strategies, 0.02, 0.05) )  heart_disease_markov_data$prob_asymp_to_death <- runif(n_strategies, 0.01, 0.02)  # From Symptomatic state heart_disease_markov_data$prob_symp_to_hf <- case_when(   heart_disease_markov_data$management_strategy == \"Standard Care\" ~ runif(n_strategies, 0.15, 0.25),   heart_disease_markov_data$management_strategy == \"Intensive Monitoring\" ~ runif(n_strategies, 0.10, 0.18),   heart_disease_markov_data$management_strategy == \"Preventive Surgery\" ~ runif(n_strategies, 0.05, 0.12) )  heart_disease_markov_data$prob_symp_to_death <- runif(n_strategies, 0.02, 0.04)  # From Heart Failure state heart_disease_markov_data$prob_hf_to_death <- runif(n_strategies, 0.12, 0.20)  # STATE-SPECIFIC ANNUAL COSTS heart_disease_markov_data$cost_asymptomatic <- case_when(   heart_disease_markov_data$management_strategy == \"Standard Care\" ~ rnorm(n_strategies, 2000, 300),   heart_disease_markov_data$management_strategy == \"Intensive Monitoring\" ~ rnorm(n_strategies, 4000, 500),   heart_disease_markov_data$management_strategy == \"Preventive Surgery\" ~ rnorm(n_strategies, 8000, 1000) )  heart_disease_markov_data$cost_symptomatic <- rnorm(n_strategies, 12000, 2000) heart_disease_markov_data$cost_heart_failure <- rnorm(n_strategies, 35000, 5000) heart_disease_markov_data$cost_death <- rep(0, n_strategies)  # No ongoing costs after death  # STATE-SPECIFIC ANNUAL UTILITIES (Quality of Life) heart_disease_markov_data$utility_asymptomatic <- runif(n_strategies, 0.90, 0.95) heart_disease_markov_data$utility_symptomatic <- runif(n_strategies, 0.70, 0.80) heart_disease_markov_data$utility_heart_failure <- runif(n_strategies, 0.45, 0.60) heart_disease_markov_data$utility_death <- rep(0, n_strategies)  # No utility after death  # Display first few rows head(heart_disease_markov_data, 5)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "markov-chain-structure",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Markov Chain Structure",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "HEALTH STATES (Markov States): Asymptomatic Heart Disease Symptomatic Heart Disease Heart Failure Death (Absorbing State) TRANSITION PATHWAYS:",
        "code": "Asymptomatic → Symptomatic → Heart Failure → Death              ↘ Death        ↘ Death"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "transition-matrix-example",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Transition Matrix Example",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Create example transition matrix for Standard Care states <- c(\"Asymptomatic\", \"Symptomatic\", \"Heart Failure\", \"Death\") trans_matrix_standard <- matrix(0, nrow = 4, ncol = 4) rownames(trans_matrix_standard) <- states colnames(trans_matrix_standard) <- states  # Fill transition matrix with average probabilities for Standard Care standard_data <- heart_disease_markov_data[heart_disease_markov_data$management_strategy == \"Standard Care\", ]  trans_matrix_standard[1, 1] <- 1 - mean(standard_data$prob_asymp_to_symp) - mean(standard_data$prob_asymp_to_death)  # Stay asymptomatic trans_matrix_standard[1, 2] <- mean(standard_data$prob_asymp_to_symp)  # Asymp to symptomatic trans_matrix_standard[1, 4] <- mean(standard_data$prob_asymp_to_death)  # Asymp to death  trans_matrix_standard[2, 2] <- 1 - mean(standard_data$prob_symp_to_hf) - mean(standard_data$prob_symp_to_death)  # Stay symptomatic trans_matrix_standard[2, 3] <- mean(standard_data$prob_symp_to_hf)  # Symp to heart failure trans_matrix_standard[2, 4] <- mean(standard_data$prob_symp_to_death)  # Symp to death  trans_matrix_standard[3, 3] <- 1 - mean(standard_data$prob_hf_to_death)  # Stay in heart failure trans_matrix_standard[3, 4] <- mean(standard_data$prob_hf_to_death)  # HF to death  trans_matrix_standard[4, 4] <- 1.0  # Death is absorbing  cat(\"EXAMPLE TRANSITION MATRIX (Standard Care):\\n\") cat(\"=========================================\\n\") print(round(trans_matrix_standard, 3)) cat(\"\\nRow sums (should equal 1.0):\", round(rowSums(trans_matrix_standard), 3), \"\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "markov-cohort-simulation",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Markov Cohort Simulation",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Run Markov cohort simulation num_cycles <- 20 cohort_trace <- matrix(0, nrow = num_cycles + 1, ncol = 4) colnames(cohort_trace) <- states  # Initial distribution: Everyone starts asymptomatic cohort_trace[1, 1] <- 1.0  # Run Markov simulation for (cycle in 2:(num_cycles + 1)) {   cohort_trace[cycle, ] <- cohort_trace[cycle - 1, ] %*% trans_matrix_standard }  # Create summary table trace_df <- data.frame(   Year = 0:num_cycles,   Asymptomatic = round(cohort_trace[, 1] * 100, 1),   Symptomatic = round(cohort_trace[, 2] * 100, 1),   Heart_Failure = round(cohort_trace[, 3] * 100, 1),   Death = round(cohort_trace[, 4] * 100, 1) )  # Show key time points key_years <- c(1, 6, 11, 16, 21)  # 0, 5, 10, 15, 20 years cat(\"Population distribution over time:\\n\") print(trace_df[key_years, ])"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "cost-effectiveness-calculation",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Cost-Effectiveness Calculation",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "# Calculate costs and utilities for Standard Care state_costs <- c(mean(standard_data$cost_asymptomatic),                 mean(standard_data$cost_symptomatic),                 mean(standard_data$cost_heart_failure),                 0)  # Death  state_utilities <- c(mean(standard_data$utility_asymptomatic),                     mean(standard_data$utility_symptomatic),                     mean(standard_data$utility_heart_failure),                     0)  # Death  names(state_costs) <- states names(state_utilities) <- states  cat(\"Annual costs per state:\\n\") print(round(state_costs, 0)) cat(\"\\nAnnual utilities per state:\\n\") print(round(state_utilities, 3))  # Calculate cumulative discounted costs and utilities discount_rate <- 0.03 cumulative_costs <- rep(0, num_cycles + 1) cumulative_utilities <- rep(0, num_cycles + 1)  for (cycle in 2:(num_cycles + 1)) {   # Calculate cycle costs and utilities   cycle_cost <- sum(cohort_trace[cycle, ] * state_costs)   cycle_utility <- sum(cohort_trace[cycle, ] * state_utilities)    # Apply discounting   discount_factor <- (1 + discount_rate)^(-(cycle - 1))    cumulative_costs[cycle] <- cumulative_costs[cycle - 1] + cycle_cost * discount_factor   cumulative_utilities[cycle] <- cumulative_utilities[cycle - 1] + cycle_utility * discount_factor }  # Final results final_cost <- cumulative_costs[num_cycles + 1] final_qalys <- cumulative_utilities[num_cycles + 1]  cat(\"\\nFINAL 20-YEAR RESULTS (Standard Care):\\n\") cat(\"Total Lifetime Cost: $\", round(final_cost, 0), \"\\n\") cat(\"Total Lifetime QALYs:\", round(final_qalys, 2), \"\\n\") cat(\"Cost per QALY: $\", round(final_cost / final_qalys, 0), \"\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "markov-chain-interpretation",
        "dir": "Articles",
        "previous_headings": "Markov Chain Analysis Example > Scenario: Chronic Heart Disease Management",
        "what": "Markov Chain Interpretation",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "Markov chains ideal : Chronic diseases multiple stages Long-term cost-effectiveness analysis (years lifetime) Disease progression modeling Comparing interventions different timing effects Policy decisions affecting population health disease states change time Recurring decisions ongoing treatments",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "comparison-table",
        "dir": "Articles",
        "previous_headings": "When to Use Each Method",
        "what": "Comparison Table",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "",
        "code": "comparison_table <- data.frame(   Aspect = c(\"Time Horizon\", \"Disease Type\", \"Decision Complexity\", \"Outcomes\",              \"Costs\", \"Best For\", \"Data Requirements\", \"Computational Needs\"),   Decision_Tree = c(\"Short-term (days-months)\", \"Acute conditions\", \"Simple (2-3 options)\",                    \"One-time outcomes\", \"One-time costs\", \"Treatment selection\",                    \"Probabilities, costs, utilities\", \"Low\"),   Markov_Chain = c(\"Long-term (years-lifetime)\", \"Chronic conditions\", \"Complex strategies\",                   \"Recurring outcomes\", \"Ongoing costs\", \"Disease management\",                   \"Transition probabilities, state costs\", \"Higher\") )  print(comparison_table)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "example-applications",
        "dir": "Articles",
        "previous_headings": "When to Use Each Method",
        "what": "Example Applications",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "DECISION TREES best : Emergency treatment decisions (appendicitis, trauma) Surgical vs non-surgical interventions Diagnostic test decisions Vaccination decisions One-time screening decisions MARKOV CHAINS best : Chronic disease management (diabetes, heart disease) Cancer progression treatment Addiction treatment programs Preventive intervention policies Healthcare resource planning Long-term pharmaceutical studies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "combined-approaches",
        "dir": "Articles",
        "previous_headings": "When to Use Each Method",
        "what": "Combined Approaches",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "complex problems benefit : Decision tree initial treatment choice Markov chain long-term disease progression Example: Cancer treatment selection (tree) + survival modeling (Markov)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "summary",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Summary",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "vignette demonstrates practical applications decision tree Markov chain methods medical decision analysis cost-effectiveness research. generated datasets can used ClinicoPath jamovi module perform analyses interactively.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "generated-datasets",
        "dir": "Articles",
        "previous_headings": "Summary",
        "what": "Generated Datasets",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "example code creates two key datasets: appendicitis_decision_data - Decision tree example heart_disease_markov_data - Markov chain example datasets demonstrate realistic medical scenarios can used practice analysis types jamovi.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-decision-trees.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "Summary",
        "what": "Next Steps",
        "title": "Decision Tree and Markov Chain Analysis Examples",
        "text": "Load datasets jamovi Use ClinicoPath decision analysis modules Practice interpreting cost-effectiveness results Apply methods research questions",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "kappasizeci function provides statistical power analysis interobserver agreement studies using Cohen’s kappa statistic. function calculates required sample size achieve specified precision (confidence interval width) kappa coefficient estimates studies evaluating agreement multiple raters observers.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "what-is-cohens-kappa",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "What is Cohen’s Kappa?",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Cohen’s kappa (κ) statistical measure interobserver agreement categorical items. measures agreement raters accounting possibility chance agreement: κ=po−pe1−pe\\kappa = \\frac{p_o - p_e}{1 - p_e} : - pop_o = observed proportional agreement - pep_e = expected agreement chance Kappa Interpretation Guidelines: - κ < 0.00: Poor agreement (worse chance) - κ = 0.00-0.20: Slight agreement - κ = 0.21-0.40: Fair agreement - κ = 0.41-0.60: Moderate agreement - κ = 0.61-0.80: Substantial agreement - κ = 0.81-1.00: Almost perfect agreement",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "why-sample-size-calculation-for-kappa",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Why Sample Size Calculation for Kappa?",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Interobserver agreement studies require adequate sample sizes : Ensure Precision: Achieve narrow confidence intervals around kappa estimates Statistical Power: Detect clinically meaningful differences agreement Resource Planning: Optimize study costs logistics Regulatory Requirements: Meet standards validation studies Publication Standards: Satisfy journal requirements reliability studies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "key-features-of-kappasizeci",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Key Features of kappasizeci",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Multiple Categories: Supports 2-5 outcome categories Flexible Rater Numbers: Accommodates 2-5 raters Confidence Interval Approach: Focuses precision rather hypothesis testing Real-world Applications: Covers medical, psychological, quality control scenarios Performance Optimized: Intelligent caching repeated calculations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "installation-and-setup",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Installation and Setup",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Load required libraries library(meddecide) ## Warning: replacing previous import 'dplyr::select' by 'jmvcore::select' when ## loading 'meddecide' library(dplyr) ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(knitr)  # Set options for better output options(digits = 3) knitr::opts_chunk$set(   fig.width = 12,   fig.height = 8,     dpi = 300,   echo = TRUE,   eval = FALSE,   out.width = \"100%\" )  # Check if required packages are available if (!requireNamespace(\"kappaSize\", quietly = TRUE)) {   message(\"Note: kappaSize package required for sample size calculations\")   message(\"Install with: install.packages('kappaSize')\") }"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "kappa-parameters",
        "dir": "Articles",
        "previous_headings": "Understanding the Parameters > Core Parameters",
        "what": "Kappa Parameters",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "kappa0: Null hypothesis value kappa (expected agreement level) kappaL: Lower bound desired confidence interval kappaU: Upper bound desired confidence interval confidence interval [kappaL, kappaU] defines precision requirement: - Narrow intervals (e.g., ±0.05) require larger sample sizes - Wide intervals (e.g., ±0.20) require smaller sample sizes",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "study-design-parameters",
        "dir": "Articles",
        "previous_headings": "Understanding the Parameters > Core Parameters",
        "what": "Study Design Parameters",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "outcome: Number outcome categories (2, 3, 4, 5) raters: Number raters/observers (2, 3, 4, 5) props: Proportions outcome category (must sum 1.0) alpha: Significance level (typically 0.05)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "parameter-relationships",
        "dir": "Articles",
        "previous_headings": "Understanding the Parameters",
        "what": "Parameter Relationships",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Create parameter relationship examples param_examples <- data.frame(   Study_Type = c(     \"High Precision\",     \"Standard Precision\",      \"Lower Precision\",     \"Many Categories\",     \"Few Categories\",     \"Many Raters\",     \"Few Raters\"   ),      Precision_Width = c(0.10, 0.20, 0.40, 0.20, 0.20, 0.20, 0.20),   Expected_Sample_Size = c(\"Large\", \"Medium\", \"Small\", \"Large\", \"Small\", \"Small\", \"Large\"),      Typical_Application = c(     \"Regulatory validation studies\",     \"Standard research studies\",     \"Preliminary feasibility studies\",      \"Complex diagnostic classifications\",     \"Binary diagnostic decisions\",     \"Multi-reader validation studies\",     \"Pilot agreement studies\"   ) )  kable(param_examples, caption = \"Parameter Relationships and Expected Sample Size Effects\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "binary-outcomes-2-categories",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Binary Outcomes (2 Categories)",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "simplest case involves binary classifications (e.g., Disease/Disease):",
        "code": "# Example: Mammography screening agreement # Two radiologists reviewing mammograms for suspicious findings  # Study parameters binary_study <- list(   description = \"Mammography screening agreement study\",   outcome = \"2\",           # Binary: Suspicious / Not suspicious   kappa0 = 0.75,          # Expected high agreement   kappaL = 0.65,          # Lower confidence bound   kappaU = 0.85,          # Upper confidence bound     props = \"0.15, 0.85\",   # 15% suspicious findings   raters = \"2\",           # Two radiologists   alpha = 0.05            # 5% significance level )  # Display study design cat(\"Study Design:\\n\") cat(\"Purpose:\", binary_study$description, \"\\n\") cat(\"Expected κ:\", binary_study$kappa0, \"\\n\")  cat(\"Precision: ±\", (as.numeric(binary_study$kappaU) - as.numeric(binary_study$kappaL))/2, \"\\n\") cat(\"Prevalence: 15% suspicious findings\\n\") cat(\"Raters: 2 radiologists\\n\\n\")  # In practice, you would call: # result <- kappaSizeCI( #   outcome = binary_study$outcome, #   kappa0 = binary_study$kappa0,  #   kappaL = binary_study$kappaL, #   kappaU = binary_study$kappaU, #   props = binary_study$props, #   raters = binary_study$raters, #   alpha = binary_study$alpha # )  cat(\"Sample size calculation would be performed using kappaSize package\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "understanding-binary-study-results",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples > Binary Outcomes (2 Categories)",
        "what": "Understanding Binary Study Results",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Key considerations binary outcomes: - Prevalence Effects: Rare conditions (low prevalence) typically require larger sample sizes - Agreement Expectations: Higher expected kappa values may require larger samples narrow confidence intervals - Clinical Context: Diagnostic studies often require κ > 0.70 clinical acceptability",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "three-category-outcomes",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Three-Category Outcomes",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Many clinical assessments use three-level classifications:",
        "code": "# Example: Cancer grading study # Pathologists grading tumor differentiation  three_cat_study <- list(   description = \"Pathological tumor grading agreement\",   outcome = \"3\",                    # Three grades   kappa0 = 0.70,                   # Good expected agreement   kappaL = 0.60,                   # Lower bound   kappaU = 0.80,                   # Upper bound   props = \"0.20, 0.50, 0.30\",      # Well, Moderate, Poor differentiation   raters = \"3\",                    # Three pathologists   alpha = 0.05 )  cat(\"Three-Category Study Design:\\n\") cat(\"Purpose:\", three_cat_study$description, \"\\n\") cat(\"Categories: Well differentiated (20%), Moderate (50%), Poor (30%)\\n\") cat(\"Expected κ:\", three_cat_study$kappa0, \"\\n\") cat(\"Precision width:\", as.numeric(three_cat_study$kappaU) - as.numeric(three_cat_study$kappaL), \"\\n\") cat(\"Raters: 3 pathologists\\n\\n\")  # Parse proportions to show distribution props_values <- as.numeric(strsplit(three_cat_study$props, \",\")[[1]]) prop_labels <- c(\"Well differentiated\", \"Moderately differentiated\", \"Poorly differentiated\")  prop_table <- data.frame(   Category = prop_labels,   Proportion = props_values,   Percentage = paste0(props_values * 100, \"%\") )  kable(prop_table, caption = \"Expected Category Distributions\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "four-category-outcomes",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Four-Category Outcomes",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Four-category systems common radiology quality assessments:",
        "code": "# Example: BI-RADS assessment # Radiologists using BI-RADS classification  four_cat_study <- list(   description = \"BI-RADS classification agreement study\",   outcome = \"4\",   kappa0 = 0.75,   kappaL = 0.65,   kappaU = 0.85,   props = \"0.40, 0.30, 0.20, 0.10\",  # BI-RADS 1, 2, 3, 4/5   raters = \"3\",   alpha = 0.05 )  cat(\"Four-Category Study Design:\\n\") cat(\"Purpose:\", four_cat_study$description, \"\\n\") cat(\"BI-RADS Categories:\\n\")  props_values <- as.numeric(strsplit(four_cat_study$props, \",\")[[1]]) birads_labels <- c(\"BI-RADS 1 (Normal)\", \"BI-RADS 2 (Benign)\", \"BI-RADS 3 (Probably benign)\", \"BI-RADS 4/5 (Suspicious)\")  birads_table <- data.frame(   Category = birads_labels,   Proportion = props_values,   Percentage = paste0(props_values * 100, \"%\"),   Clinical_Action = c(\"Routine screening\", \"Routine screening\", \"Short-term follow-up\", \"Biopsy recommended\") )  kable(birads_table, caption = \"BI-RADS Category Distribution and Clinical Actions\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "five-category-outcomes",
        "dir": "Articles",
        "previous_headings": "Basic Usage Examples",
        "what": "Five-Category Outcomes",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Five-category systems often used psychological assessments Likert scales:",
        "code": "# Example: Pain assessment study # Nurses rating pain using behavioral indicators  five_cat_study <- list(   description = \"Pediatric pain assessment agreement\",   outcome = \"5\",   kappa0 = 0.60,                   # Moderate agreement expected for subjective assessment   kappaL = 0.45,   kappaU = 0.75,   props = \"0.20, 0.25, 0.25, 0.20, 0.10\",  # No pain to severe pain   raters = \"3\",   alpha = 0.05 )  cat(\"Five-Category Study Design:\\n\") cat(\"Purpose:\", five_cat_study$description, \"\\n\")  props_values <- as.numeric(strsplit(five_cat_study$props, \",\")[[1]]) pain_labels <- c(\"No pain (0)\", \"Mild pain (1-3)\", \"Moderate pain (4-6)\", \"Severe pain (7-8)\", \"Extreme pain (9-10)\")  pain_table <- data.frame(   Pain_Level = pain_labels,   Proportion = props_values,   Percentage = paste0(props_values * 100, \"%\"),   Intervention = c(\"None\", \"Non-pharmacological\", \"Mild analgesics\", \"Strong analgesics\", \"Immediate intervention\") )  kable(pain_table, caption = \"Pain Assessment Categories and Interventions\")"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "diagnostic-agreement-studies",
        "dir": "Articles",
        "previous_headings": "Real-World Applications > Medical and Clinical Studies",
        "what": "Diagnostic Agreement Studies",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Collection of diagnostic agreement scenarios diagnostic_scenarios <- list(      # Radiology   chest_xray = list(     study = \"Pneumonia Detection in Emergency Department\",     setting = \"Emergency department physicians reading chest X-rays\",     outcome = \"2\",     kappa0 = 0.65,     precision = 0.20,     props = \"0.25, 0.75\",  # 25% pneumonia prevalence     raters = \"3\",     rationale = \"Emergency setting requires good agreement for rapid diagnosis\"   ),      # Dermatology     skin_lesion = list(     study = \"Melanoma Risk Assessment\",     setting = \"Dermatologists evaluating suspicious skin lesions\",     outcome = \"2\",      kappa0 = 0.70,     precision = 0.20,     props = \"0.08, 0.92\",  # Low melanoma prevalence     raters = \"4\",     rationale = \"Critical diagnosis requires high agreement and multiple readers\"   ),      # Cardiology   ecg_abnormal = list(     study = \"ECG Abnormality Detection\",     setting = \"Cardiologists interpreting ECGs for abnormalities\",     outcome = \"2\",     kappa0 = 0.80,     precision = 0.15,     props = \"0.35, 0.65\",  # 35% abnormal ECGs     raters = \"2\",      rationale = \"High precision needed for cardiac diagnosis\"   ) )  # Create summary table diagnostic_summary <- data.frame(   Study = sapply(diagnostic_scenarios, function(x) x$study),   Setting = sapply(diagnostic_scenarios, function(x) x$setting),   Categories = sapply(diagnostic_scenarios, function(x) x$outcome),   Expected_Kappa = sapply(diagnostic_scenarios, function(x) x$kappa0),   Precision_Width = sapply(diagnostic_scenarios, function(x) x$precision),   Raters = sapply(diagnostic_scenarios, function(x) x$raters),   Rationale = sapply(diagnostic_scenarios, function(x) x$rationale) )  kable(diagnostic_summary, caption = \"Diagnostic Agreement Study Examples\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "multi-category-medical-assessments",
        "dir": "Articles",
        "previous_headings": "Real-World Applications > Medical and Clinical Studies",
        "what": "Multi-Category Medical Assessments",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Medical severity and staging studies severity_scenarios <- list(      cancer_stage = list(     study = \"Cancer TNM Staging\",     categories = c(\"T1\", \"T2\", \"T3\", \"T4\"),     outcome = \"4\",     kappa0 = 0.75,     props = \"0.30, 0.35, 0.25, 0.10\",     raters = \"3\",     clinical_impact = \"Treatment planning directly depends on staging accuracy\"   ),      asthma_severity = list(     study = \"Asthma Severity Classification\",      categories = c(\"Mild intermittent\", \"Mild persistent\", \"Moderate persistent\", \"Severe persistent\"),     outcome = \"4\",     kappa0 = 0.65,     props = \"0.25, 0.30, 0.30, 0.15\",     raters = \"2\",     clinical_impact = \"Medication choice and monitoring frequency based on severity\"   ),      fracture_grade = list(     study = \"Fracture Classification\",     categories = c(\"Grade I\", \"Grade II\", \"Grade III\"),     outcome = \"3\",      kappa0 = 0.80,     props = \"0.40, 0.35, 0.25\",     raters = \"4\",     clinical_impact = \"Surgical decision making based on fracture severity\"   ) )  cat(\"Medical Severity Assessment Studies:\\n\\n\")  for (scenario_name in names(severity_scenarios)) {   scenario <- severity_scenarios[[scenario_name]]   cat(\"Study:\", scenario$study, \"\\n\")   cat(\"Categories:\", paste(scenario$categories, collapse = \", \"), \"\\n\")   cat(\"Expected κ:\", scenario$kappa0, \"\\n\")   cat(\"Clinical Impact:\", scenario$clinical_impact, \"\\n\")   cat(\"Recommended Raters:\", scenario$raters, \"\\n\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "mental-health-assessments",
        "dir": "Articles",
        "previous_headings": "Real-World Applications > Psychological and Behavioral Research",
        "what": "Mental Health Assessments",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Psychological assessment scenarios psych_scenarios <- list(      depression_severity = list(     study = \"Depression Severity Rating\",     instrument = \"Clinical interview with standardized criteria\",     outcome = \"5\",     categories = c(\"None\", \"Mild\", \"Moderate\", \"Severe\", \"Extreme\"),     kappa0 = 0.60,  # Lower due to subjective nature     props = \"0.15, 0.20, 0.30, 0.25, 0.10\",     raters = \"2\",     challenges = \"Subjective symptoms, cultural factors, patient disclosure variability\"   ),      autism_severity = list(     study = \"Autism Spectrum Disorder Severity\",     instrument = \"ADOS (Autism Diagnostic Observation Schedule)\",     outcome = \"4\",     categories = c(\"No evidence\", \"Mild\", \"Moderate\", \"Severe\"),     kappa0 = 0.75,  # Higher with standardized tool     props = \"0.20, 0.25, 0.30, 0.25\",     raters = \"3\",     challenges = \"Developmental variability, behavioral observation context\"   ),      anxiety_rating = list(     study = \"Anxiety Disorder Classification\",      instrument = \"Structured clinical interview\",     outcome = \"3\",     categories = c(\"No anxiety disorder\", \"Anxiety disorder present\", \"Severe anxiety disorder\"),     kappa0 = 0.65,     props = \"0.40, 0.40, 0.20\",     raters = \"2\",     challenges = \"Symptom overlap between disorders, comorbidity effects\"   ) )  # Create detailed table psych_table <- data.frame(   Study = sapply(psych_scenarios, function(x) x$study),   Instrument = sapply(psych_scenarios, function(x) x$instrument),   Categories = sapply(psych_scenarios, function(x) x$outcome),   Expected_Kappa = sapply(psych_scenarios, function(x) x$kappa0),   Raters = sapply(psych_scenarios, function(x) x$raters),   Main_Challenges = sapply(psych_scenarios, function(x) x$challenges) )  kable(psych_table, caption = \"Psychological Assessment Agreement Studies\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "behavioral-observation-studies",
        "dir": "Articles",
        "previous_headings": "Real-World Applications > Psychological and Behavioral Research",
        "what": "Behavioral Observation Studies",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Behavioral observation scenarios behavioral_scenarios <- data.frame(   Study_Type = c(     \"Classroom Behavior Observation\",     \"Clinical Behavior Assessment\",      \"Developmental Milestone Evaluation\",     \"Social Interaction Coding\",     \"Communication Skill Rating\"   ),      Setting = c(     \"Elementary school classroom\",     \"Clinical psychology office\",     \"Pediatric developmental clinic\",      \"Playground observation\",     \"Speech therapy session\"   ),      Categories = c(3, 4, 5, 3, 4),      Category_Examples = c(     \"On-task, Off-task, Disruptive\",     \"Cooperative, Neutral, Resistant, Aggressive\",     \"Not achieved, Emerging, Achieved, Advanced, Mastered\",     \"Positive, Neutral, Negative\",     \"Poor, Fair, Good, Excellent\"   ),      Expected_Kappa = c(0.65, 0.70, 0.60, 0.55, 0.75),      Typical_Raters = c(2, 3, 2, 4, 2),      Key_Considerations = c(     \"Observer fatigue, context variability\",     \"Behavioral definitions, training level\",     \"Age-related variability, assessment timing\",     \"Social dynamics, observation period\",     \"Skill complexity, assessment criteria\"   ) )  kable(behavioral_scenarios, caption = \"Behavioral Observation Agreement Studies\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "manufacturing-and-production",
        "dir": "Articles",
        "previous_headings": "Real-World Applications > Quality Control and Performance Assessment",
        "what": "Manufacturing and Production",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Quality control scenarios qc_scenarios <- list(      product_inspection = list(     study = \"Manufacturing Quality Control\",     context = \"Final product inspection in electronics manufacturing\",     outcome = \"3\",     categories = c(\"Pass\", \"Minor defect\", \"Major defect\"),     kappa0 = 0.85,  # High agreement expected for objective criteria     props = \"0.80, 0.15, 0.05\",     raters = \"4\",     precision_requirement = \"High precision needed for quality certification\"   ),      food_safety = list(     study = \"Restaurant Food Safety Inspection\",     context = \"Health department restaurant inspections\",     outcome = \"4\",      categories = c(\"Excellent\", \"Good\", \"Fair\", \"Poor\"),     kappa0 = 0.75,     props = \"0.20, 0.40, 0.30, 0.10\",     raters = \"2\",     precision_requirement = \"Good agreement needed for regulatory compliance\"   ),      service_quality = list(     study = \"Customer Service Quality Assessment\",     context = \"Call center service quality evaluation\",     outcome = \"5\",     categories = c(\"Poor\", \"Below average\", \"Average\", \"Good\", \"Excellent\"),     kappa0 = 0.70,     props = \"0.05, 0.15, 0.40, 0.30, 0.10\",     raters = \"3\",     precision_requirement = \"Moderate precision for performance management\"   ) )  cat(\"Quality Control Agreement Studies:\\n\\n\")  for (scenario_name in names(qc_scenarios)) {   scenario <- qc_scenarios[[scenario_name]]   cat(\"Study:\", scenario$study, \"\\n\")   cat(\"Context:\", scenario$context, \"\\n\")   cat(\"Categories:\", paste(scenario$categories, collapse = \" | \"), \"\\n\")   cat(\"Expected Agreement:\", scenario$kappa0, \"\\n\")   cat(\"Precision Requirement:\", scenario$precision_requirement, \"\\n\")   cat(\"Inspectors/Raters:\", scenario$raters, \"\\n\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "genomic-classification-studies",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Precision Medicine and Biomarker Studies",
        "what": "Genomic Classification Studies",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Precision medicine scenarios requiring agreement studies precision_scenarios <- list(      variant_classification = list(     study = \"Genetic Variant Pathogenicity Classification\",     context = \"Clinical geneticists classifying variants using ACMG guidelines\",     outcome = \"5\",     categories = c(\"Benign\", \"Likely benign\", \"VUS\", \"Likely pathogenic\", \"Pathogenic\"),     kappa0 = 0.70,     props = \"0.25, 0.30, 0.25, 0.15, 0.05\",     raters = \"3\",     clinical_significance = \"Variant classification directly impacts treatment decisions\"   ),      immunohistochemistry = list(     study = \"IHC Biomarker Scoring\",     context = \"Pathologists scoring HER2 expression in breast cancer\",     outcome = \"4\",     categories = c(\"0\", \"1+\", \"2+\", \"3+\"),     kappa0 = 0.80,     props = \"0.30, 0.25, 0.25, 0.20\",     raters = \"2\",      clinical_significance = \"HER2 status determines targeted therapy eligibility\"   ),      radiogenomics = list(     study = \"Imaging Biomarker Assessment\",     context = \"Radiologists assessing radiomic features predictive of genomic subtypes\",     outcome = \"3\",     categories = c(\"Low probability\", \"Intermediate probability\", \"High probability\"),     kappa0 = 0.65,     props = \"0.40, 0.35, 0.25\",      raters = \"4\",     clinical_significance = \"Imaging biomarkers guide biopsy decisions and treatment planning\"   ) )  # Create precision medicine summary precision_table <- data.frame(   Study = sapply(precision_scenarios, function(x) x$study),   Context = sapply(precision_scenarios, function(x) x$context),   Categories = sapply(precision_scenarios, function(x) x$outcome),   Expected_Kappa = sapply(precision_scenarios, function(x) x$kappa0),   Raters = sapply(precision_scenarios, function(x) x$raters),   Clinical_Impact = sapply(precision_scenarios, function(x) x$clinical_significance) )  kable(precision_table, caption = \"Precision Medicine Agreement Studies\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "qualitative-research-applications",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Content Analysis and Communication Research",
        "what": "Qualitative Research Applications",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Content analysis scenarios content_scenarios <- list(      interview_coding = list(     study = \"Qualitative Interview Theme Identification\",     context = \"Researchers coding patient interview themes about treatment experiences\",     outcome = \"4\",     themes = c(\"Positive experience\", \"Mixed experience\", \"Negative experience\", \"Unclear/Ambiguous\"),     kappa0 = 0.60,  # Lower due to interpretive nature     props = \"0.30, 0.35, 0.25, 0.10\",     raters = \"2\",     challenges = \"Subjective interpretation, context dependency, cultural factors\"   ),      media_sentiment = list(     study = \"News Media Sentiment Analysis\",     context = \"Researchers coding sentiment in health news coverage\",     outcome = \"3\",     categories = c(\"Negative\", \"Neutral\", \"Positive\"),     kappa0 = 0.75,  # Higher with clear guidelines     props = \"0.25, 0.50, 0.25\",     raters = \"3\",     challenges = \"Implicit bias, cultural interpretation, context effects\"   ),      social_media = list(     study = \"Social Media Health Information Classification\",     context = \"Analysts classifying health information accuracy in social posts\",     outcome = \"4\",     categories = c(\"Accurate\", \"Partially accurate\", \"Misleading\", \"False\"),     kappa0 = 0.65,     props = \"0.40, 0.30, 0.20, 0.10\",     raters = \"4\",     challenges = \"Evolving information, source credibility assessment, expertise required\"   ) )  cat(\"Content Analysis Agreement Studies:\\n\\n\")  for (scenario_name in names(content_scenarios)) {   scenario <- content_scenarios[[scenario_name]]   cat(\"Study:\", scenario$study, \"\\n\")   cat(\"Context:\", scenario$context, \"\\n\")      if (\"themes\" %in% names(scenario)) {     cat(\"Themes:\", paste(scenario$themes, collapse = \" | \"), \"\\n\")   } else {     cat(\"Categories:\", paste(scenario$categories, collapse = \" | \"), \"\\n\")   }      cat(\"Expected κ:\", scenario$kappa0, \"\\n\")   cat(\"Coders:\", scenario$raters, \"\\n\")   cat(\"Challenges:\", scenario$challenges, \"\\n\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "determining-precision-requirements",
        "dir": "Articles",
        "previous_headings": "Sample Size Planning Guidelines > Study Design Considerations",
        "what": "Determining Precision Requirements",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Precision requirement guidelines precision_guide <- data.frame(   Study_Purpose = c(     \"Regulatory validation\",     \"Clinical decision support validation\",      \"Research instrument development\",     \"Preliminary feasibility study\",     \"Quality improvement initiative\",     \"Educational assessment tool\",     \"Exploratory research\"   ),      Recommended_Precision = c(     \"±0.05 to ±0.10\",     \"±0.10 to ±0.15\",      \"±0.10 to ±0.20\",     \"±0.15 to ±0.25\",     \"±0.10 to ±0.20\",     \"±0.15 to ±0.25\",     \"±0.20 to ±0.30\"   ),      Minimum_Kappa = c(     \"≥0.80\",     \"≥0.70\",     \"≥0.60\",      \"≥0.50\",     \"≥0.60\",     \"≥0.60\",     \"≥0.40\"   ),      Typical_Sample_Size = c(     \"Large (200-500+)\",     \"Medium-Large (100-300)\",     \"Medium (50-200)\",     \"Small-Medium (30-100)\",     \"Medium (50-150)\",     \"Medium (50-150)\",     \"Small (20-80)\"   ),      Key_Considerations = c(     \"Regulatory standards, patient safety\",     \"Clinical impact, diagnostic accuracy\",     \"Psychometric properties, validity evidence\",     \"Resource constraints, proof of concept\",     \"Operational feasibility, cost-effectiveness\",     \"Educational outcomes, assessment reliability\",     \"Hypothesis generation, method development\"   ) )  kable(precision_guide, caption = \"Precision Requirements by Study Purpose\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "rater-selection-and-training",
        "dir": "Articles",
        "previous_headings": "Sample Size Planning Guidelines > Study Design Considerations",
        "what": "Rater Selection and Training",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Rater selection guidelines rater_guide <- data.frame(   Number_of_Raters = c(\"2\", \"3\", \"4\", \"5\"),      Advantages = c(     \"Simple design, lower cost, faster completion\",     \"Tie-breaking capability, moderate cost increase\",     \"Good reliability, majority decision possible\",      \"High reliability, robust against outliers\"   ),      Disadvantages = c(     \"No tie-breaking, vulnerable to outliers\",     \"Moderate cost increase, scheduling complexity\",     \"Higher cost, scheduling challenges\",     \"High cost, logistical complexity\"   ),      Best_For = c(     \"Well-defined criteria, experienced raters\",     \"Standard research studies, moderate complexity\",     \"Complex assessments, validation studies\",     \"High-stakes decisions, regulatory studies\"   ),      Sample_Size_Effect = c(     \"Baseline (largest sample needed)\",     \"10-20% reduction from 2-rater design\",     \"20-30% reduction from 2-rater design\",     \"25-35% reduction from 2-rater design\"   ) )  kable(rater_guide, caption = \"Rater Number Selection Guidelines\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "effect-of-prevalence-on-sample-size",
        "dir": "Articles",
        "previous_headings": "Sample Size Planning Guidelines > Statistical Considerations",
        "what": "Effect of Prevalence on Sample Size",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Create examples showing prevalence effects prevalence_examples <- data.frame(   Condition = c(     \"Common condition\",     \"Moderate prevalence\",     \"Rare condition\",     \"Very rare condition\"   ),      Prevalence = c(\"50%\", \"25%\", \"10%\", \"2%\"),      Proportions = c(     \"0.50, 0.50\",     \"0.25, 0.75\",      \"0.10, 0.90\",     \"0.02, 0.98\"   ),      Sample_Size_Effect = c(     \"Baseline (optimal)\",     \"10-20% increase\",     \"50-100% increase\",      \"200-400% increase\"   ),      Examples = c(     \"Gender classification, coin flip outcomes\",     \"Hypertension screening, common infections\",     \"Cancer screening, rare genetic variants\",     \"Adverse drug reactions, rare diseases\"   ),      Recommendations = c(     \"Standard sample size calculations apply\",     \"Plan for moderate sample size increase\",     \"Consider enriched sampling strategies\",     \"Multi-site collaboration often necessary\"   ) )  kable(prevalence_examples, caption = \"Prevalence Effects on Sample Size Requirements\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "category-distribution-optimization",
        "dir": "Articles",
        "previous_headings": "Sample Size Planning Guidelines > Statistical Considerations",
        "what": "Category Distribution Optimization",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Guidelines for optimal category distributions distribution_guide <- data.frame(   Scenario = c(     \"Balanced design\",     \"Clinical reality\",     \"Enriched sampling\",     \"Natural prevalence\"   ),      Strategy = c(     \"Equal proportions across categories\",     \"Proportions match real-world prevalence\",     \"Oversample rare categories for power\",     \"Use observed prevalence from pilot data\"   ),      Advantages = c(     \"Optimal statistical power, simple analysis\",     \"Generalizable results, realistic estimates\",     \"Adequate power for rare categories\",     \"Most accurate prevalence estimates\"   ),      Disadvantages = c(     \"May not reflect real prevalence\",     \"May lack power for rare categories\",      \"Complex sampling, generalizability concerns\",     \"May require very large samples\"   ),      Best_For = c(     \"Method development, proof of concept\",     \"Validation studies, clinical implementation\",     \"Rare disease studies, safety assessments\",     \"Epidemiological studies, surveillance\"   ) )  kable(distribution_guide, caption = \"Category Distribution Strategy Guidelines\")"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "pre-study-planning",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > Study Planning Checklist",
        "what": "Pre-Study Planning",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Comprehensive planning checklist planning_checklist <- data.frame(   Phase = c(     rep(\"Design Phase\", 5),     rep(\"Preparation Phase\", 4),      rep(\"Execution Phase\", 4),     rep(\"Analysis Phase\", 3)   ),      Checklist_Item = c(     \"Define study objectives and research questions\",     \"Specify outcome categories and operational definitions\",     \"Determine precision requirements and target kappa\",     \"Estimate category prevalence from literature/pilot data\",     \"Calculate required sample size with appropriate precision\",          \"Develop rater training materials and protocols\",     \"Create standardized assessment procedures\",     \"Establish inter-rater reliability training program\",      \"Pilot test procedures with small sample\",          \"Recruit and train raters to criterion standard\",     \"Implement quality control procedures during data collection\",     \"Monitor inter-rater agreement throughout study\",     \"Document any protocol deviations or issues\",          \"Calculate achieved kappa with confidence intervals\",     \"Compare achieved vs. planned precision\",     \"Report methodology and results transparently\"   ),      Critical_Success_Factor = c(     \"Clear, specific, measurable objectives\",     \"Unambiguous category definitions with examples\",     \"Realistic precision requirements for study purpose\",     \"Accurate prevalence estimates or conservative assumptions\",     \"Adequate sample size with 10-20% overage\",          \"Comprehensive training until criterion reliability achieved\",     \"Standardized procedures reducing rater variability\",     \"Regular reliability assessments and retraining\",     \"Small-scale validation before full implementation\",          \"Consistent application of trained procedures\",     \"Real-time monitoring and feedback systems\",     \"Documentation of agreement levels throughout\",     \"Transparent reporting of all methodological details\",          \"Appropriate statistical methods and reporting\",     \"Honest assessment of achieved vs. planned outcomes\",     \"Complete methodology section enabling replication\"   ) )  kable(planning_checklist, caption = \"Comprehensive Study Planning Checklist\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "common-pitfalls-and-solutions",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > Study Planning Checklist",
        "what": "Common Pitfalls and Solutions",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Common pitfalls and their solutions pitfalls_guide <- data.frame(   Common_Pitfall = c(     \"Inadequate rater training\",     \"Unclear category definitions\",     \"Insufficient sample size\",     \"Ignoring prevalence effects\",      \"Over-optimistic kappa expectations\",     \"No pilot testing\",     \"Inadequate quality control\",     \"Poor documentation\"   ),      Consequences = c(     \"Low agreement, unreliable results\",     \"Inconsistent interpretation, poor agreement\",     \"Wide confidence intervals, imprecise estimates\",     \"Unexpected large sample size requirements\",     \"Disappointed by achieved agreement levels\",     \"Protocol problems discovered too late\",     \"Agreement drift over time, inconsistent results\",     \"Irreproducible methods, unclear procedures\"   ),      Prevention_Strategy = c(     \"Comprehensive training to criterion standard\",     \"Develop detailed decision rules with examples\",     \"Conservative sample size calculations with overage\",     \"Use realistic prevalence estimates in planning\",     \"Base expectations on literature and pilot data\",     \"Always conduct small-scale pilot testing\",     \"Continuous monitoring with regular feedback\",     \"Detailed protocol documentation and reporting\"   ),      Detection_Method = c(     \"Monitor training agreement, regular assessments\",     \"Track disagreements and confusion patterns\",     \"Monitor confidence interval width during study\",     \"Compare pilot vs. planned prevalence estimates\",     \"Compare achieved vs. expected agreement levels\",     \"Small pilot reveals procedural issues\",     \"Track agreement trends over time\",     \"External review and replication attempts\"   ) )  kable(pitfalls_guide, caption = \"Common Pitfalls and Prevention Strategies\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "kappa-interpretation-in-context",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > Interpretation Guidelines",
        "what": "Kappa Interpretation in Context",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Context-specific interpretation guidelines interpretation_guide <- data.frame(   Clinical_Context = c(     \"Life-threatening diagnosis\",     \"Treatment selection\",     \"Screening decisions\",      \"Quality improvement\",     \"Research classification\",     \"Educational assessment\"   ),      Minimum_Acceptable_Kappa = c(     \"≥0.80\",     \"≥0.70\",     \"≥0.60\",     \"≥0.60\",      \"≥0.50\",     \"≥0.60\"   ),      Interpretation_Considerations = c(     \"Patient safety paramount, minimal disagreement tolerated\",     \"Treatment effectiveness depends on accurate classification\",     \"Balance sensitivity/specificity with resource utilization\",     \"Improvement trends more important than absolute values\",     \"Scientific rigor balanced with practical constraints\",     \"Educational outcomes require reliable measurement\"   ),      Action_If_Below_Threshold = c(     \"Additional training, refined criteria, expert consensus\",     \"Protocol revision, additional validation studies\",     \"Enhanced training, clearer guidelines, pilot testing\",     \"Process improvement, additional training, system changes\",     \"Method refinement, additional categories, expert review\",     \"Rubric revision, faculty development, norm setting\"   ) )  kable(interpretation_guide, caption = \"Context-Specific Kappa Interpretation Guidelines\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "reporting-standards",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > Interpretation Guidelines",
        "what": "Reporting Standards",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Comprehensive reporting standards reporting_elements <- data.frame(   Report_Section = c(     rep(\"Methods\", 8),     rep(\"Results\", 5),     rep(\"Discussion\", 3)   ),      Required_Element = c(     \"Study design and objectives\",     \"Rater selection and qualifications\",      \"Training procedures and criterion standards\",     \"Assessment materials and procedures\",     \"Category definitions and decision rules\",     \"Sample size calculation and rationale\",     \"Data collection procedures and timeline\",     \"Statistical analysis plan\",          \"Sample characteristics and representativeness\",     \"Achieved sample size vs. planned\",     \"Kappa coefficients with confidence intervals\",      \"Agreement by category and rater pairs\",     \"Sensitivity analyses and robustness checks\",          \"Comparison with literature values\",     \"Clinical or practical significance\",     \"Limitations and future directions\"   ),      Reporting_Detail = c(     \"Clear research questions and hypotheses\",     \"Professional background, experience level, training status\",     \"Duration, methods, assessments, criterion achievement\",     \"Materials used, standardization procedures, blinding\",     \"Operational definitions, examples, decision algorithms\",     \"Precision requirements, prevalence assumptions, power\",     \"Recruitment, randomization, quality control measures\",     \"Software, statistical methods, confidence interval approach\",          \"Demographics, inclusion/exclusion, representativeness\",     \"Actual vs. planned N, reasons for any differences\",     \"Point estimates, confidence intervals, interpretation guidelines\",     \"Category-specific agreement, patterns of disagreement\",      \"Robustness to assumptions, alternative analyses\",          \"Literature context, benchmark comparisons\",     \"Clinical impact, decision-making implications\",     \"Study limitations, generalizability, future research needs\"   ) )  kable(reporting_elements, caption = \"Comprehensive Reporting Standards for Agreement Studies\")"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "common-parameter-errors",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Problem-Solving > Input Validation Issues",
        "what": "Common Parameter Errors",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Common parameter validation errors and solutions validation_errors <- data.frame(   Error_Type = c(     \"Kappa out of range\",     \"Invalid confidence bounds\",     \"Proportion count mismatch\",     \"Proportions don't sum to 1\",     \"Invalid rater count\",     \"Invalid outcome categories\",     \"Alpha out of range\"   ),      Example_Error = c(     \"kappa0 = 1.2 or kappa0 = -0.5\",     \"kappaL = 0.80, kappaU = 0.70\",     \"outcome='3' but props='0.5, 0.5'\",     \"props = '0.30, 0.80' (sums to 1.10)\",     \"raters = '6' or raters = '1'\",     \"outcome = '6' or outcome = '1'\",     \"alpha = 1.5 or alpha = -0.05\"   ),      Solution = c(     \"Use values between 0.01 and 0.99\",     \"Ensure kappaL < kappaU, both in (0,1)\",     \"Provide exactly n proportions for n categories\",     \"Ensure proportions sum to 1.0 (±0.01)\",     \"Use 2, 3, 4, or 5 raters only\",      \"Use 2, 3, 4, or 5 outcome categories only\",     \"Use values between 0.01 and 0.99\"   ),      Prevention = c(     \"Check literature for realistic kappa ranges\",     \"Plan CI width carefully, validate bounds\",     \"Count categories carefully, double-check input\",     \"Verify proportions sum to 1, use decimals\",     \"Review study design for practical rater numbers\",     \"Confirm category system matches study needs\",     \"Use standard significance levels (0.05, 0.01)\"   ) )  kable(validation_errors, caption = \"Common Parameter Validation Errors and Solutions\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "proportion-specification-challenges",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Problem-Solving > Input Validation Issues",
        "what": "Proportion Specification Challenges",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Proportion specification guidance proportion_guidance <- data.frame(   Challenge = c(     \"Unknown true proportions\",     \"Literature values unavailable\",     \"Multiple possible distributions\",     \"Rare category concerns\",     \"Unbalanced categories\"   ),      Approach = c(     \"Use pilot data or expert estimates\",     \"Use balanced distribution as conservative estimate\",     \"Perform sensitivity analysis with multiple scenarios\",     \"Consider enriched sampling strategy\",     \"Plan for increased sample size\"   ),      Example_Solution = c(     \"props = '0.25, 0.75' based on 20-patient pilot\",     \"props = '0.33, 0.33, 0.34' for 3-category equal distribution\",     \"Calculate sample size for best/worst/most likely scenarios\",     \"props = '0.15, 0.85' with targeted recruitment of rare cases\",     \"props = '0.10, 0.90' with 2-3x larger sample size\"   ),      Validation_Strategy = c(     \"Compare pilot to early study data, adjust if needed\",     \"Monitor actual proportions, recalculate if significantly different\",     \"Report sensitivity analysis results, justify chosen scenario\",     \"Document enrichment strategy, discuss generalizability\",     \"Plan interim analysis to confirm adequate rare category sample\"   ) )  kable(proportion_guidance, caption = \"Proportion Specification Guidance and Solutions\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "large-study-considerations",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Problem-Solving > Performance Optimization",
        "what": "Large Study Considerations",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "",
        "code": "# Optimization strategies for large studies optimization_strategies <- data.frame(   Study_Size = c(     \"Small (N<100)\",     \"Medium (N=100-500)\",      \"Large (N=500-1000)\",     \"Very Large (N>1000)\"   ),      Primary_Challenges = c(     \"Limited precision, recruitment\",     \"Rater scheduling, quality control\",     \"Data management, rater consistency\",      \"Multi-site coordination, standardization\"   ),      Optimization_Strategies = c(     \"Careful planning, over-recruitment, focused training\",     \"Batch processing, regular reliability checks\",     \"Database systems, ongoing training, drift monitoring\",     \"Central training, standardized protocols, real-time monitoring\"   ),      Quality_Control = c(     \"100% double rating, immediate feedback\",     \"Random subset double rating (20-30%)\",     \"Systematic quality checks, quarterly retraining\",     \"Automated quality metrics, central review system\"   ),      Technology_Solutions = c(     \"Simple data entry, manual tracking\",     \"Database with validation rules\",     \"Automated workflows, dashboard monitoring\",     \"Enterprise systems, real-time analytics\"   ) )  kable(optimization_strategies, caption = \"Study Size Optimization Strategies\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations",
        "what": "Key Takeaways",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "kappasizeci function provides essential sample size planning capabilities interobserver agreement studies. Key benefits include:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "statistical-accuracy",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Key Takeaways",
        "what": "Statistical Accuracy",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Precision-Based Approach: Focus confidence interval width rather hypothesis testing Multiple Categories: Support 2-5 outcome categories covering real-world applications Flexible Design: Accommodates 2-5 raters various study designs Validated Methods: Uses established kappaSize package algorithms",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "practical-applications",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Key Takeaways",
        "what": "Practical Applications",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Medical Research: Diagnostic accuracy, severity assessment, imaging interpretation Psychological Studies: Behavioral assessment, clinical rating scales, symptom evaluation Quality Control: Manufacturing inspection, service evaluation, performance assessment Content Analysis: Qualitative coding, media analysis, educational assessment",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "implementation-benefits",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Key Takeaways",
        "what": "Implementation Benefits",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Study Planning: Accurate sample size determination research planning Resource Optimization: Appropriate sample sizes minimize costs ensuring precision Regulatory Compliance: Meet standards validation reliability studies Publication Quality: Satisfy journal requirements methodological rigor",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "study-design-phase",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Recommendations for Practice",
        "what": "Study Design Phase",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Clear Objectives: Define precise research questions agreement requirements Realistic Expectations: Base kappa targets literature pilot data Conservative Planning: Add 10-20% calculated sample sizes contingencies Pilot Testing: Always conduct small-scale pilot validate procedures",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "implementation-phase",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Recommendations for Practice",
        "what": "Implementation Phase",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Comprehensive Training: Train raters criterion standard data collection Quality Monitoring: Continuously monitor agreement throughout study Documentation: Maintain detailed records procedures decisions Flexibility: prepared adjust based interim analyses",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "analysis-and-reporting",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations > Recommendations for Practice",
        "what": "Analysis and Reporting",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Transparent Methods: Report methodological details reproducibility Clinical Context: Interpret results within relevant clinical practical context Limitations: Acknowledge study limitations generalizability constraints Future Directions: Provide guidance subsequent research implementation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/07-kappasizeci-comprehensive.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "Summary and Recommendations",
        "what": "Next Steps",
        "title": "Sample Size Calculations for Interobserver Agreement Studies",
        "text": "Explore function specific research scenarios Conduct pilot studies validate parameter assumptions Consider comprehensive test datasets method validation Review performance optimization features large-scale studies",
        "code": "sessionInfo()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "vignette demonstrates real-world clinical applications Decision Panel Optimization module across different medical specialties scenarios.",
        "code": "# Load required packages library(meddecide) library(dplyr) library(ggplot2) library(rpart) library(rpart.plot) library(knitr) library(forcats)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-context",
        "dir": "Articles",
        "previous_headings": "Scenario 1: Emergency Department COVID-19 Screening",
        "what": "Clinical Context",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "emergency department needs rapidly screen patients COVID-19 managing limited resources preventing nosocomial transmission.",
        "code": "# Examine test characteristics covid_tests <- covid_screening_data %>%   select(rapid_antigen, pcr, chest_ct, covid_status) %>%   na.omit()  # Calculate individual test performance test_performance <- function(test, truth) {   tab <- table(test, truth)   sens <- tab[2,2] / sum(tab[,2])   spec <- tab[1,1] / sum(tab[,1])   ppv <- tab[2,2] / sum(tab[2,])   npv <- tab[1,1] / sum(tab[1,])      return(data.frame(     Sensitivity = sens,     Specificity = spec,     PPV = ppv,     NPV = npv   )) }  # Individual test performance rapid_perf <- test_performance(covid_tests$rapid_antigen, covid_tests$covid_status) pcr_perf <- test_performance(covid_tests$pcr, covid_tests$covid_status) ct_perf <- test_performance(covid_tests$chest_ct, covid_tests$covid_status)  performance_table <- rbind(   `Rapid Antigen` = rapid_perf,   `PCR` = pcr_perf,   `Chest CT` = ct_perf )  kable(round(performance_table * 100, 1),        caption = \"Individual Test Performance (%)\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "optimization-analysis",
        "dir": "Articles",
        "previous_headings": "Scenario 1: Emergency Department COVID-19 Screening",
        "what": "Optimization Analysis",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Run optimization for different scenarios # 1. Maximum sensitivity (don't miss cases) covid_max_sens <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   strategies = \"all\",   optimizationCriteria = \"sensitivity\",   minSensitivity = 0.95 )  # 2. Cost-effective screening covid_cost_effective <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   strategies = \"all\",   optimizationCriteria = \"efficiency\",   useCosts = TRUE,   testCosts = \"5,50,200\",   fpCost = 500,   fnCost = 5000 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-decision-algorithm",
        "dir": "Articles",
        "previous_headings": "Scenario 1: Emergency Department COVID-19 Screening",
        "what": "Clinical Decision Algorithm",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "Based analysis, ’s practical algorithm:",
        "code": "# Implement sequential testing algorithm apply_covid_algorithm <- function(data) {   n <- nrow(data)   decisions <- character(n)   tests_used <- character(n)      for (i in 1:n) {     # Step 1: Rapid antigen test     if (data$rapid_antigen[i] == \"Positive\") {       decisions[i] <- \"Isolate, Confirm with PCR\"       tests_used[i] <- \"Rapid\"     } else if (data$symptom_score[i] >= 6) {       # Step 2: High symptom score → CT       if (!is.na(data$chest_ct[i]) && data$chest_ct[i] == \"Abnormal\") {         decisions[i] <- \"Probable COVID, Isolate, PCR\"         tests_used[i] <- \"Rapid + CT\"       } else {         decisions[i] <- \"Low probability, Standard care\"         tests_used[i] <- \"Rapid + CT\"       }     } else {       decisions[i] <- \"Low probability, Standard care\"       tests_used[i] <- \"Rapid\"     }   }      return(data.frame(Decision = decisions, Tests = tests_used)) }  # Apply algorithm algorithm_results <- apply_covid_algorithm(covid_screening_data[1:10,]) kable(cbind(covid_screening_data[1:10, c(\"patient_id\", \"rapid_antigen\",                                           \"symptom_score\", \"covid_status\")],             algorithm_results))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "cost-effectiveness-visualization",
        "dir": "Articles",
        "previous_headings": "Scenario 1: Emergency Department COVID-19 Screening",
        "what": "Cost-Effectiveness Visualization",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Simulate different strategies strategies <- expand.grid(   use_rapid = c(TRUE, FALSE),   use_pcr = c(TRUE, FALSE),   use_ct = c(TRUE, FALSE) ) %>%   filter(use_rapid | use_pcr | use_ct) # At least one test  # Calculate performance for each strategy strategy_performance <- strategies %>%   rowwise() %>%   mutate(     tests = paste(c(       if(use_rapid) \"RAT\" else NULL,       if(use_pcr) \"PCR\" else NULL,       if(use_ct) \"CT\" else NULL     ), collapse = \"+\"),     cost = sum(c(       if(use_rapid) 5 else 0,       if(use_pcr) 50 else 0,       if(use_ct) 200 else 0     )),     # Simulated performance (would come from actual analysis)     sensitivity = case_when(       use_rapid & use_pcr & use_ct ~ 0.99,       use_pcr & use_ct ~ 0.98,       use_rapid & use_pcr ~ 0.97,       use_pcr ~ 0.95,       use_rapid & use_ct ~ 0.94,       use_ct ~ 0.90,       use_rapid ~ 0.65     ),     specificity = case_when(       use_rapid & use_pcr & use_ct ~ 0.83,       use_pcr & use_ct ~ 0.84,       use_rapid & use_pcr ~ 0.97,       use_pcr ~ 0.99,       use_rapid & use_ct ~ 0.83,       use_ct ~ 0.85,       use_rapid ~ 0.98     )   )  # Create cost-effectiveness plot ggplot(strategy_performance, aes(x = cost, y = sensitivity * 100)) +   geom_point(aes(size = specificity * 100), alpha = 0.6) +   geom_text(aes(label = tests), vjust = -1, size = 3) +   geom_line(data = strategy_performance %>%                arrange(cost) %>%               filter(sensitivity == cummax(sensitivity)),             color = \"red\", alpha = 0.5) +   scale_size_continuous(name = \"Specificity (%)\", range = c(3, 10)) +   labs(     title = \"Cost-Effectiveness of COVID-19 Testing Strategies\",     x = \"Cost per Patient ($)\",     y = \"Sensitivity (%)\",     caption = \"Red line shows cost-effectiveness frontier\"   ) +   theme_minimal()"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-context-1",
        "dir": "Articles",
        "previous_headings": "Scenario 2: Breast Cancer Screening Program",
        "what": "Clinical Context",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "population-based breast cancer screening program needs optimize use mammography, ultrasound, MRI based risk factors.",
        "code": "# Examine population characteristics breast_summary <- breast_cancer_data %>%   summarise(     n = n(),     prevalence = mean(cancer_status == \"Cancer\"),     mean_age = mean(age),     pct_family_history = mean(family_history == \"Yes\") * 100,     pct_brca = mean(brca_mutation == \"Positive\") * 100,     pct_dense_breast = mean(breast_density %in% c(\"C\", \"D\")) * 100   )  kable(breast_summary, digits = 2,       caption = \"Population Characteristics\")  # Risk stratification breast_cancer_data <- breast_cancer_data %>%   mutate(     risk_category = case_when(       brca_mutation == \"Positive\" ~ \"High Risk\",       family_history == \"Yes\" & age < 50 ~ \"High Risk\",       family_history == \"Yes\" | breast_density == \"D\" ~ \"Moderate Risk\",       TRUE ~ \"Average Risk\"     )   )  table(breast_cancer_data$risk_category)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "risk-stratified-analysis",
        "dir": "Articles",
        "previous_headings": "Scenario 2: Breast Cancer Screening Program",
        "what": "Risk-Stratified Analysis",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Analyze each risk group separately risk_groups <- split(breast_cancer_data, breast_cancer_data$risk_category)  # High-risk group optimization high_risk_panel <- decisionpanel(   data = risk_groups$`High Risk`,   tests = c(\"mammography\", \"ultrasound\", \"mri\"),   testLevels = c(\"BIRADS 3-5\", \"Suspicious\", \"Suspicious\"),   gold = \"cancer_status\",   goldPositive = \"Cancer\",   strategies = \"all\",   optimizationCriteria = \"sensitivity\",   minSensitivity = 0.95 )  # Average-risk group optimization (cost-conscious) average_risk_panel <- decisionpanel(   data = risk_groups$`Average Risk`,   tests = c(\"clinical_exam\", \"mammography\", \"ultrasound\"),   testLevels = c(\"Abnormal\", \"BIRADS 3-5\", \"Suspicious\"),   gold = \"cancer_status\",   goldPositive = \"Cancer\",   strategies = \"all\",   optimizationCriteria = \"efficiency\",   useCosts = TRUE,   testCosts = \"20,100,150\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "screening-recommendations-by-risk",
        "dir": "Articles",
        "previous_headings": "Scenario 2: Breast Cancer Screening Program",
        "what": "Screening Recommendations by Risk",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Create recommendation table recommendations <- data.frame(   Risk_Category = c(\"High Risk\", \"Moderate Risk\", \"Average Risk\"),   Recommended_Tests = c(     \"Annual MRI + Mammography\",     \"Annual Mammography + US if dense\",     \"Biennial Mammography\"   ),   Expected_Sensitivity = c(\"99%\", \"90%\", \"85%\"),   Expected_Specificity = c(\"80%\", \"92%\", \"95%\"),   Cost_per_Screen = c(\"$1,100\", \"$250\", \"$100\"),   NNS = c(50, 200, 500)  # Number needed to screen )  kable(recommendations,        caption = \"Risk-Stratified Screening Recommendations\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "age-specific-performance",
        "dir": "Articles",
        "previous_headings": "Scenario 2: Breast Cancer Screening Program",
        "what": "Age-Specific Performance",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Analyze performance by age group age_groups <- breast_cancer_data %>%   mutate(age_group = cut(age, breaks = c(40, 50, 60, 70, 80),                          labels = c(\"40-49\", \"50-59\", \"60-69\", \"70-79\")))  # Calculate mammography performance by age age_performance <- age_groups %>%   group_by(age_group) %>%   summarise(     n = n(),     prevalence = mean(cancer_status == \"Cancer\"),     mammography_sens = {       tab <- table(mammography, cancer_status)       if(nrow(tab) == 2 && ncol(tab) == 2) {         tab[2,2] / sum(tab[,2])       } else NA     },     mammography_spec = {       tab <- table(mammography, cancer_status)       if(nrow(tab) == 2 && ncol(tab) == 2) {         tab[1,1] / sum(tab[,1])       } else NA     }   )  # Visualize ggplot(age_performance, aes(x = age_group)) +   geom_bar(aes(y = mammography_sens * 100), stat = \"identity\",             fill = \"skyblue\", alpha = 0.7) +   geom_line(aes(y = prevalence * 1000, group = 1), color = \"red\", size = 2) +   geom_point(aes(y = prevalence * 1000), color = \"red\", size = 3) +   scale_y_continuous(     name = \"Mammography Sensitivity (%)\",     sec.axis = sec_axis(~./10, name = \"Cancer Prevalence per 1000\")   ) +   labs(     title = \"Mammography Performance by Age Group\",     x = \"Age Group\"   ) +   theme_minimal()"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-context-2",
        "dir": "Articles",
        "previous_headings": "Scenario 3: Tuberculosis Case Finding",
        "what": "Clinical Context",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "TB program high-burden setting needs optimize case finding limited resources.",
        "code": "# TB test combinations for different settings tb_settings <- data.frame(   Setting = c(\"Community\", \"Clinic\", \"Hospital\", \"Contact Tracing\"),   Prevalence = c(0.02, 0.20, 0.40, 0.10),   Available_Tests = c(     \"Symptoms, CXR\",     \"Symptoms, Smear, GeneXpert, CXR\",     \"All tests\",     \"Symptoms, GeneXpert\"   ),   Budget_per_case = c(10, 30, 100, 50) )  kable(tb_settings, caption = \"TB Testing Scenarios by Setting\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "sequential-testing-algorithm",
        "dir": "Articles",
        "previous_headings": "Scenario 3: Tuberculosis Case Finding",
        "what": "Sequential Testing Algorithm",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Implement WHO-recommended algorithm apply_tb_algorithm <- function(data) {   decisions <- character(nrow(data))      for (i in 1:nrow(data)) {     if (data$symptoms[i] == \"Yes\" || data$contact_history[i] == \"Yes\") {       # Symptomatic or contact: get GeneXpert       if (!is.na(data$genexpert[i]) && data$genexpert[i] == \"MTB detected\") {         decisions[i] <- \"Start TB treatment\"       } else if (!is.na(data$chest_xray[i]) && data$chest_xray[i] == \"Abnormal\") {         # CXR abnormal but GeneXpert negative         if (!is.na(data$culture[i])) {           decisions[i] <- ifelse(data$culture[i] == \"Positive\",                                 \"Start TB treatment\",                                 \"Not TB, investigate other causes\")         } else {           decisions[i] <- \"Clinical decision needed\"         }       } else {         decisions[i] <- \"TB unlikely\"       }     } else {       # Asymptomatic: screen with CXR if available       if (!is.na(data$chest_xray[i]) && data$chest_xray[i] == \"Abnormal\") {         decisions[i] <- \"Needs further testing\"       } else {         decisions[i] <- \"No TB screening needed\"       }     }   }      return(decisions) }  # Apply to sample tb_sample <- tb_diagnosis_data[1:20,] tb_sample$decision <- apply_tb_algorithm(tb_sample)  # Show results kable(tb_sample %>%        select(patient_id, symptoms, genexpert, chest_xray, tb_status, decision) %>%       head(10))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "cost-effectiveness-by-strategy",
        "dir": "Articles",
        "previous_headings": "Scenario 3: Tuberculosis Case Finding",
        "what": "Cost-Effectiveness by Strategy",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Compare different TB screening strategies tb_strategies <- data.frame(   Strategy = c(     \"Symptoms only\",     \"Symptoms → Smear\",     \"Symptoms → GeneXpert\",      \"Symptoms → CXR → GeneXpert\",     \"Universal GeneXpert\",     \"Universal CXR → GeneXpert\"   ),   Tests_per_case_found = c(100, 50, 20, 15, 10, 12),   Cost_per_case_found = c(100, 200, 400, 350, 800, 600),   Sensitivity = c(60, 70, 85, 92, 95, 93),   Time_to_diagnosis = c(0, 3, 1, 2, 1, 1) )  # Create multi-dimensional comparison ggplot(tb_strategies, aes(x = Cost_per_case_found, y = Sensitivity)) +   geom_point(aes(size = Tests_per_case_found,                   color = factor(Time_to_diagnosis)), alpha = 0.7) +   geom_text(aes(label = Strategy), vjust = -1, size = 3) +   scale_size_continuous(name = \"Tests per case\", range = c(3, 10)) +   scale_color_discrete(name = \"Days to diagnosis\") +   labs(     title = \"TB Screening Strategy Comparison\",     x = \"Cost per TB case found ($)\",     y = \"Sensitivity (%)\"   ) +   theme_minimal()"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-context-3",
        "dir": "Articles",
        "previous_headings": "Scenario 4: Chest Pain Evaluation",
        "what": "Clinical Context",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "Emergency department evaluation chest pain requires rapid, accurate rule-myocardial infarction.",
        "code": "# Risk stratification using HEART score components mi_ruleout_data <- mi_ruleout_data %>%   mutate(     heart_score = (age > 65) * 1 +                   (chest_pain == \"Typical\") * 2 +                   (chest_pain == \"Atypical\") * 1 +                   (ecg == \"Ischemic changes\") * 2 +                   (prior_cad == \"Yes\") * 1 +                   (diabetes == \"Yes\" | smoking == \"Yes\") * 1,     risk_category = cut(heart_score,                         breaks = c(-1, 3, 6, 10),                        labels = c(\"Low\", \"Moderate\", \"High\"))   )  # Show risk distribution risk_table <- table(mi_ruleout_data$risk_category, mi_ruleout_data$mi_status) kable(prop.table(risk_table, margin = 1) * 100,       digits = 1,       caption = \"MI Prevalence by Risk Category (%)\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "time-sensitive-protocols",
        "dir": "Articles",
        "previous_headings": "Scenario 4: Chest Pain Evaluation",
        "what": "Time-Sensitive Protocols",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Define protocols by urgency protocols <- list(   rapid_rule_out = function(data) {     # 0/1-hour protocol     data$troponin_initial == \"Normal\" &      data$ecg == \"Normal\" &      data$heart_score <= 3   },      standard_rule_out = function(data) {     # 0/3-hour protocol     data$troponin_initial == \"Normal\" &      data$troponin_3hr == \"Normal\" &     data$ecg == \"Normal\"   },      rule_in = function(data) {     # Immediate rule-in     data$troponin_initial == \"Elevated\" &      data$ecg == \"Ischemic changes\"   } )  # Apply protocols mi_ruleout_data <- mi_ruleout_data %>%   mutate(     rapid_rule_out = protocols$rapid_rule_out(.),     standard_rule_out = protocols$standard_rule_out(.) & !rapid_rule_out,     rule_in = protocols$rule_in(.),     need_further_testing = !rapid_rule_out & !standard_rule_out & !rule_in   )  # Summarize protocol performance protocol_performance <- mi_ruleout_data %>%   summarise(     rapid_rule_out_pct = mean(rapid_rule_out) * 100,     rapid_rule_out_npv = sum(rapid_rule_out & mi_status == \"No MI\") /                           sum(rapid_rule_out) * 100,     standard_rule_out_pct = mean(standard_rule_out) * 100,     standard_rule_out_npv = sum(standard_rule_out & mi_status == \"No MI\") /                             sum(standard_rule_out) * 100,     rule_in_pct = mean(rule_in) * 100,     rule_in_ppv = sum(rule_in & mi_status == \"MI\") / sum(rule_in) * 100   )  kable(t(protocol_performance), digits = 1,       caption = \"Protocol Performance Metrics\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "visualization-of-patient-flow",
        "dir": "Articles",
        "previous_headings": "Scenario 4: Chest Pain Evaluation",
        "what": "Visualization of Patient Flow",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Create patient flow diagram data flow_data <- mi_ruleout_data %>%   mutate(     disposition = case_when(       rapid_rule_out ~ \"Discharge (1 hour)\",       standard_rule_out ~ \"Discharge (3 hours)\",       rule_in ~ \"Admit CCU\",       TRUE ~ \"Observation/Further testing\"     )   ) %>%   group_by(disposition, mi_status) %>%   summarise(n = n()) %>%   mutate(pct = n / sum(n) * 100)  # Create flow diagram ggplot(flow_data, aes(x = disposition, y = n, fill = mi_status)) +   geom_bar(stat = \"identity\", position = \"stack\") +   geom_text(aes(label = sprintf(\"%.0f%%\", pct)),              position = position_stack(vjust = 0.5)) +   scale_fill_manual(values = c(\"No MI\" = \"lightgreen\", \"MI\" = \"salmon\")) +   labs(     title = \"Patient Disposition by Protocol\",     x = \"Disposition\",     y = \"Number of Patients\",     fill = \"Final Diagnosis\"   ) +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "clinical-context-4",
        "dir": "Articles",
        "previous_headings": "Scenario 5: Thyroid Nodule Evaluation",
        "what": "Clinical Context",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "Thyroid nodules common cancer rare. Optimize use FNA, molecular testing, surgery.",
        "code": "# Analyze by nodule size thyroid_by_size <- thyroid_nodule_data %>%   mutate(size_category = cut(nodule_size,                               breaks = c(0, 10, 20, 40, 100),                              labels = c(\"<1cm\", \"1-2cm\", \"2-4cm\", \">4cm\"))) %>%   group_by(size_category) %>%   summarise(     n = n(),     cancer_rate = mean(cancer_status == \"Malignant\") * 100,     fna_done = mean(!is.na(fna_cytology)) * 100,     molecular_done = mean(!is.na(molecular_test)) * 100   )  kable(thyroid_by_size, digits = 1,       caption = \"Thyroid Nodule Characteristics by Size\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "diagnostic-algorithm-implementation",
        "dir": "Articles",
        "previous_headings": "Scenario 5: Thyroid Nodule Evaluation",
        "what": "Diagnostic Algorithm Implementation",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Implement Bethesda-based algorithm thyroid_algorithm <- decisionpanel(   data = thyroid_nodule_data,   tests = c(\"ultrasound\", \"fna_cytology\", \"molecular_test\"),   testLevels = c(\"TI-RADS 4-5\", \"Suspicious/Malignant\", \"Suspicious\"),   gold = \"cancer_status\",   goldPositive = \"Malignant\",   strategies = \"sequential\",   sequentialStop = \"positive\",   createTree = TRUE,   treeMethod = \"cart\",   useCosts = TRUE,   testCosts = \"200,300,3000\",  # US, FNA, Molecular   fpCost = 10000,  # Unnecessary surgery   fnCost = 50000   # Missed cancer )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "decision-tree-visualization",
        "dir": "Articles",
        "previous_headings": "Scenario 5: Thyroid Nodule Evaluation",
        "what": "Decision Tree Visualization",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "# Simplified decision tree representation cat(\"Thyroid Nodule Evaluation Algorithm:\\n\") cat(\"1. Ultrasound Assessment\\n\") cat(\"   ├─ TI-RADS 1-2: No FNA needed\\n\") cat(\"   └─ TI-RADS 3-5: Proceed to FNA\\n\") cat(\"      ├─ Benign (Bethesda II): Follow-up\\n\") cat(\"      ├─ Indeterminate (Bethesda III-IV): Molecular testing\\n\") cat(\"      │  ├─ Benign profile: Follow-up\\n\") cat(\"      │  └─ Suspicious profile: Surgery\\n\") cat(\"      └─ Suspicious/Malignant (Bethesda V-VI): Surgery\\n\")  # Create visual representation of outcomes outcomes <- data.frame(   Test_Path = c(\"US only\", \"US+FNA\", \"US+FNA+Molecular\", \"Direct Surgery\"),   Patients_pct = c(40, 30, 20, 10),   Cancers_found_pct = c(0, 20, 60, 20),   Cost = c(200, 500, 3500, 200) )  ggplot(outcomes, aes(x = Test_Path, y = Patients_pct)) +   geom_bar(stat = \"identity\", fill = \"lightblue\", alpha = 0.7) +   geom_line(aes(y = Cancers_found_pct, group = 1), color = \"red\", size = 2) +   geom_point(aes(y = Cancers_found_pct), color = \"red\", size = 3) +   scale_y_continuous(     name = \"Percentage of Patients\",     sec.axis = sec_axis(~., name = \"Percentage of Cancers Found\")   ) +   labs(     title = \"Thyroid Nodule Evaluation Pathways\",     x = \"Testing Path\"   ) +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "key-learnings-across-scenarios",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "Key Learnings Across Scenarios",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "Context Matters: Optimal strategies differ screening diagnosis Sequential Testing: Often efficient parallel testing Risk Stratification: Improves efficiency outcomes Cost Considerations: Must balance performance resources Implementation: Clear algorithms improve adoption",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "general-recommendations",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "General Recommendations",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "summary_recommendations <- data.frame(   Scenario = c(\"Screening\", \"Diagnosis\", \"Emergency\", \"Surveillance\"),   Priority = c(\"High Sensitivity\", \"Balanced\", \"Speed + Accuracy\", \"Specificity\"),   Strategy = c(\"Parallel OR\", \"Sequential\", \"Rapid protocols\", \"Confirmatory\"),   Key_Metric = c(\"NPV\", \"Accuracy\", \"Time to decision\", \"PPV\"),   Example = c(\"Cancer screening\", \"TB diagnosis\", \"Chest pain\", \"Cancer follow-up\") )  kable(summary_recommendations,       caption = \"Testing Strategy Recommendations by Clinical Scenario\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "future-directions",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "Future Directions",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "Machine Learning Integration: Combine multiple variables beyond just test results Dynamic Protocols: Adapt based local prevalence resources Real-time Optimization: Update algorithms based performance data Patient Preferences: Include patient values decision-making",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-decision-panel-clinical.html",
        "id": "session-information",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Session Information",
        "title": "Clinical Applications of Decision Panel Optimization",
        "text": "",
        "code": "sessionInfo()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "kappasizefixedn function specialized power analysis tool helps researchers determine expected lower bound kappa (κ) agreement coefficients working fixed, predetermined sample size. Unlike traditional sample size calculations determine many subjects need target effect size, function answers question: “Given access N subjects, level agreement can reliably detect?”",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "when-to-use-kappasizefixedn",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "When to Use kappasizefixedn",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "function particularly valuable research scenarios : Sample size constrained practical limitations (e.g., rare diseases, expensive procedures) Retrospective studies using existing databases specimen collections Pilot studies limited resources Multi-site studies contributing sites varying patient volumes Grant planning need justify feasibility available resources",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "fixed-sample-size-analysis",
        "dir": "Articles",
        "previous_headings": "Introduction > Key Concepts",
        "what": "Fixed Sample Size Analysis",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Traditional power analysis follows pattern: Effect Size + Power + Alpha → Sample Size Fixed sample size analysis follows: Sample Size + Effect Size + Alpha → Power/Precision",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "lower-bound-interpretation",
        "dir": "Articles",
        "previous_headings": "Introduction > Key Concepts",
        "what": "Lower Bound Interpretation",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "function calculates lower confidence bound kappa, representing minimum level agreement can reliably detect available sample size. helps assess whether study adequate power detect meaningful agreement levels.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "kappa-coefficient-overview",
        "dir": "Articles",
        "previous_headings": "Theoretical Background",
        "what": "Kappa Coefficient Overview",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Cohen’s kappa (κ) measures inter-rater agreement categorical data, accounting agreement might occur chance: κ=po−pe1−pe\\kappa = \\frac{p_o - p_e}{1 - p_e} : - pop_o = observed agreement - pep_e = expected agreement chance",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "statistical-framework",
        "dir": "Articles",
        "previous_headings": "Theoretical Background",
        "what": "Statistical Framework",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "kappasizefixedn function uses kappaSize package implementation variance formulas different numbers outcome categories:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "binary-outcomes-2-categories",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Statistical Framework",
        "what": "Binary Outcomes (2 categories)",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Uses asymptotic variance estimates binary kappa corrections finite samples.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "multi-category-outcomes-3-5-categories",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Statistical Framework",
        "what": "Multi-category Outcomes (3-5 categories)",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Employs generalized kappa variance formulas account : - Number categories - Marginal probability distributions - Number raters - Sample size effects",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "basic-syntax",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage",
        "what": "Basic Syntax",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "",
        "code": "kappaSizeFixedN(   outcome = \"2\",           # Number of categories (2, 3, 4, or 5)   kappa0 = 0.60,          # Expected kappa value   props = \"0.30, 0.70\",   # Category proportions   raters = \"2\",           # Number of raters (2-5)   alpha = 0.05,           # Significance level   n = 100                 # Available sample size )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "outcome-number-of-outcome-categories",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "outcome: Number of Outcome Categories",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Options: “2”, “3”, “4”, “5” Purpose: Determines statistical model use 2: Disease present/absent, malignant/benign, positive/negative test 3: Mild/moderate/severe, low/medium/high risk 4: grade 1-4, ECOG performance status 0-3 5: Likert scales, pain intensity scales",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "kappa0-expected-kappa-value",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "kappa0: Expected Kappa Value",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Range: 0.01 0.99 (exclusive) Purpose: level agreement expect observe Guidance: Base literature review, pilot data, clinical expertise",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "props-category-proportions",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "props: Category Proportions",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Format: Comma-separated proportions sum 1.0 Binary: “0.25, 0.75” (25% disease prevalence) Three-category: “0.20, 0.50, 0.30” (mild, moderate, severe) Sources: Literature, registry data, clinical experience",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "raters-number-of-raters",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "raters: Number of Raters",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Options: “2”, “3”, “4”, “5” Impact: raters can improve precision increase complexity Practical considerations: Availability, cost, logistics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "alpha-significance-level",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "alpha: Significance Level",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Common values: 0.05 (5%), 0.01 (1%) Impact: Lower alpha provides conservative bounds Selection: Based field standards study importance",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "n-available-sample-size",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "n: Available Sample Size",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Requirements: Positive integer ≥ 10 Reality check: Must reflect actual constraints (budget, time, access)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "example-1-emergency-department-chest-x-ray-agreement",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Medical Diagnosis Studies",
        "what": "Example 1: Emergency Department Chest X-ray Agreement",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Scenario: Two emergency physicians reviewing chest X-rays pneumonia detection 80 available cases. Clinical Context: - Emergency departments natural patient flow limitations - Quick decision-making requires reliable agreement physicians - Cost-effective validation diagnostic protocols",
        "code": "# Emergency department pneumonia detection result <- kappaSizeFixedN(   outcome = \"2\",   kappa0 = 0.65,          # Expected good agreement   props = \"0.25, 0.75\",   # 25% pneumonia prevalence   raters = \"2\",           # Two emergency physicians   alpha = 0.05,   n = 80                  # Available ED cases )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "example-2-pathology-tumor-grading",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Medical Diagnosis Studies",
        "what": "Example 2: Pathology Tumor Grading",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Scenario: Three pathologists grading tumor differentiation 160 available specimens. Clinical Context: - Tumor banks finite specimen availability - Grading consistency affects treatment decisions - Multi-institutional studies require agreement validation",
        "code": "# Tumor grading agreement study result <- kappaSizeFixedN(   outcome = \"4\",   kappa0 = 0.75,                           # Expected strong agreement   props = \"0.15, 0.25, 0.35, 0.25\",       # Grade 1, 2, 3, 4 distribution   raters = \"3\",                            # Three pathologists   alpha = 0.05,   n = 160                                  # Available tumor specimens )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "example-3-cognitive-impairment-assessment",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Multi-Category Assessments",
        "what": "Example 3: Cognitive Impairment Assessment",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Scenario: Two neuropsychologists assessing cognitive status 90 available patients. Clinical Context: - Specialized cognitive testing requires trained personnel - Limited patient availability memory clinics - Diagnostic consistency crucial treatment planning",
        "code": "# Cognitive impairment assessment result <- kappaSizeFixedN(   outcome = \"4\",   kappa0 = 0.70,   props = \"0.20, 0.30, 0.30, 0.20\",      # Normal, MCI, Mild, Moderate+ dementia   raters = \"2\",                            # Two neuropsychologists     alpha = 0.05,   n = 90                                   # Available cognitive assessments )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "example-4-burn-severity-grading",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Multi-Category Assessments",
        "what": "Example 4: Burn Severity Grading",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Scenario: Three emergency physicians grading burn severity 75 available cases.",
        "code": "# Burn severity grading study result <- kappaSizeFixedN(   outcome = \"3\",   kappa0 = 0.75,   props = \"0.40, 0.35, 0.25\",            # First, second, third degree   raters = \"3\",                           # Three emergency physicians   alpha = 0.05,   n = 75                                  # Available burn cases )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "example-5-systematic-review-quality-assessment",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Research Methodology Applications",
        "what": "Example 5: Systematic Review Quality Assessment",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Scenario: Two researchers assessing study quality 60 available papers. Research Context: - Systematic reviews limited available literature - Quality assessment affects meta-analysis inclusion - Agreement validation required methodology papers",
        "code": "# Study quality assessment for systematic review result <- kappaSizeFixedN(   outcome = \"3\",   kappa0 = 0.70,   props = \"0.25, 0.45, 0.30\",            # Low, moderate, high quality   raters = \"2\",                           # Two researchers   alpha = 0.05,   n = 60                                  # Available studies )"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "rare-disease-studies",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Dealing with Unbalanced Proportions",
        "what": "Rare Disease Studies",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "studying rare conditions, category proportions can highly unbalanced: Considerations Unbalanced Data: - Requires larger sample sizes reliable estimates - May need stratified analysis approaches - Consider specialized statistical methods rare events",
        "code": "# Rare disease diagnosis agreement result <- kappaSizeFixedN(   outcome = \"2\",   kappa0 = 0.80,   props = \"0.05, 0.95\",                   # 5% rare disease prevalence   raters = \"3\",   alpha = 0.05,   n = 200                                 # Large sample needed for rare events )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "large-consensus-panels",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Multi-Rater Scenarios",
        "what": "Large Consensus Panels",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Multi-rater Considerations: - Agreement typically decreases raters - Computational complexity increases - May require hierarchical staged agreement protocols",
        "code": "# Multi-expert consensus study result <- kappaSizeFixedN(   outcome = \"5\",   kappa0 = 0.60,                          # Lower expected agreement with more raters   props = \"0.10, 0.20, 0.35, 0.25, 0.10\", # Symmetric distribution   raters = \"5\",                           # Five expert raters   alpha = 0.01,                           # Strict significance level   n = 150 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "finding-the-optimal-trade-off",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Sample Size Optimization",
        "what": "Finding the Optimal Trade-off",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "flexibility sample size, can explore different scenarios:",
        "code": "# Compare different sample sizes sample_sizes <- c(50, 100, 150, 200, 250)  results <- list() for (n in sample_sizes) {   results[[paste0(\"n_\", n)]] <- kappaSizeFixedN(     outcome = \"3\",     kappa0 = 0.65,     props = \"0.30, 0.40, 0.30\",     raters = \"2\",     alpha = 0.05,     n = n   ) }  # Analysis of results would show diminishing returns pattern"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "realistic-expectation-setting",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "1. Realistic Expectation Setting",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Base kappa0 literature review pilot data Consider inter-rater agreement often decreases real-world settings Account rater training experience levels",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "proportion-estimation",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "2. Proportion Estimation",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Use registry data, literature reviews, pilot studies Consider seasonal temporal variations Account selection bias available samples",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "rater-selection",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "3. Rater Selection",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Training: Ensure consistent training across raters Experience: Balance expertise availability Independence: Maintain rater independence scoring",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "sample-size-constraints",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "4. Sample Size Constraints",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "realistic practical limitations Document constraints study protocols Consider power implications interpretation",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "overly-optimistic-kappa-expectations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "1. Overly Optimistic Kappa Expectations",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Problem: Setting kappa0 high based idealized conditions Solution: - Review literature realistic agreement levels - Conduct small pilot studies - Account real-world variability",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "ignoring-practical-constraints",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "2. Ignoring Practical Constraints",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Problem: considering rater availability, cost, time constraints Solution: - Factor practical limitations early planning - contingency plans lower sample sizes - Consider staged adaptive designs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "inadequate-proportion-estimation",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "3. Inadequate Proportion Estimation",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Problem: Using unrealistic outdated prevalence estimates Solution: - Use multiple data sources proportion estimates - Conduct sensitivity analyses different proportions - Update estimates preliminary data becomes available",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "pre-study-checklist",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Quality Assurance",
        "what": "Pre-study Checklist",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Literature review completed expected kappa values Realistic proportion estimates obtained Rater training protocol established Sample size constraints documented Power analysis results acceptable study goals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "during-study-monitoring",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Quality Assurance",
        "what": "During-study Monitoring",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Track actual vs. expected proportions Monitor rater consistency/drift Document protocol deviations Consider interim power analyses",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "understanding-the-output",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results",
        "what": "Understanding the Output",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "kappasizefixedn function provides two main outputs: Statistical Result: lower confidence bound kappa Study Explanation: Detailed interpretation parameters context",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "statistical-interpretation",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Understanding the Output",
        "what": "Statistical Interpretation",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "lower bound represents minimum level agreement can reliably detect sample size. value meets clinical research threshold meaningful agreement, study adequate power.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "clinical-decision-making",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Understanding the Output",
        "what": "Clinical Decision Making",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Use results : - Justify feasibility grant applications - Set realistic expectations stakeholders - Inform protocol modifications power inadequate - Support statistical analysis plans",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "in-methods-sections",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Methods Sections",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "“Power analysis using kappasizefixedn function indicated available sample size N subjects expected kappa X, reliably detect lower bound Y 95% confidence (α = 0.05).”",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "in-results-sections",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Results Sections",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Report observed kappa compare expected lower bound power analysis.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "in-discussion-sections",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Discussion Sections",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Address discrepancies expected observed agreement levels, discuss implications study conclusions.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "proportions-must-sum-to-1",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“Proportions must sum to 1”",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Cause: Category proportions don’t sum exactly 1.0 Solution: Adjust proportions use normalized values",
        "code": "# Incorrect props = \"0.25, 0.80\"  # Sums to 1.05  # Correct   props = \"0.24, 0.76\"  # Sums to 1.00"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "sample-size-too-small",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“Sample size too small”",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Cause: Sample size less minimum recommended (typically 10) Solution: - Increase sample size possible - Consider alternative study designs - Use specialized small-sample methods",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "kappasize-package-not-installed",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“kappaSize package not installed”",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Cause: Required dependency available Solution: Install kappaSize package",
        "code": "install.packages(\"kappaSize\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "very-small-or-large-kappa-values",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Computational Issues",
        "what": "Very Small or Large Kappa Values",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Extreme kappa values (< 0.1 > 0.95) may cause computational issues: Solutions: - Verify extreme values realistic - Consider alternative agreement measures extreme cases - Increase sample size stable estimates",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "complex-multi-rater-scenarios",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Computational Issues",
        "what": "Complex Multi-rater Scenarios",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "4-5 raters 4-5 categories, computations become complex: Solutions: - Ensure adequate sample size (n > 100 recommended) - Consider staged agreement protocols - Validate results simulation studies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "complementary-functions",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Complementary Functions",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "kappasizefixedn function works well alongside: kappasizeci: traditional sample size calculations power analysis tools: comprehensive study planning Agreement analysis functions: post-hoc agreement assessment",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "advanced-methods",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Advanced Methods",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "specialized scenarios, consider: Weighted kappa: ordinal categories meaningful ordering Multilevel models: hierarchical data structures Bayesian approaches: incorporating prior information",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "software-integration",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Software Integration",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "function integrates well : jamovi: User-friendly interface clinical researchers R workflows: Programmable analysis pipelines Reproducible research: RMarkdown Quarto integration",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "summary",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Summary",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "kappasizefixedn function provides essential power analysis capabilities inter-rater agreement studies fixed sample sizes. Key takeaways: Use sample size constrained practical limitations Provides lower confidence bounds detectable agreement levels Supports 2-5 categories 2-5 raters Requires realistic parameter estimates meaningful results Integrates comprehensive study planning workflows understanding properly applying tool, researchers can make informed decisions study feasibility set appropriate expectations inter-rater agreement analyses.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/08-kappasizefixedn-comprehensive.html",
        "id": "references",
        "dir": "Articles",
        "previous_headings": "",
        "what": "References",
        "title": "Complete Guide to kappasizefixedn: Fixed Sample Size Kappa Power Analysis",
        "text": "Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20(1), 37-46. Fleiss, J. L., Levin, B., & Paik, M. C. (2003). Statistical methods rates proportions. John Wiley & Sons. Gwet, K. L. (2014). Handbook inter-rater reliability: definitive guide measuring extent agreement among raters. Advanced Analytics, LLC. Landis, J. R., & Koch, G. G. (1977). measurement observer agreement categorical data. Biometrics, 33(1), 159-174. Shoukri, M. M. (2011). Measures interobserver agreement reliability. Chapman Hall/CRC. vignette generated using ClinicoPath R package. information, visit ClinicoPath GitHub repository.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "vignette covers advanced features Decision Panel Optimization module, including custom optimization functions, complex constraints, programmatic access results.",
        "code": "# Load required packages library(meddecide) library(dplyr) library(ggplot2) library(rpart) library(rpart.plot) library(knitr) library(forcats) # Set seed for reproducibility set.seed(123)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "defining-custom-utility-functions",
        "dir": "Articles",
        "previous_headings": "Custom Optimization Functions",
        "what": "Defining Custom Utility Functions",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "module allows custom utility functions incorporate domain-specific knowledge:",
        "code": "# Define a custom utility function for COVID screening # Prioritizes not missing cases while considering hospital capacity covid_utility <- function(TP, FP, TN, FN, test_cost, hospital_capacity = 100) {   # Base utilities   u_TP <- 100    # Correctly identified case   u_TN <- 10     # Correctly ruled out   u_FP <- -20    # Unnecessary isolation   u_FN <- -1000  # Missed case (high penalty)      # Capacity penalty - increases FP cost when near capacity   current_positives <- TP + FP   capacity_factor <- ifelse(current_positives > hospital_capacity * 0.8,                            (current_positives / hospital_capacity)^2,                            1)   u_FP_adjusted <- u_FP * capacity_factor      # Calculate total utility   total_utility <- (TP * u_TP + TN * u_TN +                     FP * u_FP_adjusted + FN * u_FN - test_cost)      return(total_utility) }  # Example calculation n_total <- 1000 prevalence <- 0.15 test_cost <- 55  # Combined test cost  # Scenario 1: Low capacity utility_low_capacity <- covid_utility(   TP = 147,  # 98% sensitivity   FP = 26,   # 97% specificity     TN = 824,   FN = 3,   test_cost = test_cost,   hospital_capacity = 50 )  # Scenario 2: High capacity utility_high_capacity <- covid_utility(   TP = 147,   FP = 26,   TN = 824,   FN = 3,   test_cost = test_cost,   hospital_capacity = 200 )  cat(\"Utility with low capacity:\", utility_low_capacity, \"\\n\") cat(\"Utility with high capacity:\", utility_high_capacity, \"\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "implementing-multi-objective-optimization",
        "dir": "Articles",
        "previous_headings": "Custom Optimization Functions",
        "what": "Implementing Multi-Objective Optimization",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "multiple objectives conflict, use Pareto optimization:",
        "code": "# Generate test combinations and their performance generate_pareto_data <- function(data, tests, gold, gold_positive) {   # Get all possible test combinations   all_combinations <- list()      for (i in 1:length(tests)) {     combos <- combn(tests, i, simplify = FALSE)     all_combinations <- c(all_combinations, combos)   }      # Calculate metrics for each combination   results <- data.frame()      for (combo in all_combinations) {     # Simulate parallel ANY rule     test_positive <- rowSums(data[combo] == \"Positive\" |                             data[combo] == \"Abnormal\" |                             data[combo] == \"MTB detected\",                            na.rm = TRUE) > 0          truth <- data[[gold]] == gold_positive          # Calculate metrics     TP <- sum(test_positive & truth)     FP <- sum(test_positive & !truth)     TN <- sum(!test_positive & !truth)     FN <- sum(!test_positive & truth)          sensitivity <- TP / (TP + FN)     specificity <- TN / (TN + FP)          # Simulated costs     test_costs <- c(rapid_antigen = 5, pcr = 50, chest_ct = 200)     total_cost <- sum(test_costs[combo])          results <- rbind(results, data.frame(       tests = paste(combo, collapse = \"+\"),       n_tests = length(combo),       sensitivity = sensitivity,       specificity = specificity,       cost = total_cost     ))   }      return(results) }  # Generate Pareto frontier for COVID tests pareto_data <- generate_pareto_data(   covid_screening_data[1:500,],  # Use subset for speed   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   gold = \"covid_status\",   gold_positive = \"Positive\" )  # Identify Pareto optimal solutions is_pareto_optimal <- function(data, objectives) {   n <- nrow(data)   pareto <- rep(TRUE, n)      for (i in 1:n) {     for (j in 1:n) {       if (i != j) {         # Check if j dominates i         dominates <- all(data[j, objectives] >= data[i, objectives]) &&                     any(data[j, objectives] > data[i, objectives])         if (dominates) {           pareto[i] <- FALSE           break         }       }     }   }      return(pareto) }  # For sensitivity and cost (cost should be minimized, so use negative) pareto_data$neg_cost <- -pareto_data$cost pareto_data$pareto_optimal <- is_pareto_optimal(   pareto_data,    c(\"sensitivity\", \"neg_cost\") )  # Visualize Pareto frontier ggplot(pareto_data, aes(x = cost, y = sensitivity * 100)) +   geom_point(aes(color = pareto_optimal, size = n_tests), alpha = 0.7) +   geom_line(data = pareto_data[pareto_data$pareto_optimal,] %>% arrange(cost),             color = \"red\", size = 1) +   geom_text(data = pareto_data[pareto_data$pareto_optimal,],             aes(label = tests), vjust = -1, size = 3) +   scale_color_manual(values = c(\"gray\", \"red\")) +   labs(     title = \"Pareto Frontier for Multi-Objective Optimization\",     x = \"Total Cost ($)\",     y = \"Sensitivity (%)\",     caption = \"Red points and line show Pareto optimal solutions\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "cost-sensitive-decision-trees",
        "dir": "Articles",
        "previous_headings": "Advanced Decision Trees",
        "what": "Cost-Sensitive Decision Trees",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "Implement decision trees consider accuracy cost:",
        "code": "# Prepare data for decision tree tree_data <- covid_screening_data %>%   select(rapid_antigen, pcr, chest_ct, symptom_score,           age, risk_group, covid_status) %>%   na.omit()  # Create cost matrix # Rows: predicted, Columns: actual # Cost of false negative is 10x cost of false positive cost_matrix <- matrix(c(0, 1,     # Predict Negative                        10, 0),    # Predict Positive                      nrow = 2, byrow = TRUE)  # Build cost-sensitive tree cost_tree <- rpart(   covid_status ~ rapid_antigen + pcr + chest_ct +                   symptom_score + age + risk_group,   data = tree_data,   method = \"class\",   parms = list(loss = cost_matrix),   control = rpart.control(cp = 0.01, maxdepth = 4) )  # Visualize tree rpart.plot(cost_tree,             main = \"Cost-Sensitive Decision Tree for COVID-19\",            extra = 104,  # Show probability and number            under = TRUE,            faclen = 0,            cex = 0.8)  # Compare with standard tree standard_tree <- rpart(   covid_status ~ rapid_antigen + pcr + chest_ct +                   symptom_score + age + risk_group,   data = tree_data,   method = \"class\",   control = rpart.control(cp = 0.01, maxdepth = 4) )  # Performance comparison tree_comparison <- data.frame(   Model = c(\"Standard\", \"Cost-Sensitive\"),   Accuracy = c(     sum(predict(standard_tree, type = \"class\") == tree_data$covid_status) / nrow(tree_data),     sum(predict(cost_tree, type = \"class\") == tree_data$covid_status) / nrow(tree_data)   ),   Sensitivity = c(     {       pred <- predict(standard_tree, type = \"class\")       sum(pred == \"Positive\" & tree_data$covid_status == \"Positive\") /          sum(tree_data$covid_status == \"Positive\")     },     {       pred <- predict(cost_tree, type = \"class\")       sum(pred == \"Positive\" & tree_data$covid_status == \"Positive\") /          sum(tree_data$covid_status == \"Positive\")     }   ) )  kable(tree_comparison, digits = 3,       caption = \"Performance Comparison: Standard vs Cost-Sensitive Trees\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "ensemble-decision-trees",
        "dir": "Articles",
        "previous_headings": "Advanced Decision Trees",
        "what": "Ensemble Decision Trees",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "Combine multiple trees robust decisions:",
        "code": "# Create bootstrap samples and build multiple trees n_trees <- 10 trees <- list() tree_weights <- numeric(n_trees)  for (i in 1:n_trees) {   # Bootstrap sample   boot_indices <- sample(nrow(tree_data), replace = TRUE)   boot_data <- tree_data[boot_indices,]      # Build tree with random feature subset   features <- c(\"rapid_antigen\", \"pcr\", \"chest_ct\",                  \"symptom_score\", \"age\", \"risk_group\")   selected_features <- sample(features, size = 4)      formula <- as.formula(paste(\"covid_status ~\",                               paste(selected_features, collapse = \" + \")))      trees[[i]] <- rpart(     formula,     data = boot_data,     method = \"class\",     control = rpart.control(cp = 0.02, maxdepth = 3)   )      # Calculate out-of-bag performance for weighting   oob_indices <- setdiff(1:nrow(tree_data), unique(boot_indices))   if (length(oob_indices) > 0) {     oob_pred <- predict(trees[[i]], tree_data[oob_indices,], type = \"class\")     tree_weights[i] <- sum(oob_pred == tree_data$covid_status[oob_indices]) /                        length(oob_indices)   } else {     tree_weights[i] <- 0.5   } }  # Normalize weights tree_weights <- tree_weights / sum(tree_weights)  # Ensemble prediction function ensemble_predict <- function(trees, weights, newdata) {   # Get probability predictions from each tree   prob_matrix <- matrix(0, nrow = nrow(newdata), ncol = 2)      for (i in 1:length(trees)) {     probs <- predict(trees[[i]], newdata, type = \"prob\")     prob_matrix <- prob_matrix + probs * weights[i]   }      # Return class with highest probability   classes <- levels(tree_data$covid_status)   predicted_class <- classes[apply(prob_matrix, 1, which.max)]      return(list(class = predicted_class, prob = prob_matrix)) }  # Test ensemble ensemble_pred <- ensemble_predict(trees, tree_weights, tree_data)  # Compare performance ensemble_comparison <- data.frame(   Model = c(\"Single Tree\", \"Ensemble\"),   Accuracy = c(     sum(predict(trees[[1]], type = \"class\") == tree_data$covid_status) / nrow(tree_data),     sum(ensemble_pred$class == tree_data$covid_status) / nrow(tree_data)   ) )  kable(ensemble_comparison, digits = 3,       caption = \"Single Tree vs Ensemble Performance\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "implementing-complex-constraints",
        "dir": "Articles",
        "previous_headings": "Complex Constraints and Business Rules",
        "what": "Implementing Complex Constraints",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "Real-world scenarios often complex constraints:",
        "code": "# Function to check if a test combination meets constraints meets_constraints <- function(tests, constraints) {   # Example constraints for TB testing      # 1. If GeneXpert is used, must have sputum collection capability   if (\"genexpert\" %in% tests && !(\"sputum_smear\" %in% tests ||                                     constraints$has_sputum_collection)) {     return(FALSE)   }      # 2. Culture requires biosafety level 3 lab   if (\"culture\" %in% tests && !constraints$has_bsl3_lab) {     return(FALSE)   }      # 3. Maximum turnaround time constraint   test_times <- c(symptoms = 0, sputum_smear = 0.5, genexpert = 0.1,                    culture = 21, chest_xray = 0.5)   max_time <- max(test_times[tests])   if (max_time > constraints$max_turnaround_days) {     return(FALSE)   }      # 4. Budget constraint   test_costs <- c(symptoms = 1, sputum_smear = 3, genexpert = 20,                    culture = 30, chest_xray = 10)   total_cost <- sum(test_costs[tests])   if (total_cost > constraints$budget_per_patient) {     return(FALSE)   }      return(TRUE) }  # Define facility-specific constraints facility_constraints <- list(   rural_clinic = list(     has_sputum_collection = TRUE,     has_bsl3_lab = FALSE,     max_turnaround_days = 1,     budget_per_patient = 15   ),   district_hospital = list(     has_sputum_collection = TRUE,     has_bsl3_lab = FALSE,     max_turnaround_days = 7,     budget_per_patient = 50   ),   reference_lab = list(     has_sputum_collection = TRUE,     has_bsl3_lab = TRUE,     max_turnaround_days = 30,     budget_per_patient = 100   ) )  # Find valid combinations for each facility type tb_tests <- c(\"symptoms\", \"sputum_smear\", \"genexpert\", \"culture\", \"chest_xray\")  for (facility in names(facility_constraints)) {   valid_combos <- list()      # Check all combinations   for (i in 1:length(tb_tests)) {     combos <- combn(tb_tests, i, simplify = FALSE)     for (combo in combos) {       if (meets_constraints(combo, facility_constraints[[facility]])) {         valid_combos <- c(valid_combos, list(combo))       }     }   }      cat(\"\\n\", facility, \": \", length(valid_combos), \" valid combinations\\n\", sep = \"\")   cat(\"Examples: \\n\")   for (j in 1:min(3, length(valid_combos))) {     cat(\"  -\", paste(valid_combos[[j]], collapse = \" + \"), \"\\n\")   } }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "time-dependent-testing-strategies",
        "dir": "Articles",
        "previous_headings": "Complex Constraints and Business Rules",
        "what": "Time-Dependent Testing Strategies",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "Implement strategies change based time constraints:",
        "code": "# Time-dependent chest pain protocol time_dependent_protocol <- function(patient_data, time_available_hours) {      decisions <- data.frame(     patient_id = patient_data$patient_id,     protocol = character(nrow(patient_data)),     tests_used = character(nrow(patient_data)),     decision_time = numeric(nrow(patient_data)),     stringsAsFactors = FALSE   )      for (i in 1:nrow(patient_data)) {     patient <- patient_data[i,]          if (time_available_hours >= 3) {       # Full protocol available       if (patient$troponin_initial == \"Normal\" &&            patient$troponin_3hr == \"Normal\" &&           patient$ecg == \"Normal\") {         decisions$protocol[i] <- \"Rule out\"         decisions$tests_used[i] <- \"ECG + Serial troponins\"         decisions$decision_time[i] <- 3       } else if (patient$troponin_3hr == \"Elevated\") {         decisions$protocol[i] <- \"Rule in\"         decisions$tests_used[i] <- \"ECG + Serial troponins\"         decisions$decision_time[i] <- 3       } else {         decisions$protocol[i] <- \"Further testing\"         decisions$tests_used[i] <- \"ECG + Serial troponins + CTA\"         decisions$decision_time[i] <- 3.5       }            } else if (time_available_hours >= 1) {       # Rapid protocol       if (patient$troponin_initial == \"Normal\" &&            patient$ecg == \"Normal\" &&           patient$age < 40) {         decisions$protocol[i] <- \"Low risk discharge\"         decisions$tests_used[i] <- \"ECG + Initial troponin\"         decisions$decision_time[i] <- 1       } else {         decisions$protocol[i] <- \"Requires admission\"         decisions$tests_used[i] <- \"ECG + Initial troponin\"         decisions$decision_time[i] <- 1       }            } else {       # Ultra-rapid       if (patient$ecg == \"Ischemic changes\") {         decisions$protocol[i] <- \"Immediate cath lab\"         decisions$tests_used[i] <- \"ECG only\"         decisions$decision_time[i] <- 0.2       } else {         decisions$protocol[i] <- \"Clinical decision\"         decisions$tests_used[i] <- \"ECG only\"         decisions$decision_time[i] <- 0.2       }     }   }      return(decisions) }  # Apply to sample patients sample_mi <- mi_ruleout_data[1:20,]  # Different time scenarios time_scenarios <- c(0.5, 1, 3, 6)  for (time_limit in time_scenarios) {   results <- time_dependent_protocol(sample_mi, time_limit)      cat(\"\\nTime available:\", time_limit, \"hours\\n\")   cat(\"Protocols used:\\n\")   print(table(results$protocol))   cat(\"Average decision time:\", mean(results$decision_time), \"hours\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "efficient-computation-for-large-datasets",
        "dir": "Articles",
        "previous_headings": "Performance Optimization",
        "what": "Efficient Computation for Large Datasets",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "# Performance Optimization and Benchmarking # This section demonstrates different approaches to optimize performance calculations  # Function to safely calculate performance metrics with NA handling safe_performance_metrics <- function(predictions, actual, positive_class = \"Positive\") {   # Handle missing values   complete_cases <- !is.na(predictions) & !is.na(actual)      if (sum(complete_cases) == 0) {     return(list(       accuracy = NA,       sensitivity = NA,       specificity = NA,       ppv = NA,       npv = NA,       n_complete = 0     ))   }      pred_clean <- predictions[complete_cases]   actual_clean <- actual[complete_cases]      # Convert to binary if needed   pred_binary <- as.character(pred_clean) == positive_class   actual_binary <- as.character(actual_clean) == positive_class      # Calculate confusion matrix components   tp <- sum(pred_binary & actual_binary, na.rm = TRUE)   tn <- sum(!pred_binary & !actual_binary, na.rm = TRUE)   fp <- sum(pred_binary & !actual_binary, na.rm = TRUE)   fn <- sum(!pred_binary & actual_binary, na.rm = TRUE)      # Calculate metrics with division by zero protection   total <- tp + tn + fp + fn   accuracy <- if (total > 0) (tp + tn) / total else NA      sensitivity <- if ((tp + fn) > 0) tp / (tp + fn) else NA   specificity <- if ((tn + fp) > 0) tn / (tn + fp) else NA   ppv <- if ((tp + fp) > 0) tp / (tp + fp) else NA   npv <- if ((tn + fn) > 0) tn / (tn + fn) else NA      return(list(     accuracy = accuracy,     sensitivity = sensitivity,     specificity = specificity,     ppv = ppv,     npv = npv,     n_complete = sum(complete_cases)   )) }  # Optimized confusion matrix calculation fast_confusion_matrix <- function(predictions, actual, positive_class = \"Positive\") {   # Handle NAs upfront   complete_cases <- !is.na(predictions) & !is.na(actual)      if (sum(complete_cases) < 2) {     return(matrix(c(0, 0, 0, 0), nrow = 2,                    dimnames = list(                     Predicted = c(\"Negative\", \"Positive\"),                     Actual = c(\"Negative\", \"Positive\")                   )))   }      pred_clean <- predictions[complete_cases]   actual_clean <- actual[complete_cases]      # Use table for fast cross-tabulation   conf_table <- table(     Predicted = factor(pred_clean, levels = c(setdiff(unique(c(pred_clean, actual_clean)), positive_class), positive_class)),     Actual = factor(actual_clean, levels = c(setdiff(unique(c(pred_clean, actual_clean)), positive_class), positive_class))   )      return(conf_table) }  # Vectorized performance calculation vectorized_metrics <- function(pred_vector, actual_vector, positive_class = \"Positive\") {   # Remove NAs   complete_idx <- !is.na(pred_vector) & !is.na(actual_vector)      if (sum(complete_idx) == 0) {     return(data.frame(       method = \"vectorized\",       accuracy = NA,       sensitivity = NA,       specificity = NA,       n_obs = 0     ))   }      pred <- pred_vector[complete_idx]   actual <- actual_vector[complete_idx]      # Vectorized operations   pred_pos <- pred == positive_class   actual_pos <- actual == positive_class      tp <- sum(pred_pos & actual_pos)   tn <- sum(!pred_pos & !actual_pos)   fp <- sum(pred_pos & !actual_pos)   fn <- sum(!pred_pos & actual_pos)      n_total <- length(pred)   n_pos <- sum(actual_pos)   n_neg <- sum(!actual_pos)      data.frame(     method = \"vectorized\",     accuracy = (tp + tn) / n_total,     sensitivity = if (n_pos > 0) tp / n_pos else NA,     specificity = if (n_neg > 0) tn / n_neg else NA,     n_obs = n_total   ) }  # Create test data for benchmarking (ensure no NAs in critical columns) set.seed(123) n_test <- 1000  # Create predictions with some realistic accuracy actual_test <- factor(sample(c(\"Negative\", \"Positive\"), n_test,                             replace = TRUE, prob = c(0.8, 0.2)))  # Create predictions that correlate with actual (realistic scenario) pred_prob <- ifelse(actual_test == \"Positive\", 0.85, 0.15) pred_test <- factor(ifelse(runif(n_test) < pred_prob, \"Positive\", \"Negative\"))  # Introduce some missing values (but not in the benchmarked functions) missing_idx <- sample(n_test, size = floor(n_test * 0.05)) actual_test_with_na <- actual_test pred_test_with_na <- pred_test actual_test_with_na[missing_idx[1:length(missing_idx)/2]] <- NA pred_test_with_na[missing_idx[(length(missing_idx)/2 + 1):length(missing_idx)]] <- NA  cat(\"Test data created:\\n\") cat(\"Total observations:\", n_test, \"\\n\") cat(\"Missing values in actual:\", sum(is.na(actual_test_with_na)), \"\\n\") cat(\"Missing values in predictions:\", sum(is.na(pred_test_with_na)), \"\\n\") cat(\"Complete cases:\", sum(!is.na(actual_test_with_na) & !is.na(pred_test_with_na)), \"\\n\")  # Test the functions with clean data first cat(\"\\nTesting functions with clean data:\\n\") clean_metrics <- safe_performance_metrics(pred_test, actual_test) print(clean_metrics)  clean_confusion <- fast_confusion_matrix(pred_test, actual_test) print(clean_confusion)  # Test with data containing NAs cat(\"\\nTesting functions with NA values:\\n\") na_metrics <- safe_performance_metrics(pred_test_with_na, actual_test_with_na) print(na_metrics)  # Benchmark different approaches (using clean data to avoid NA issues in timing) cat(\"\\nPerformance benchmarking:\\n\")  # Only benchmark if microbenchmark is available if (requireNamespace(\"microbenchmark\", quietly = TRUE)) {   tryCatch({     benchmark_results <- microbenchmark::microbenchmark(       \"safe_metrics\" = safe_performance_metrics(pred_test, actual_test),       \"fast_confusion\" = fast_confusion_matrix(pred_test, actual_test),       \"vectorized\" = vectorized_metrics(pred_test, actual_test),       times = 10     )          print(benchmark_results)          # Plot benchmark results if possible     if (requireNamespace(\"ggplot2\", quietly = TRUE)) {       plot(benchmark_results)     }        }, error = function(e) {     cat(\"Benchmark error (using fallback timing):\", e$message, \"\\n\")          # Fallback timing method     cat(\"Using system.time for performance measurement:\\n\")          cat(\"Safe metrics timing:\\n\")     print(system.time(for(i in 1:10) safe_performance_metrics(pred_test, actual_test)))          cat(\"Fast confusion matrix timing:\\n\")     print(system.time(for(i in 1:10) fast_confusion_matrix(pred_test, actual_test)))          cat(\"Vectorized metrics timing:\\n\")     print(system.time(for(i in 1:10) vectorized_metrics(pred_test, actual_test)))   }) } else {   cat(\"microbenchmark package not available, using system.time:\\n\")      cat(\"Safe metrics timing:\\n\")   print(system.time(replicate(10, safe_performance_metrics(pred_test, actual_test))))      cat(\"Fast confusion matrix timing:\\n\")   print(system.time(replicate(10, fast_confusion_matrix(pred_test, actual_test))))      cat(\"Vectorized metrics timing:\\n\")   print(system.time(replicate(10, vectorized_metrics(pred_test, actual_test)))) }  # Performance comparison table performance_comparison <- data.frame(   Method = c(\"Safe Metrics\", \"Fast Confusion Matrix\", \"Vectorized Metrics\"),   `Handles NAs` = c(\"Yes\", \"Yes\", \"Yes\"),   `Memory Efficient` = c(\"Medium\", \"High\", \"High\"),   `Speed` = c(\"Medium\", \"Fast\", \"Fastest\"),   `Use Case` = c(\"General purpose\", \"Detailed analysis\", \"Large datasets\"),   stringsAsFactors = FALSE )  knitr::kable(performance_comparison,               caption = \"Performance Optimization Comparison\",              align = 'c')"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "caching-and-memoization",
        "dir": "Articles",
        "previous_headings": "Performance Optimization",
        "what": "Caching and Memoization",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "# Create memoized function for expensive calculations library(memoise)  # Original expensive function calculate_test_performance <- function(test_data, gold_standard) {   # Simulate expensive calculation   Sys.sleep(0.1)  # Pretend this takes time      conf_matrix <- table(test_data, gold_standard)   sensitivity <- conf_matrix[2,2] / sum(conf_matrix[,2])   specificity <- conf_matrix[1,1] / sum(conf_matrix[,1])      return(list(sensitivity = sensitivity, specificity = specificity)) }  # Memoized version calculate_test_performance_memo <- memoise(calculate_test_performance)  # Demonstration test_vector <- as.numeric(covid_screening_data$rapid_antigen == \"Positive\") gold_vector <- as.numeric(covid_screening_data$covid_status == \"Positive\")  # First call - slow system.time({   result1 <- calculate_test_performance_memo(test_vector[1:100], gold_vector[1:100]) })  # Second call with same data - fast (cached) system.time({   result2 <- calculate_test_performance_memo(test_vector[1:100], gold_vector[1:100]) })  cat(\"Results match:\", identical(result1, result2), \"\\n\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "exporting-results-for-clinical-decision-support-systems",
        "dir": "Articles",
        "previous_headings": "Integration with External Systems",
        "what": "Exporting Results for Clinical Decision Support Systems",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "# Export Clinical Decision Support System Rules  # Safe function to export tree rules with proper error handling export_tree_as_rules <- function(tree_model, data) {   # Check if tree model exists and is valid   if (is.null(tree_model) || !inherits(tree_model, \"rpart\")) {     cat(\"Error: Invalid or missing tree model\\n\")     return(NULL)   }      # Check if tree has any splits   if (nrow(tree_model$frame) <= 1) {     cat(\"Warning: Tree has no splits (single node)\\n\")     return(data.frame(       rule_id = 1,       condition = \"Always true\",       prediction = \"Default\",       confidence = 1.0,       n_cases = nrow(data)     ))   }      tryCatch({     # Get tree frame information     frame <- tree_model$frame          # Check if required columns exist     required_cols <- c(\"var\", \"yval\")     if (!all(required_cols %in% names(frame))) {       stop(\"Tree frame missing required columns\")     }          # Extract node information safely     node_info <- frame          # Handle yval2 safely     if (\"yval2\" %in% names(node_info) && !is.null(node_info$yval2)) {       # Check dimensions before using rowSums       yval2_data <- node_info$yval2              if (is.matrix(yval2_data) && ncol(yval2_data) >= 2) {         # Safe to use rowSums         node_counts <- rowSums(yval2_data[, 1:min(2, ncol(yval2_data)), drop = FALSE])       } else if (is.data.frame(yval2_data) && ncol(yval2_data) >= 2) {         # Convert to matrix first         yval2_matrix <- as.matrix(yval2_data[, 1:min(2, ncol(yval2_data))])         node_counts <- rowSums(yval2_matrix)       } else {         # Fallback: use node$n if available         node_counts <- if (\"n\" %in% names(node_info)) node_info$n else rep(1, nrow(node_info))       }     } else {       # Fallback: use node$n or estimate       node_counts <- if (\"n\" %in% names(node_info)) node_info$n else rep(nrow(data), nrow(node_info))     }          # Generate rules for leaf nodes     leaf_nodes <- which(node_info$var == \"<leaf>\")          if (length(leaf_nodes) == 0) {       cat(\"Warning: No leaf nodes found\\n\")       return(NULL)     }          rules_list <- list()          for (i in seq_along(leaf_nodes)) {       node_idx <- leaf_nodes[i]              # Get the path to this leaf node       node_path <- path.rpart(tree_model, nodes = as.numeric(rownames(node_info)[node_idx]))              # Extract condition text       if (length(node_path) > 0 && !is.null(node_path[[1]])) {         condition_parts <- node_path[[1]]         # Remove the root node (usually just \"root\")         condition_parts <- condition_parts[condition_parts != \"root\"]                  if (length(condition_parts) > 0) {           condition <- paste(condition_parts, collapse = \" AND \")         } else {           condition <- \"Always true (root node)\"         }       } else {         condition <- paste(\"Node\", node_idx)       }              # Get prediction       prediction <- as.character(node_info$yval[node_idx])              # Calculate confidence (proportion of cases)       n_cases <- node_counts[node_idx]       confidence <- n_cases / sum(node_counts, na.rm = TRUE)              rules_list[[i]] <- data.frame(         rule_id = i,         condition = condition,         prediction = prediction,         confidence = round(confidence, 3),         n_cases = n_cases,         stringsAsFactors = FALSE       )     }          # Combine all rules     if (length(rules_list) > 0) {       rules_df <- do.call(rbind, rules_list)       return(rules_df)     } else {       return(NULL)     }        }, error = function(e) {     cat(\"Error in export_tree_as_rules:\", e$message, \"\\n\")     cat(\"Tree structure:\\n\")     if (exists(\"frame\")) {       print(str(frame))     } else {       print(str(tree_model))     }     return(NULL)   }) }  # Alternative simple rule extraction function simple_tree_rules <- function(tree_model, data) {   if (is.null(tree_model) || !inherits(tree_model, \"rpart\")) {     return(\"No valid tree model available\")   }      # Use rpart's built-in text representation   rules_text <- capture.output(print(tree_model))      return(paste(rules_text, collapse = \"\\n\")) }  # Generate exportable rules cat(\"Generating Clinical Decision Support Rules...\\n\")  # Check if we have a valid tree from previous chunks if (exists(\"cost_tree\") && !is.null(cost_tree)) {   cat(\"Exporting rules from cost-sensitive tree...\\n\")      # Try the main function first   exported_rules <- export_tree_as_rules(cost_tree, covid_screening_data)      if (!is.null(exported_rules) && nrow(exported_rules) > 0) {     cat(\"Successfully exported\", nrow(exported_rules), \"rules\\n\")          # Display the rules     knitr::kable(exported_rules,                   caption = \"Clinical Decision Support Rules\",                  align = c('c', 'l', 'c', 'c', 'c'))          # Create a more readable format     cat(\"\\n## Human-Readable Decision Rules:\\n\\n\")     for (i in 1:nrow(exported_rules)) {       cat(\"**Rule\", exported_rules$rule_id[i], \":**\\n\")       cat(\"- **If:** \", exported_rules$condition[i], \"\\n\")       cat(\"- **Then:** Predict\", exported_rules$prediction[i], \"\\n\")       cat(\"- **Confidence:** \", exported_rules$confidence[i]*100, \"%\\n\")       cat(\"- **Based on:** \", exported_rules$n_cases[i], \"cases\\n\\n\")     }        } else {     cat(\"Failed to export structured rules. Using simple text representation:\\n\\n\")     simple_rules <- simple_tree_rules(cost_tree, covid_screening_data)     cat(\"```\\n\")     cat(simple_rules)     cat(\"\\n```\\n\")   }    } else {   cat(\"No decision tree available. Creating a simple example tree...\\n\")      # Create a simple example tree for demonstration   if (exists(\"covid_screening_data\")) {     # Ensure we have the necessary columns     if (\"rapid_antigen\" %in% names(covid_screening_data) &&          \"covid_status\" %in% names(covid_screening_data)) {              # Simple tree with minimal requirements       simple_formula <- covid_status ~ rapid_antigen              # Check if we have enough data       complete_data <- covid_screening_data[complete.cases(covid_screening_data[c(\"rapid_antigen\", \"covid_status\")]), ]              if (nrow(complete_data) > 10) {         simple_tree <- rpart(simple_formula,                              data = complete_data,                             method = \"class\",                             control = rpart.control(minbucket = 5, cp = 0.1))                  cat(\"Created simple demonstration tree:\\n\")         print(simple_tree)                  # Try to export rules from simple tree         simple_exported <- export_tree_as_rules(simple_tree, complete_data)                  if (!is.null(simple_exported)) {           knitr::kable(simple_exported,                         caption = \"Simple Decision Rules (Example)\",                        align = c('c', 'l', 'c', 'c', 'c'))         }       } else {         cat(\"Insufficient data for tree creation\\n\")       }     } else {       cat(\"Required columns not found in data\\n\")     }   } else {     cat(\"No data available for tree creation\\n\")   } }  # Export formats section cat(\"\\n## Export Formats\\n\\n\")  export_formats <- data.frame(   Format = c(\"JSON\", \"XML\", \"CSV\", \"SQL\", \"R Code\"),   `Use Case` = c(     \"Web applications, APIs\",     \"Healthcare standards (HL7)\",     \"Spreadsheet analysis\",     \"Database integration\",     \"R/Statistical software\"   ),   Complexity = c(\"Medium\", \"High\", \"Low\", \"Medium\", \"Low\"),   Implementation = c(     \"jsonlite::toJSON()\",     \"XML::xmlTree()\",     \"write.csv()\",     \"Custom SQL generation\",     \"dput() or custom function\"   ),   stringsAsFactors = FALSE )  knitr::kable(export_formats,              caption = \"Available Export Formats for Decision Rules\",              align = c('l', 'l', 'c', 'l'))  cat(\"\\n## Implementation Example\\n\\n\") cat(\"Here's how these rules could be implemented in a clinical system:\\n\\n\")  implementation_example <- ' # Example implementation in R clinical_decision <- function(rapid_antigen_result) {   if (rapid_antigen_result == \"Positive\") {     return(list(       decision = \"Positive\",       confidence = 0.95,       recommendation = \"Confirm with PCR if needed for official diagnosis\"     ))   } else {     return(list(       decision = \"Negative\",        confidence = 0.85,       recommendation = \"Consider PCR if high clinical suspicion\"     ))   } }  # Usage example: # result <- clinical_decision(\"Positive\") # print(result$decision) '  cat(\"```r\\n\") cat(implementation_example) cat(\"```\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "creating-api-ready-outputs",
        "dir": "Articles",
        "previous_headings": "Integration with External Systems",
        "what": "Creating API-Ready Outputs",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "# Function to create API response for test panel recommendation create_api_response <- function(patient_data, optimal_panel) {   response <- list(     timestamp = Sys.time(),     patient_id = patient_data$patient_id,     recommendations = list(       primary = list(         tests = optimal_panel$tests,         strategy = optimal_panel$strategy,         expected_performance = list(           sensitivity = round(optimal_panel$sensitivity * 100, 1),           specificity = round(optimal_panel$specificity * 100, 1),           ppv = round(optimal_panel$ppv * 100, 1),           npv = round(optimal_panel$npv * 100, 1)         ),         estimated_cost = optimal_panel$cost       ),       alternative_protocols = list(         rapid = \"Rapid antigen only\",         comprehensive = \"All available tests\"       )     ),     warnings = list(),     metadata = list(       model_version = \"1.0.0\",       confidence_level = \"high\"     )   )      # Add warnings based on patient characteristics   if (patient_data$age > 65) {     response$warnings <- append(response$warnings,                                 \"High-risk age group - consider lower threshold\")   }      return(response) }  # Example API response example_patient <- covid_screening_data[1,] example_panel <- list(   tests = \"rapid_antigen+pcr\",   strategy = \"parallel_any\",   sensitivity = 0.97,   specificity = 0.97,   ppv = 0.82,   npv = 0.99,   cost = 55 )  api_response <- create_api_response(example_patient, example_panel) cat(\"API Response:\\n\") print(jsonlite::toJSON(api_response, pretty = TRUE))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "cross-validation-with-custom-splits",
        "dir": "Articles",
        "previous_headings": "Validation and Quality Control",
        "what": "Cross-Validation with Custom Splits",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "# Time-based cross-validation for temporal data time_based_cv <- function(data, date_column, n_splits = 5) {   # Sort by date   data <- data[order(data[[date_column]]),]   n <- nrow(data)      # Create time-based splits   splits <- list()   test_size <- floor(n / (n_splits + 1))      for (i in 1:n_splits) {     train_end <- test_size * i     test_start <- train_end + 1     test_end <- min(test_start + test_size - 1, n)          splits[[i]] <- list(       train = 1:train_end,       test = test_start:test_end     )   }      return(splits) }  # Stratified cross-validation ensuring prevalence balance stratified_cv <- function(data, outcome_column, n_folds = 5) {   # Separate by outcome   positive_idx <- which(data[[outcome_column]] == levels(data[[outcome_column]])[2])   negative_idx <- which(data[[outcome_column]] == levels(data[[outcome_column]])[1])      # Shuffle within strata   positive_idx <- sample(positive_idx)   negative_idx <- sample(negative_idx)      # Create folds maintaining proportion   folds <- list()   pos_per_fold <- length(positive_idx) %/% n_folds   neg_per_fold <- length(negative_idx) %/% n_folds      for (i in 1:n_folds) {     if (i < n_folds) {       fold_pos <- positive_idx[((i-1)*pos_per_fold + 1):(i*pos_per_fold)]       fold_neg <- negative_idx[((i-1)*neg_per_fold + 1):(i*neg_per_fold)]     } else {       # Last fold gets remaining       fold_pos <- positive_idx[((i-1)*pos_per_fold + 1):length(positive_idx)]       fold_neg <- negative_idx[((i-1)*neg_per_fold + 1):length(negative_idx)]     }          folds[[i]] <- c(fold_pos, fold_neg)   }      return(folds) }  # Apply stratified CV folds <- stratified_cv(covid_screening_data, \"covid_status\", n_folds = 5)  # Check fold balance for (i in 1:length(folds)) {   fold_data <- covid_screening_data[folds[[i]],]   prevalence <- mean(fold_data$covid_status == \"Positive\")   cat(\"Fold\", i, \": n =\", length(folds[[i]]),        \", prevalence =\", round(prevalence * 100, 1), \"%\\n\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "vignette covered advanced features including: Custom Optimization: Multi-objective optimization, Pareto frontiers Advanced Trees: Cost-sensitive ensemble methods Complex Constraints: Business rules time-dependent strategies Performance: Efficient computation caching Integration: API outputs clinical decision support Validation: Custom cross-validation schemes advanced features enable Decision Panel Optimization module handle complex real-world scenarios maintaining computational efficiency clinical relevance.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-decision-panel-advanced.html",
        "id": "session-information",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Session Information",
        "title": "Advanced Features and Customization in Decision Panel Optimization",
        "text": "",
        "code": "sessionInfo()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "kappasizepower function provides power analysis sample size determination inter-rater agreement studies. Unlike fixed sample size analysis, function answers question: “many subjects need detect meaningful improvement agreement raters?”",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "when-to-use-kappasizepower",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "When to Use kappasizepower",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "function essential research scenarios : Designing new agreement studies specific power requirements Validating training programs aim improve inter-rater agreement Standardizing clinical protocols requiring demonstrated agreement improvements Grant applications requiring rigorous power analysis justification Multi-center studies establishing minimum recruitment targets",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "power-analysis-framework",
        "dir": "Articles",
        "previous_headings": "Introduction > Key Concepts",
        "what": "Power Analysis Framework",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Traditional power analysis determines sample size based : Effect Size + Power + Alpha → Sample Size kappa agreement: κ₁ - κ₀ + Power + Alpha → Required N",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "hypothesis-testing-for-agreement",
        "dir": "Articles",
        "previous_headings": "Introduction > Key Concepts",
        "what": "Hypothesis Testing for Agreement",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "H₀: κ = κ₀ (null hypothesis agreement level) H₁: κ = κ₁ (alternative hypothesis agreement level) Effect Size: κ₁ - κ₀ (improvement agreement)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "critical-validation",
        "dir": "Articles",
        "previous_headings": "Introduction > Key Concepts",
        "what": "Critical Validation",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "κ₁ must greater κ₀ - alternative hypothesis represent better agreement null hypothesis.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "inter-rater-agreement-fundamentals",
        "dir": "Articles",
        "previous_headings": "Theoretical Background",
        "what": "Inter-rater Agreement Fundamentals",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cohen’s kappa (κ) measures agreement beyond chance: κ=po−pe1−pe\\kappa = \\frac{p_o - p_e}{1 - p_e} : - pop_o = observed agreement - pep_e = expected agreement chance",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "sample-size-determinants",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Power Analysis Theory",
        "what": "Sample Size Determinants",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Sample size requirements depend : Effect Size (κ₁ - κ₀): Larger differences require smaller samples Desired Power: Higher power requires larger samples Significance Level (α): Stricter levels require larger samples Number Categories: categories generally require larger samples Number Raters: raters can affect sample size requirements Category Proportions: Unbalanced distributions may require larger samples",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "statistical-framework",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Power Analysis Theory",
        "what": "Statistical Framework",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "kappasizepower function uses kappaSize package implementation power calculations different numbers outcome categories:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "binary-outcomes-2-categories",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Power Analysis Theory",
        "what": "Binary Outcomes (2 categories)",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Uses asymptotic variance estimates binary kappa finite sample corrections.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "multi-category-outcomes-3-5-categories",
        "dir": "Articles",
        "previous_headings": "Theoretical Background > Power Analysis Theory",
        "what": "Multi-category Outcomes (3-5 categories)",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Employs generalized kappa variance formulas accounting : - Number categories raters - Marginal probability distributions - Complex covariance structures",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "basic-syntax",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage",
        "what": "Basic Syntax",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "",
        "code": "kappaSizePower(   outcome = \"2\",           # Number of categories (2, 3, 4, or 5)   kappa0 = 0.40,          # Null hypothesis kappa value   kappa1 = 0.60,          # Alternative hypothesis kappa value   props = \"0.30, 0.70\",   # Category proportions   raters = \"2\",           # Number of raters (2-5)   alpha = 0.05,           # Significance level   power = 0.80            # Desired power )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "outcome-number-of-outcome-categories",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "outcome: Number of Outcome Categories",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Options: “2”, “3”, “4”, “5” Purpose: Determines statistical model use 2: Disease present/absent, positive/negative test 3: Mild/moderate/severe disease 4: grade 1-4, ECOG performance status 5: Likert scales, comprehensive rating systems",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "kappa0-null-hypothesis-kappa",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "kappa0: Null Hypothesis Kappa",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Range: 0.01 0.99 (exclusive) Purpose: Current baseline agreement level Sources: Literature review, pilot data, current practice assessment",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "kappa1-alternative-hypothesis-kappa",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "kappa1: Alternative Hypothesis Kappa",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Range: 0.01 0.99 (exclusive) Critical Requirement: Must greater kappa0 Purpose: Target agreement level intervention/training Effect Size: κ₁ - κ₀ represents improvement want detect",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "props-category-proportions",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "props: Category Proportions",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Format: Comma-separated proportions sum 1.0 Binary: “0.25, 0.75” (25% disease prevalence) Three-category: “0.20, 0.50, 0.30” Sources: Registry data, literature, preliminary studies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "raters-number-of-raters",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "raters: Number of Raters",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Options: “2”, “3”, “4”, “5” Impact: raters can improve precision increase complexity Practical considerations: Availability, cost, training requirements",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "alpha-significance-level",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "alpha: Significance Level",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Common values: 0.05 (5%), 0.01 (1%) Impact: Lower alpha requires larger sample sizes Selection: Based field standards consequence errors",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "power-desired-power",
        "dir": "Articles",
        "previous_headings": "Function Parameters and Usage > Parameter Details",
        "what": "power: Desired Power",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Range: 0.01 0.99, typically ≥ 0.80 Common values: 0.80 (80%), 0.90 (90%) Impact: Higher power requires larger sample sizes Minimum: least 0.50 meaningful analysis",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-1-emergency-department-pneumonia-detection",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Medical Diagnosis Studies",
        "what": "Example 1: Emergency Department Pneumonia Detection",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Emergency physicians want validate training improves chest X-ray agreement pneumonia detection. Clinical Context: - Training programs require validation effectiveness - Patient safety depends reliable pneumonia detection - Effect size 0.25 (0.75 - 0.50) represents meaningful improvement",
        "code": "# Emergency department pneumonia training validation result <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.50,          # Current fair agreement   kappa1 = 0.75,          # Target good agreement post-training   props = \"0.25, 0.75\",   # 25% pneumonia prevalence   raters = \"2\",           # Two emergency physicians   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-2-mammography-screening-enhancement",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Medical Diagnosis Studies",
        "what": "Example 2: Mammography Screening Enhancement",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Radiologists implementing new BI-RADS standardization want demonstrate improved agreement. Clinical Context: - Screening programs require high agreement levels - Effect size 0.20 represents substantial improvement - Higher power (85%) provides stronger evidence",
        "code": "# Mammography screening standardization study result <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.60,          # Current good agreement   kappa1 = 0.80,          # Target excellent agreement   props = \"0.12, 0.88\",   # 12% positive findings (BI-RADS 4-5)   raters = \"2\",           # Two radiologists   alpha = 0.05,   power = 0.85            # Higher power for screening validation )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-3-heart-failure-severity-staging",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Multi-Category Medical Assessments",
        "what": "Example 3: Heart Failure Severity Staging",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Cardiologists validating new echocardiographic staging criteria. Clinical Context: - Staging affects treatment decisions - Standardization improves patient outcomes - Multi-category assessment adds complexity",
        "code": "# Heart failure staging validation study result <- kappaSizePower(   outcome = \"3\",   kappa0 = 0.55,          # Current moderate agreement   kappa1 = 0.75,          # Target good agreement   props = \"0.20, 0.50, 0.30\",  # Mild, Moderate, Severe   raters = \"2\",           # Two cardiologists   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-4-burn-severity-grading-protocol",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Multi-Category Medical Assessments",
        "what": "Example 4: Burn Severity Grading Protocol",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Emergency physicians implementing standardized burn severity assessment. Clinical Context: - Burn severity affects triage decisions - Large effect size (0.25) represents major improvement - Multiple raters increase reliability",
        "code": "# Burn severity grading standardization result <- kappaSizePower(   outcome = \"3\",   kappa0 = 0.60,          # Current good agreement   kappa1 = 0.85,          # Target excellent agreement   props = \"0.40, 0.35, 0.25\",  # First, Second, Third degree   raters = \"3\",           # Three emergency physicians   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-5-tumor-grading-standardization",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Complex Multi-Category Studies",
        "what": "Example 5: Tumor Grading Standardization",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Pathologists implementing standardized tumor grading criteria. Clinical Context: - Tumor grading affects treatment decisions - Standardization reduces inter-institutional variability - Four categories require careful power analysis",
        "code": "# Tumor grading standardization study result <- kappaSizePower(   outcome = \"4\",   kappa0 = 0.60,          # Current good agreement   kappa1 = 0.80,          # Target very good agreement   props = \"0.15, 0.25, 0.35, 0.25\",  # Grade 1, 2, 3, 4   raters = \"3\",           # Three pathologists   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-6-cognitive-assessment-tool-validation",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > Complex Multi-Category Studies",
        "what": "Example 6: Cognitive Assessment Tool Validation",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Neuropsychologists validating structured cognitive assessment protocol. Clinical Context: - Cognitive assessment affects care planning - Structured protocols improve consistency - Effect size 0.20 represents meaningful improvement",
        "code": "# Cognitive assessment tool validation result <- kappaSizePower(   outcome = \"4\",   kappa0 = 0.55,          # Current moderate agreement   kappa1 = 0.75,          # Target good agreement   props = \"0.20, 0.30, 0.30, 0.20\",  # Normal, MCI, Mild, Moderate+ dementia   raters = \"2\",           # Two neuropsychologists   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-7-surgical-complication-grading",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > High-Precision Research Applications",
        "what": "Example 7: Surgical Complication Grading",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Surgeons implementing standardized Clavien-Dindo classification. Clinical Context: - Surgical outcomes require high precision - Strict alpha (0.01) high power (90%) rigorous validation - Large effect size (0.20) represents substantial improvement",
        "code": "# Surgical complication grading validation result <- kappaSizePower(   outcome = \"4\",   kappa0 = 0.65,          # Current good agreement   kappa1 = 0.85,          # Target excellent agreement   props = \"0.40, 0.30, 0.20, 0.10\",  # None, Grade I, II, III+   raters = \"3\",           # Three surgeons   alpha = 0.01,           # Strict significance level   power = 0.90            # High power requirement )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "example-8-biomarker-expression-assessment",
        "dir": "Articles",
        "previous_headings": "Clinical Applications and Examples > High-Precision Research Applications",
        "what": "Example 8: Biomarker Expression Assessment",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Scenario: Pathologists standardizing immunohistochemical scoring. Clinical Context: - Biomarker scoring affects treatment decisions - Research applications require high precision - Large effect size (0.20) strict criteria",
        "code": "# Biomarker expression standardization result <- kappaSizePower(   outcome = \"3\",   kappa0 = 0.70,          # Current good agreement   kappa1 = 0.90,          # Target excellent agreement   props = \"0.30, 0.45, 0.25\",  # Low, Moderate, High expression   raters = \"2\",           # Two pathologists   alpha = 0.01,           # Strict significance level   power = 0.90            # High power requirement )"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "small-effect-sizes-κ₁---κ₀-0-20",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Effect Size Considerations",
        "what": "Small Effect Sizes (κ₁ - κ₀ < 0.20)",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Require large sample sizes may clinically meaningful:",
        "code": "# Small but clinically significant improvement result <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.70,          # Already good agreement   kappa1 = 0.80,          # Modest improvement   props = \"0.50, 0.50\",   # Balanced categories   raters = \"2\",   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "large-effect-sizes-κ₁---κ₀-0-30",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Effect Size Considerations",
        "what": "Large Effect Sizes (κ₁ - κ₀ > 0.30)",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Require smaller sample sizes, easier detect:",
        "code": "# Large improvement from training result <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.30,          # Poor baseline agreement   kappa1 = 0.70,          # Good post-training agreement   props = \"0.25, 0.75\",   raters = \"2\",   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "rare-event-studies",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Dealing with Unbalanced Proportions",
        "what": "Rare Event Studies",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Considerations Unbalanced Data: - May require larger sample sizes - Consider stratified analysis approaches - Validate results simulation studies",
        "code": "# Rare disease diagnosis agreement result <- kappaSizePower(   outcome = \"2\",   kappa0 = 0.60,   kappa1 = 0.80,   props = \"0.05, 0.95\",   # 5% rare disease prevalence   raters = \"3\",   alpha = 0.05,   power = 0.80 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "research-validation-studies",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > High-Power Study Designs",
        "what": "Research Validation Studies",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "High-Power Considerations: - Necessary definitive validation studies - Required regulatory submissions - Increases sample size requirements substantially",
        "code": "# High-power research validation result <- kappaSizePower(   outcome = \"5\",   kappa0 = 0.50,   kappa1 = 0.70,   props = \"0.10, 0.20, 0.35, 0.25, 0.10\",   raters = \"4\",   alpha = 0.01,           # Strict significance   power = 0.95            # Very high power )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "coordinated-research-networks",
        "dir": "Articles",
        "previous_headings": "Advanced Applications > Multi-Center Study Planning",
        "what": "Coordinated Research Networks",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Multi-Center Considerations: - Account -site variability - Consider hierarchical study designs - Plan adequate power site",
        "code": "# Multi-center standardization study result <- kappaSizePower(   outcome = \"4\",   kappa0 = 0.55,          # Current multi-center variability   kappa1 = 0.75,          # Target standardized agreement   props = \"0.25, 0.30, 0.25, 0.20\",   raters = \"3\",           # Representative raters per site   alpha = 0.05,   power = 0.85            # Higher power for multi-center )"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "realistic-effect-size-setting",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "1. Realistic Effect Size Setting",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Base κ₀ literature review pilot data Set κ₁ represent clinically meaningful improvement Consider improvement often decreases real-world settings",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "proportion-estimation",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "2. Proportion Estimation",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Use registry data large databases available Consider temporal geographical variations Account selection bias study populations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "power-and-alpha-selection",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "3. Power and Alpha Selection",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Standard Approaches: - α = 0.05, Power = 0.80: clinical studies - α = 0.01, Power = 0.90: High-stakes validation studies - α = 0.05, Power = 0.85: Regulatory submissions",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "rater-selection-and-training",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Study Design Considerations",
        "what": "4. Rater Selection and Training",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Training: Ensure consistent training across raters Experience: Balance expertise availability Independence: Maintain rater independence assessment Calibration: Consider calibration exercises",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "unrealistic-effect-size-expectations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "1. Unrealistic Effect Size Expectations",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Problem: Setting κ₁ high based ideal conditions Solution: - Review literature realistic agreement levels - Conduct pilot studies actual conditions - Account implementation challenges",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "ignoring-practical-constraints",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "2. Ignoring Practical Constraints",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Problem: Sample size calculations exceed feasible recruitment Solution: - Consider feasibility planning - Explore alternative study designs - Plan adaptive sequential designs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "inadequate-baseline-assessment",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "3. Inadequate Baseline Assessment",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Problem: Poor κ₀ estimation leading underpowered studies Solution: - Conduct thorough baseline assessment - Use multiple data sources κ₀ estimation - Consider sensitivity analyses",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "overlooking-implementation-complexity",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Common Pitfalls and Solutions",
        "what": "4. Overlooking Implementation Complexity",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Problem: accounting real-world implementation challenges Solution: - Plan training calibration time - Account rater availability scheduling - Consider quality control procedures",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "pre-study-planning-checklist",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Quality Assurance Framework",
        "what": "Pre-study Planning Checklist",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Literature review completed realistic κ₀ κ₁ values Proportion estimates obtained reliable sources Power analysis conducted multiple scenarios Feasibility assessment completed Rater training protocol established Quality control procedures defined",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "during-study-monitoring",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Quality Assurance Framework",
        "what": "During-study Monitoring",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Interim agreement assessments conducted Rater consistency monitored Protocol adherence documented Sample size adequacy reassessed",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "post-study-validation",
        "dir": "Articles",
        "previous_headings": "Best Practices and Guidelines > Quality Assurance Framework",
        "what": "Post-study Validation",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Achieved agreement levels compared predictions Power analysis assumptions validated Lessons learned documented future studies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "understanding-power-analysis-output",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results",
        "what": "Understanding Power Analysis Output",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "kappasizepower function provides: Required Sample Size: Number subjects needed Study Design Summary: Comprehensive explanation parameters context",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "sample-size-interpretation",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Understanding Power Analysis Output",
        "what": "Sample Size Interpretation",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Key Considerations: - Sample size refers number subjects rated raters - Consider dropout rates missing data - Plan quality control assessments",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "clinical-decision-making",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Understanding Power Analysis Output",
        "what": "Clinical Decision Making",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Use results : - Justify study feasibility grant applications - Set recruitment targets multi-center studies - Inform resource planning training implementation - Support protocol development",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "in-grant-applications",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Grant Applications",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "“Power analysis using kappasizepower indicated N subjects required detect improvement inter-rater agreement κ₀=X κ₁=Y 80% power 5% significance level.”",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "in-study-protocols",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Study Protocols",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Detail power analysis assumptions including: - Baseline agreement estimates sources - Target agreement levels justification - Effect size rationale - Power alpha selection rationale",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "in-manuscripts",
        "dir": "Articles",
        "previous_headings": "Interpretation of Results > Reporting Guidelines",
        "what": "In Manuscripts",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Report power analysis achieved results: - Compare observed agreement predicted levels - Discuss discrepancies planned achieved parameters - Address implications study conclusions",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "kappa1-must-be-greater-than-kappa0",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“kappa1 must be greater than kappa0”",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cause: Alternative hypothesis agreement better null hypothesis Solution:",
        "code": "# Incorrect kappa0 = 0.70, kappa1 = 0.60  # kappa1 < kappa0  # Correct kappa0 = 0.60, kappa1 = 0.70  # kappa1 > kappa0"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "proportions-must-sum-to-1",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“Proportions must sum to 1”",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cause: Category proportions don’t sum exactly 1.0 Solution: Adjust proportions use normalized values",
        "code": "# Incorrect props = \"0.25, 0.80\"  # Sums to 1.05  # Correct props = \"0.24, 0.76\"  # Sums to 1.00"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "power-should-be-at-least-0-5-for-meaningful-analysis",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“Power should be at least 0.5 for meaningful analysis”",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cause: Power set low reasonable detection Solution: Increase power least 50%, typically 80%",
        "code": "# Problematic power = 0.30  # Too low  # Recommended power = 0.80  # Standard minimum"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "kappasize-package-not-installed",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Error Messages and Solutions",
        "what": "“kappaSize package not installed”",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cause: Required dependency available Solution: Install kappaSize package",
        "code": "install.packages(\"kappaSize\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "very-large-sample-size-requirements",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Computational Issues",
        "what": "Very Large Sample Size Requirements",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "sample sizes exceed feasible limits: Solutions: - Reduce effect size expectations (smaller κ₁ - κ₀) - Accept lower power (minimum 80%) - Consider multi-stage adaptive designs - Explore alternative study approaches",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "small-effect-sizes",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Computational Issues",
        "what": "Small Effect Sizes",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "small effect sizes (κ₁ - κ₀ < 0.10): Considerations: - Ensure clinical meaningfulness small improvements - Consider cost-benefit large sample requirements - Explore whether improvement justifies study",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "complex-multi-rater-scenarios",
        "dir": "Articles",
        "previous_headings": "Troubleshooting Common Issues > Computational Issues",
        "what": "Complex Multi-rater Scenarios",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "4-5 raters 4-5 categories: Solutions: - Ensure computational stability adequate samples - Consider phased implementation approaches - Validate simulation studies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "complementary-functions",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Complementary Functions",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "kappasizepower function works alongside: kappasizefixedn: fixed sample size power analysis agreement functions: post-hoc agreement assessment Sample size calculators: comprehensive study planning",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "advanced-methods",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Advanced Methods",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "specialized scenarios, consider: Weighted kappa: ordinal categories meaningful ordering Multilevel models: hierarchical data structures Bayesian approaches: incorporating prior information Sequential designs: adaptive sample size modification",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "software-integration",
        "dir": "Articles",
        "previous_headings": "Future Directions and Related Tools",
        "what": "Software Integration",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "function integrates well : jamovi: User-friendly interface clinical researchers R workflows: Programmable analysis pipelines Reproducible research: RMarkdown Quarto integration",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "summary",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Summary",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "kappasizepower function provides essential power analysis capabilities inter-rater agreement studies. Key takeaways: Use prospective study planning requiring specific power levels Ensures adequate sample sizes detecting meaningful agreement improvements Supports 2-5 categories 2-5 raters comprehensive validation Requires κ₁ > κ₀ valid power analysis Integrates comprehensive research planning workflows understanding properly applying tool, researchers can design adequately powered studies validate inter-rater agreement improvements, supporting evidence-based advances clinical practice research methodology.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/09-kappasizepower-comprehensive.html",
        "id": "references",
        "dir": "Articles",
        "previous_headings": "",
        "what": "References",
        "title": "Complete Guide to kappasizepower: Power Analysis for Inter-rater Agreement Studies",
        "text": "Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20(1), 37-46. Fleiss, J. L., Levin, B., & Paik, M. C. (2003). Statistical methods rates proportions. John Wiley & Sons. Gwet, K. L. (2014). Handbook inter-rater reliability: definitive guide measuring extent agreement among raters. Advanced Analytics, LLC. Landis, J. R., & Koch, G. G. (1977). measurement observer agreement categorical data. Biometrics, 33(1), 159-174. Shoukri, M. M. (2011). Measures interobserver agreement reliability. Chapman Hall/CRC. vignette generated using ClinicoPath R package. information, visit ClinicoPath GitHub repository.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Decision Panel Optimization module meddecide package provides comprehensive framework optimizing diagnostic test combinations medical decision-making. vignette introduces basic concepts demonstrates core functionality.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "testing-strategies",
        "dir": "Articles",
        "previous_headings": "Key Concepts",
        "what": "Testing Strategies",
        "title": "Introduction to Decision Panel Optimization",
        "text": "multiple diagnostic tests available, can combined different ways: Single Testing: Use individual tests independently rule (): Positive test positive rule (): Positive tests positive MAJORITY rule: Positive majority tests positive Stop first positive Confirmatory (require multiple positives) Exclusion (require multiple negatives)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "optimization-criteria",
        "dir": "Articles",
        "previous_headings": "Key Concepts",
        "what": "Optimization Criteria",
        "title": "Introduction to Decision Panel Optimization",
        "text": "module can optimize test panels based various criteria: Accuracy: Overall correct classification rate Sensitivity: Ability detect disease (minimize false negatives) Specificity: Ability rule disease (minimize false positives) Predictive Values: PPV NPV Cost-Effectiveness: Balance performance resource utilization Utility: Custom utility functions incorporating costs errors",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "installation-and-loading",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Installation and Loading",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "# Install meddecide package install.packages(\"meddecide\")  # Or install from GitHub devtools::install_github(\"ClinicoPath/meddecide\") # Load required packages library(meddecide) library(dplyr) library(ggplot2) library(rpart) library(rpart.plot) library(knitr) library(forcats)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "basic-example-covid-19-screening",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Basic Example: COVID-19 Screening",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Let’s start simple example using COVID-19 screening data:",
        "code": "# Examine the data structure str(covid_screening_data)  # Check disease prevalence table(covid_screening_data$covid_status) prop.table(table(covid_screening_data$covid_status))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "running-basic-analysis",
        "dir": "Articles",
        "previous_headings": "Basic Example: COVID-19 Screening",
        "what": "Running Basic Analysis",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "# Basic decision panel analysis covid_panel <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   strategies = \"all\",   optimizationCriteria = \"accuracy\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "interpreting-results",
        "dir": "Articles",
        "previous_headings": "Basic Example: COVID-19 Screening",
        "what": "Interpreting Results",
        "title": "Introduction to Decision Panel Optimization",
        "text": "analysis provides several key outputs: Individual Test Performance: test performs alone Optimal Panel: best combination tests Strategy Comparison: Performance different testing approaches Decision Tree: Optimal sequence testing",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "parallel-testing-example",
        "dir": "Articles",
        "previous_headings": "Understanding Testing Strategies",
        "what": "Parallel Testing Example",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "# Simulate parallel testing with ANY rule # Positive if rapid_antigen OR pcr is positive parallel_any <- with(covid_screening_data,    rapid_antigen == \"Positive\" | pcr == \"Positive\" )  # Create confusion matrix conf_matrix_any <- table(   Predicted = parallel_any,   Actual = covid_screening_data$covid_status == \"Positive\" )  print(conf_matrix_any)  # Calculate metrics sensitivity_any <- conf_matrix_any[2,2] / sum(conf_matrix_any[,2]) specificity_any <- conf_matrix_any[1,1] / sum(conf_matrix_any[,1])  cat(\"Parallel ANY Rule:\\n\") cat(sprintf(\"Sensitivity: %.1f%%\\n\", sensitivity_any * 100)) cat(sprintf(\"Specificity: %.1f%%\\n\", specificity_any * 100))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "sequential-testing-example",
        "dir": "Articles",
        "previous_headings": "Understanding Testing Strategies",
        "what": "Sequential Testing Example",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "# Simulate sequential testing # Start with rapid test, only do PCR if rapid is positive sequential_result <- rep(\"Negative\", nrow(covid_screening_data))  # Those with positive rapid test rapid_pos_idx <- which(covid_screening_data$rapid_antigen == \"Positive\")  # Among those, check PCR sequential_result[rapid_pos_idx] <-    ifelse(covid_screening_data$pcr[rapid_pos_idx] == \"Positive\",           \"Positive\", \"Negative\")  # Create confusion matrix conf_matrix_seq <- table(   Predicted = sequential_result == \"Positive\",   Actual = covid_screening_data$covid_status == \"Positive\" )  print(conf_matrix_seq)  # Calculate metrics sensitivity_seq <- conf_matrix_seq[2,2] / sum(conf_matrix_seq[,2]) specificity_seq <- conf_matrix_seq[1,1] / sum(conf_matrix_seq[,1])  cat(\"\\nSequential Testing:\\n\") cat(sprintf(\"Sensitivity: %.1f%%\\n\", sensitivity_seq * 100)) cat(sprintf(\"Specificity: %.1f%%\\n\", specificity_seq * 100))  # Calculate cost savings pcr_tests_saved <- sum(covid_screening_data$rapid_antigen == \"Negative\") cat(sprintf(\"PCR tests saved: %d (%.1f%%)\\n\",              pcr_tests_saved,              pcr_tests_saved/nrow(covid_screening_data) * 100))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "cost-effectiveness-analysis",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Cost-Effectiveness Analysis",
        "title": "Introduction to Decision Panel Optimization",
        "text": "costs considered, optimal strategy may change:",
        "code": "# Analysis with costs covid_panel_cost <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   strategies = \"all\",   optimizationCriteria = \"utility\",   useCosts = TRUE,   testCosts = \"5,50,200\",  # Costs for each test   fpCost = 500,            # Cost of false positive   fnCost = 5000            # Cost of false negative )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "performance-comparison-plot",
        "dir": "Articles",
        "previous_headings": "Visualization",
        "what": "Performance Comparison Plot",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "# Create performance comparison data strategies <- data.frame(   Strategy = c(\"Rapid Only\", \"PCR Only\", \"Parallel ANY\", \"Sequential\"),   Sensitivity = c(65, 95, 98, 62),   Specificity = c(98, 99, 97, 99.9),   Cost = c(5, 50, 55, 15) )  # Plot sensitivity vs specificity ggplot(strategies, aes(x = 100 - Specificity, y = Sensitivity)) +   geom_point(aes(size = Cost), alpha = 0.6) +   geom_text(aes(label = Strategy), vjust = -1) +   scale_size_continuous(range = c(3, 10)) +   xlim(0, 5) + ylim(60, 100) +   labs(     title = \"Testing Strategy Comparison\",     x = \"False Positive Rate (%)\",     y = \"Sensitivity (%)\",     size = \"Cost ($)\"   ) +   theme_minimal()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "decision-trees",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Decision Trees",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Decision trees provide clear algorithms clinical use:",
        "code": "# Generate decision tree covid_tree <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\", \"symptom_score\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\", \">5\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   createTree = TRUE,   treeMethod = \"cart\",   maxDepth = 3 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "interpreting-the-tree",
        "dir": "Articles",
        "previous_headings": "Decision Trees",
        "what": "Interpreting the Tree",
        "title": "Introduction to Decision Panel Optimization",
        "text": "typical decision tree output might look like:",
        "code": "1. Start with Rapid Antigen Test    ├─ If Positive (2% of patients)    │  └─ Confirm with PCR    │     ├─ If Positive → COVID Positive (PPV: 95%)    │     └─ If Negative → COVID Negative (NPV: 98%)    └─ If Negative (98% of patients)       ├─ If Symptoms > 5       │  └─ Perform Chest CT       │     ├─ If Abnormal → Perform PCR       │     └─ If Normal → COVID Negative       └─ If Symptoms ≤ 5 → COVID Negative"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "cross-validation",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Cross-Validation",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Validate panel performance using k-fold cross-validation:",
        "code": "# Run with cross-validation covid_panel_cv <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   crossValidate = TRUE,   nFolds = 5,   seed = 123 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "bootstrap-confidence-intervals",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Bootstrap Confidence Intervals",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Get uncertainty estimates performance metrics:",
        "code": "# Run with bootstrap covid_panel_boot <- decisionpanel(   data = covid_screening_data,   tests = c(\"rapid_antigen\", \"pcr\", \"chest_ct\"),   testLevels = c(\"Positive\", \"Positive\", \"Abnormal\"),   gold = \"covid_status\",   goldPositive = \"Positive\",   bootstrap = TRUE,   bootReps = 1000,   seed = 123 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "best-practices",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Best Practices",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Start Simple: Begin individual test performance combinations Consider Context: Screening vs. diagnosis requires different strategies Validate Results: Use cross-validation separate test sets Include Costs: Real-world decisions must consider resources Think Sequentially: Often efficient parallel testing Set Constraints: Define minimum acceptable performance Interpret Clinically: Statistical optimality isn’t everything",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Introduction to Decision Panel Optimization",
        "text": "Decision Panel Optimization module provides systematic approach combining diagnostic tests. considering various strategies, costs, constraints, helps identify practical testing algorithms balance performance resource utilization.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Next Steps",
        "title": "Introduction to Decision Panel Optimization",
        "text": "See “Clinical Applications” vignette disease-specific examples Review “Advanced Optimization” complex scenarios Check “Implementation Guide” deploying algorithms practice",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/10-decision-panel-optimization.html",
        "id": "session-information",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Session Information",
        "title": "Introduction to Decision Panel Optimization",
        "text": "",
        "code": "sessionInfo()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Precision oncology represents paradigm shift one-size-fits-cancer treatment personalized therapy based molecular characteristics individual tumors. vignette demonstrates comprehensive biomarker analysis, treatment selection algorithms, outcome evaluation using ClinicoPath modules. Learning Objectives: Master precision oncology biomarker interpretation Learn treatment selection algorithms based molecular profiles Analyze biomarker-outcome relationships Understand companion diagnostic requirements Implement clinical decision support systems Evaluate cost-effectiveness precision medicine approaches",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "clinical-context",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Clinical Context",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Modern precision oncology requires integration multiple biomarker types: Predictive Biomarkers: Guide treatment selection (EGFR, HER2, PD-L1) Prognostic Biomarkers: Predict disease outcome (Ki-67, p53) Pharmacogenomic Markers: Influence drug metabolism (CYP2D6, TPMT) Resistance Markers: Predict treatment failure (T790M, MET amplification) Immune Markers: Guide immunotherapy (MSI, TMB, TILs)",
        "code": "library(meddecide) library(dplyr) library(ggplot2) library(survival) library(pROC)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "precision-oncology-dataset",
        "dir": "Articles",
        "previous_headings": "Dataset Overview",
        "what": "Precision Oncology Dataset",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "precision_oncology_data dataset contains 116 patients comprehensive molecular profiling treatment outcomes, representing real-world precision oncology scenarios.",
        "code": "# Load the precision oncology dataset data(precision_oncology_data)  # Dataset structure str(precision_oncology_data) cat(\"Dataset dimensions:\", nrow(precision_oncology_data), \"patients ×\",      ncol(precision_oncology_data), \"variables\\n\")  # Patient demographics demographic_summary <- precision_oncology_data %>%   summarise(     median_age = median(Age),     age_range = paste(min(Age), \"-\", max(Age)),     female_pct = round(mean(Gender == \"Female\") * 100, 1),     n_tumor_types = length(unique(Tumor_Type))   )  print(\"Patient Demographics:\") print(demographic_summary)  # Tumor type distribution tumor_distribution <- table(precision_oncology_data$Tumor_Type) print(\"Tumor Type Distribution:\") print(tumor_distribution)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "actionable-biomarker-frequencies",
        "dir": "Articles",
        "previous_headings": "Biomarker Landscape Analysis",
        "what": "Actionable Biomarker Frequencies",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Assess prevalence actionable molecular alterations.",
        "code": "# Calculate biomarker frequencies biomarker_summary <- precision_oncology_data %>%   summarise(     # Targeted therapy biomarkers     egfr_positive = sum(EGFR_Mutation == \"Positive\"),     her2_amplified = sum(HER2_FISH_Status == \"Amplified\"),     braf_positive = sum(BRAF_Mutation == \"Positive\"),     alk_positive = sum(ALK_Fusion == \"Positive\"),          # Immunotherapy biomarkers     msi_high = sum(MSI_Status == \"MSI-High\"),     pdl1_high = sum(PD_L1_TPS >= 50),     pdl1_positive = sum(PD_L1_TPS >= 1),          # Any actionable alteration     any_targeted = sum(EGFR_Mutation == \"Positive\" |                        HER2_FISH_Status == \"Amplified\" |                       BRAF_Mutation == \"Positive\" |                       ALK_Fusion == \"Positive\"),          any_immunotherapy = sum(MSI_Status == \"MSI-High\" | PD_L1_TPS >= 1),          total_patients = n()   )  # Convert to percentages and create summary table biomarker_table <- data.frame(   Biomarker = c(\"EGFR Mutation\", \"HER2 Amplification\", \"BRAF Mutation\",                  \"ALK Fusion\", \"MSI-High\", \"PD-L1 ≥50%\", \"PD-L1 ≥1%\",                 \"Any Targeted Therapy\", \"Any Immunotherapy\"),   Count = c(biomarker_summary$egfr_positive, biomarker_summary$her2_amplified,             biomarker_summary$braf_positive, biomarker_summary$alk_positive,             biomarker_summary$msi_high, biomarker_summary$pdl1_high,             biomarker_summary$pdl1_positive, biomarker_summary$any_targeted,             biomarker_summary$any_immunotherapy),   Percentage = round(c(biomarker_summary$egfr_positive, biomarker_summary$her2_amplified,                       biomarker_summary$braf_positive, biomarker_summary$alk_positive,                       biomarker_summary$msi_high, biomarker_summary$pdl1_high,                       biomarker_summary$pdl1_positive, biomarker_summary$any_targeted,                       biomarker_summary$any_immunotherapy) /                       biomarker_summary$total_patients * 100, 1) )  print(\"Actionable Biomarker Frequencies:\") print(biomarker_table)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "tumor-specific-biomarker-patterns",
        "dir": "Articles",
        "previous_headings": "Biomarker Landscape Analysis",
        "what": "Tumor-Specific Biomarker Patterns",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Analyze biomarker patterns tumor type.",
        "code": "# Biomarker frequencies by tumor type biomarker_by_tumor <- precision_oncology_data %>%   group_by(Tumor_Type) %>%   summarise(     n = n(),     egfr_pct = round(mean(EGFR_Mutation == \"Positive\") * 100, 1),     her2_pct = round(mean(HER2_FISH_Status == \"Amplified\") * 100, 1),     braf_pct = round(mean(BRAF_Mutation == \"Positive\") * 100, 1),     msi_high_pct = round(mean(MSI_Status == \"MSI-High\") * 100, 1),     pdl1_high_pct = round(mean(PD_L1_TPS >= 50) * 100, 1),     .groups = 'drop'   ) %>%   arrange(desc(n))  print(\"Biomarker Frequencies by Tumor Type:\") print(biomarker_by_tumor)  # Identify tumor types with highest actionable biomarker rates high_actionable <- precision_oncology_data %>%   mutate(     actionable = EGFR_Mutation == \"Positive\" |                  HER2_FISH_Status == \"Amplified\" |                 BRAF_Mutation == \"Positive\" |                 ALK_Fusion == \"Positive\" |                 MSI_Status == \"MSI-High\" |                 PD_L1_TPS >= 50   ) %>%   group_by(Tumor_Type) %>%   summarise(     n = n(),     actionable_rate = round(mean(actionable) * 100, 1),     .groups = 'drop'   ) %>%   filter(n >= 5) %>%   arrange(desc(actionable_rate))  print(\"Tumor Types with Highest Actionable Biomarker Rates:\") print(head(high_actionable, 5))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "rule-based-treatment-assignment",
        "dir": "Articles",
        "previous_headings": "Treatment Selection Algorithms",
        "what": "Rule-Based Treatment Assignment",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Implement clinical guideline-based treatment selection.",
        "code": "# Create treatment selection algorithm precision_oncology_data <- precision_oncology_data %>%   mutate(     # Primary treatment recommendation based on biomarkers     primary_treatment = case_when(       EGFR_Mutation == \"Positive\" ~ \"EGFR TKI\",       HER2_FISH_Status == \"Amplified\" ~ \"HER2-Targeted Therapy\",       BRAF_Mutation == \"Positive\" & Tumor_Type == \"Melanoma\" ~ \"BRAF Inhibitor\",       ALK_Fusion == \"Positive\" ~ \"ALK Inhibitor\",       TRUE ~ \"Standard Chemotherapy\"     ),          # Immunotherapy candidacy     immunotherapy_candidate = case_when(       MSI_Status == \"MSI-High\" ~ \"First-line Immunotherapy\",       PD_L1_TPS >= 50 ~ \"First-line Anti-PD-1\",       PD_L1_TPS >= 1 ~ \"Combination Therapy\",       TRUE ~ \"Chemotherapy First\"     ),          # Treatment complexity score     treatment_complexity = case_when(       EGFR_Mutation == \"Positive\" | ALK_Fusion == \"Positive\" ~ \"High\",       HER2_FISH_Status == \"Amplified\" | MSI_Status == \"MSI-High\" ~ \"High\",        PD_L1_TPS >= 50 ~ \"Medium\",       PD_L1_TPS >= 1 ~ \"Medium\",       TRUE ~ \"Standard\"     )   )  # Treatment recommendation summary treatment_summary <- table(precision_oncology_data$primary_treatment) print(\"Primary Treatment Recommendations:\") print(treatment_summary)  immunotherapy_summary <- table(precision_oncology_data$immunotherapy_candidate) print(\"Immunotherapy Recommendations:\") print(immunotherapy_summary)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "biomarker-combination-analysis",
        "dir": "Articles",
        "previous_headings": "Treatment Selection Algorithms",
        "what": "Biomarker Combination Analysis",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Analyze patients multiple actionable biomarkers.",
        "code": "# Identify patients with multiple biomarkers precision_oncology_data <- precision_oncology_data %>%   mutate(     biomarker_count =        as.numeric(EGFR_Mutation == \"Positive\") +       as.numeric(HER2_FISH_Status == \"Amplified\") +       as.numeric(BRAF_Mutation == \"Positive\") +       as.numeric(ALK_Fusion == \"Positive\") +       as.numeric(MSI_Status == \"MSI-High\") +       as.numeric(PD_L1_TPS >= 50),          biomarker_category = case_when(       biomarker_count == 0 ~ \"No Actionable Biomarkers\",       biomarker_count == 1 ~ \"Single Biomarker\",       biomarker_count >= 2 ~ \"Multiple Biomarkers\"     )   )  biomarker_count_summary <- table(precision_oncology_data$biomarker_category) print(\"Biomarker Count Distribution:\") print(biomarker_count_summary)  # Analyze combination patterns multiple_biomarker_cases <- precision_oncology_data %>%   filter(biomarker_count >= 2) %>%   select(Patient_ID, Tumor_Type, EGFR_Mutation, HER2_FISH_Status,           BRAF_Mutation, ALK_Fusion, MSI_Status, PD_L1_TPS)  if(nrow(multiple_biomarker_cases) > 0) {   cat(\"Patients with Multiple Actionable Biomarkers:\", nrow(multiple_biomarker_cases), \"\\n\")   print(head(multiple_biomarker_cases)) }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "treatment-response-analysis",
        "dir": "Articles",
        "previous_headings": "Biomarker-Outcome Relationships",
        "what": "Treatment Response Analysis",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Assess biomarker predictive value treatment response.",
        "code": "# Response rates by biomarker status response_analysis <- precision_oncology_data %>%   mutate(     objective_response = Treatment_Response %in% c(\"Complete_Response\", \"Partial_Response\")   ) %>%   summarise(     # Overall response rate     overall_response_rate = round(mean(objective_response) * 100, 1),          # Response by biomarker status     egfr_positive_response = round(       mean(objective_response[EGFR_Mutation == \"Positive\"]) * 100, 1),     egfr_negative_response = round(       mean(objective_response[EGFR_Mutation == \"Negative\"]) * 100, 1),          her2_amplified_response = round(       mean(objective_response[HER2_FISH_Status == \"Amplified\"], na.rm = TRUE) * 100, 1),     her2_not_amplified_response = round(       mean(objective_response[HER2_FISH_Status != \"Amplified\"], na.rm = TRUE) * 100, 1),          msi_high_response = round(       mean(objective_response[MSI_Status == \"MSI-High\"]) * 100, 1),     msi_low_mss_response = round(       mean(objective_response[MSI_Status != \"MSI-High\"]) * 100, 1),          pdl1_high_response = round(       mean(objective_response[PD_L1_TPS >= 50]) * 100, 1),     pdl1_low_response = round(       mean(objective_response[PD_L1_TPS < 50]) * 100, 1)   )  print(\"Response Rates by Biomarker Status:\") print(response_analysis)  # Statistical significance testing # EGFR mutation vs response egfr_response_table <- table(precision_oncology_data$EGFR_Mutation,                              precision_oncology_data$Treatment_Response %in%                              c(\"Complete_Response\", \"Partial_Response\"))  if(min(egfr_response_table) >= 5) {   egfr_test <- fisher.test(egfr_response_table)   cat(\"EGFR mutation vs response p-value:\", round(egfr_test$p.value, 3), \"\\n\") }  # MSI status vs response msi_response_table <- table(precision_oncology_data$MSI_Status == \"MSI-High\",                            precision_oncology_data$Treatment_Response %in%                             c(\"Complete_Response\", \"Partial_Response\"))  if(min(msi_response_table) >= 5) {   msi_test <- fisher.test(msi_response_table)   cat(\"MSI-High vs response p-value:\", round(msi_test$p.value, 3), \"\\n\") }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "progression-free-survival-analysis",
        "dir": "Articles",
        "previous_headings": "Biomarker-Outcome Relationships",
        "what": "Progression-Free Survival Analysis",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Analyze time--progression biomarker status.",
        "code": "# PFS analysis by biomarker groups pfs_summary <- precision_oncology_data %>%   group_by(EGFR_Mutation) %>%   summarise(     n = n(),     median_pfs = median(PFS_Months),     progression_rate = round(mean(Progression_Event) * 100, 1),     .groups = 'drop'   )  print(\"PFS by EGFR Status:\") print(pfs_summary)  # MSI status PFS analysis msi_pfs_summary <- precision_oncology_data %>%   group_by(MSI_Status) %>%   summarise(     n = n(),     median_pfs = median(PFS_Months),     progression_rate = round(mean(Progression_Event) * 100, 1),     .groups = 'drop'   )  print(\"PFS by MSI Status:\") print(msi_pfs_summary)  # Survival analysis if survival package available if(requireNamespace(\"survival\", quietly = TRUE)) {   library(survival)      # Create survival object   surv_obj <- Surv(precision_oncology_data$PFS_Months,                     precision_oncology_data$Progression_Event)      # Kaplan-Meier analysis by EGFR status   km_egfr <- survfit(surv_obj ~ EGFR_Mutation, data = precision_oncology_data)      cat(\"\\nKaplan-Meier Analysis - EGFR Status:\\n\")   print(summary(km_egfr)$table)      # Log-rank test   logrank_egfr <- survdiff(surv_obj ~ EGFR_Mutation, data = precision_oncology_data)   cat(\"Log-rank test p-value (EGFR):\", round(1 - pchisq(logrank_egfr$chisq, 1), 3), \"\\n\")      # Cox proportional hazards model   cox_model <- coxph(surv_obj ~ EGFR_Mutation + MSI_Status + PD_L1_TPS + Age,                       data = precision_oncology_data)      cat(\"\\nCox Regression Results:\\n\")   print(summary(cox_model)$coefficients[, c(\"coef\", \"exp(coef)\", \"Pr(>|z|)\")]) }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "roc-analysis-for-biomarker-cutpoints",
        "dir": "Articles",
        "previous_headings": "Companion Diagnostic Development",
        "what": "ROC Analysis for Biomarker Cutpoints",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Optimize biomarker cutpoints treatment selection.",
        "code": "# ROC analysis for PD-L1 TPS cutpoint optimization if(requireNamespace(\"pROC\", quietly = TRUE)) {   library(pROC)      # Create binary response outcome   response_binary <- as.numeric(precision_oncology_data$Treatment_Response %in%                                 c(\"Complete_Response\", \"Partial_Response\"))      # ROC analysis for PD-L1 TPS   roc_pdl1 <- roc(response_binary, precision_oncology_data$PD_L1_TPS, quiet = TRUE)      cat(\"PD-L1 TPS ROC Analysis:\\n\")   cat(\"AUC:\", round(auc(roc_pdl1), 3), \"\\n\")   cat(\"95% CI:\", paste(round(ci.auc(roc_pdl1), 3), collapse = \" - \"), \"\\n\")      # Optimal cutpoint using Youden index   optimal_cutpoint <- coords(roc_pdl1, \"best\", ret = \"threshold\")   cat(\"Optimal cutpoint (Youden):\", round(optimal_cutpoint, 1), \"\\n\")      # Performance at standard cutpoints   cutpoints <- c(1, 10, 20, 50)      performance_table <- data.frame(     Cutpoint = cutpoints,     Sensitivity = sapply(cutpoints, function(x) {       round(coords(roc_pdl1, x, ret = \"sensitivity\"), 3)     }),     Specificity = sapply(cutpoints, function(x) {       round(coords(roc_pdl1, x, ret = \"specificity\"), 3)     }),     PPV = sapply(cutpoints, function(x) {       tp <- sum(precision_oncology_data$PD_L1_TPS >= x & response_binary == 1)       fp <- sum(precision_oncology_data$PD_L1_TPS >= x & response_binary == 0)       round(tp / (tp + fp), 3)     }),     NPV = sapply(cutpoints, function(x) {       tn <- sum(precision_oncology_data$PD_L1_TPS < x & response_binary == 0)       fn <- sum(precision_oncology_data$PD_L1_TPS < x & response_binary == 1)       round(tn / (tn + fn), 3)     })   )      print(\"Performance at Different PD-L1 Cutpoints:\")   print(performance_table) }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "biomarker-test-validation",
        "dir": "Articles",
        "previous_headings": "Companion Diagnostic Development",
        "what": "Biomarker Test Validation",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Assess clinical utility biomarker testing.",
        "code": "# Clinical utility analysis # Calculate number needed to test (NNT) for different biomarkers  nnt_analysis <- function(biomarker_positive, response_rate_positive, response_rate_negative, prevalence) {   # Response rate difference   response_difference <- response_rate_positive - response_rate_negative      # Number needed to treat with biomarker guidance   nnt <- 1 / (response_difference * prevalence)      return(round(nnt, 1)) }  # EGFR mutation NNT egfr_prevalence <- mean(precision_oncology_data$EGFR_Mutation == \"Positive\") egfr_pos_response <- mean(precision_oncology_data$Treatment_Response[precision_oncology_data$EGFR_Mutation == \"Positive\"] %in%                           c(\"Complete_Response\", \"Partial_Response\")) egfr_neg_response <- mean(precision_oncology_data$Treatment_Response[precision_oncology_data$EGFR_Mutation == \"Negative\"] %in%                           c(\"Complete_Response\", \"Partial_Response\"))  egfr_nnt <- nnt_analysis(NULL, egfr_pos_response, egfr_neg_response, egfr_prevalence)  # MSI-High NNT msi_prevalence <- mean(precision_oncology_data$MSI_Status == \"MSI-High\") msi_pos_response <- mean(precision_oncology_data$Treatment_Response[precision_oncology_data$MSI_Status == \"MSI-High\"] %in%                          c(\"Complete_Response\", \"Partial_Response\")) msi_neg_response <- mean(precision_oncology_data$Treatment_Response[precision_oncology_data$MSI_Status != \"MSI-High\"] %in%                          c(\"Complete_Response\", \"Partial_Response\"))  msi_nnt <- nnt_analysis(NULL, msi_pos_response, msi_neg_response, msi_prevalence)  clinical_utility_table <- data.frame(   Biomarker = c(\"EGFR Mutation\", \"MSI-High Status\"),   Prevalence = paste0(round(c(egfr_prevalence, msi_prevalence) * 100, 1), \"%\"),   Response_Rate_Positive = paste0(round(c(egfr_pos_response, msi_pos_response) * 100, 1), \"%\"),   Response_Rate_Negative = paste0(round(c(egfr_neg_response, msi_neg_response) * 100, 1), \"%\"),   Number_Needed_to_Test = c(egfr_nnt, msi_nnt) )  print(\"Clinical Utility Analysis:\") print(clinical_utility_table)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "cost-effectiveness-analysis",
        "dir": "Articles",
        "previous_headings": "Economic Evaluation",
        "what": "Cost-Effectiveness Analysis",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Assess economic impact biomarker-guided therapy.",
        "code": "# Simulate treatment costs and outcomes precision_oncology_data <- precision_oncology_data %>%   mutate(     # Estimate treatment costs based on therapy type     treatment_cost = case_when(       primary_treatment == \"EGFR TKI\" ~ 120000,       primary_treatment == \"HER2-Targeted Therapy\" ~ 150000,       primary_treatment == \"BRAF Inhibitor\" ~ 140000,       primary_treatment == \"ALK Inhibitor\" ~ 160000,       immunotherapy_candidate == \"First-line Immunotherapy\" ~ 180000,       immunotherapy_candidate == \"First-line Anti-PD-1\" ~ 150000,       TRUE ~ 80000  # Standard chemotherapy     ),          # Estimate testing costs     testing_cost = case_when(       biomarker_count == 0 ~ 0,       biomarker_count == 1 ~ 1500,       biomarker_count >= 2 ~ 3000     ),          # Total cost per patient     total_cost = treatment_cost + testing_cost,          # Quality-adjusted life years (QALYs) based on response and survival     qalys = case_when(       Treatment_Response == \"Complete_Response\" ~ PFS_Months * 0.9 / 12,       Treatment_Response == \"Partial_Response\" ~ PFS_Months * 0.8 / 12,       Treatment_Response == \"Stable_Disease\" ~ PFS_Months * 0.7 / 12,       Treatment_Response == \"Progressive_Disease\" ~ PFS_Months * 0.4 / 12,       TRUE ~ PFS_Months * 0.5 / 12     )   )  # Cost-effectiveness by biomarker strategy cost_effectiveness_summary <- precision_oncology_data %>%   group_by(biomarker_category) %>%   summarise(     n = n(),     mean_cost = round(mean(total_cost), 0),     mean_qalys = round(mean(qalys), 2),     cost_per_qaly = round(mean(total_cost) / mean(qalys), 0),     response_rate = round(mean(Treatment_Response %in% c(\"Complete_Response\", \"Partial_Response\")) * 100, 1),     .groups = 'drop'   )  print(\"Cost-Effectiveness by Biomarker Strategy:\") print(cost_effectiveness_summary)  # Incremental cost-effectiveness ratio (ICER) no_biomarker_cost <- cost_effectiveness_summary$mean_cost[cost_effectiveness_summary$biomarker_category == \"No Actionable Biomarkers\"] single_biomarker_cost <- cost_effectiveness_summary$mean_cost[cost_effectiveness_summary$biomarker_category == \"Single Biomarker\"]  no_biomarker_qaly <- cost_effectiveness_summary$mean_qalys[cost_effectiveness_summary$biomarker_category == \"No Actionable Biomarkers\"] single_biomarker_qaly <- cost_effectiveness_summary$mean_qalys[cost_effectiveness_summary$biomarker_category == \"Single Biomarker\"]  if(length(no_biomarker_cost) > 0 && length(single_biomarker_cost) > 0) {   icer <- (single_biomarker_cost - no_biomarker_cost) / (single_biomarker_qaly - no_biomarker_qaly)   cat(\"ICER (Single Biomarker vs No Biomarker): $\", round(icer, 0), \" per QALY\\n\")      # Cost-effectiveness threshold interpretation   if(icer < 50000) {     cat(\"Interpretation: Highly cost-effective (< $50,000/QALY)\\n\")   } else if(icer < 100000) {     cat(\"Interpretation: Cost-effective (< $100,000/QALY)\\n\")   } else {     cat(\"Interpretation: Not cost-effective (> $100,000/QALY)\\n\")   } }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "treatment-selection-dashboard",
        "dir": "Articles",
        "previous_headings": "Clinical Decision Support",
        "what": "Treatment Selection Dashboard",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Create clinical decision support framework.",
        "code": "# Function to generate treatment recommendations generate_treatment_recommendation <- function(patient_data) {   recommendations <- list()      # Check for targetable alterations   if(patient_data$EGFR_Mutation == \"Positive\") {     recommendations$targeted <- \"EGFR TKI (osimertinib, erlotinib)\"     recommendations$evidence_level <- \"1A\"   } else if(patient_data$ALK_Fusion == \"Positive\") {     recommendations$targeted <- \"ALK inhibitor (alectinib, crizotinib)\"     recommendations$evidence_level <- \"1A\"   } else if(patient_data$HER2_FISH_Status == \"Amplified\") {     recommendations$targeted <- \"HER2-targeted therapy (trastuzumab + pertuzumab)\"     recommendations$evidence_level <- \"1A\"   } else if(patient_data$BRAF_Mutation == \"Positive\") {     recommendations$targeted <- \"BRAF inhibitor (vemurafenib + cobimetinib)\"     recommendations$evidence_level <- \"1B\"   }      # Check for immunotherapy eligibility   if(patient_data$MSI_Status == \"MSI-High\") {     recommendations$immunotherapy <- \"Anti-PD-1 monotherapy (pembrolizumab)\"     recommendations$immuno_evidence <- \"1A\"   } else if(patient_data$PD_L1_TPS >= 50) {     recommendations$immunotherapy <- \"Anti-PD-1 monotherapy (pembrolizumab)\"     recommendations$immuno_evidence <- \"1A\"   } else if(patient_data$PD_L1_TPS >= 1) {     recommendations$immunotherapy <- \"Combination immunotherapy\"     recommendations$immuno_evidence <- \"1B\"   }      # Default to chemotherapy if no actionable alterations   if(is.null(recommendations$targeted) && is.null(recommendations$immunotherapy)) {     recommendations$default <- \"Standard chemotherapy\"     recommendations$default_evidence <- \"1A\"   }      return(recommendations) }  # Example patient recommendations example_patients <- precision_oncology_data[1:5, ]  cat(\"Treatment Recommendations for Sample Patients:\\n\\n\") for(i in 1:nrow(example_patients)) {   patient <- example_patients[i, ]   recommendations <- generate_treatment_recommendation(patient)      cat(\"Patient\", patient$Patient_ID, \"(\", patient$Tumor_Type, \"):\\n\")   cat(\"Age:\", patient$Age, \", Grade:\", patient$Grade, \"\\n\")      # Print biomarker status   cat(\"Biomarkers: \")   if(patient$EGFR_Mutation == \"Positive\") cat(\"EGFR+ \")   if(patient$ALK_Fusion == \"Positive\") cat(\"ALK+ \")   if(patient$HER2_FISH_Status == \"Amplified\") cat(\"HER2+ \")   if(patient$MSI_Status == \"MSI-High\") cat(\"MSI-H \")   if(patient$PD_L1_TPS >= 50) cat(\"PD-L1 high \")   cat(\"\\n\")      # Print recommendations   if(!is.null(recommendations$targeted)) {     cat(\"Recommended:\", recommendations$targeted, \"(Evidence:\", recommendations$evidence_level, \")\\n\")   }   if(!is.null(recommendations$immunotherapy)) {     cat(\"Alternative:\", recommendations$immunotherapy, \"(Evidence:\", recommendations$immuno_evidence, \")\\n\")   }   if(!is.null(recommendations$default)) {     cat(\"Recommended:\", recommendations$default, \"(Evidence:\", recommendations$default_evidence, \")\\n\")   }      cat(\"Actual Response:\", patient$Treatment_Response, \"\\n\")   cat(\"PFS:\", patient$PFS_Months, \"months\\n\\n\") }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "biomarker-testing-quality-metrics",
        "dir": "Articles",
        "previous_headings": "Quality Assurance in Precision Oncology",
        "what": "Biomarker Testing Quality Metrics",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Monitor quality molecular testing programs.",
        "code": "# Simulate quality metrics for biomarker testing set.seed(123) quality_metrics <- precision_oncology_data %>%   mutate(     # Simulate testing quality metrics     turnaround_time = round(rnorm(n(), mean = 7, sd = 2)),     test_success_rate = sample(c(\"Success\", \"Failed\", \"Repeat\"), n(),                                prob = c(0.85, 0.05, 0.10), replace = TRUE),     reporting_clarity = sample(c(\"Clear\", \"Adequate\", \"Unclear\"), n(),                               prob = c(0.80, 0.15, 0.05), replace = TRUE)   ) %>%   group_by(Tumor_Type) %>%   summarise(     n_tests = n(),     mean_tat = round(mean(turnaround_time), 1),     success_rate = round(mean(test_success_rate == \"Success\") * 100, 1),     clear_reporting = round(mean(reporting_clarity == \"Clear\") * 100, 1),     actionable_rate = round(mean(biomarker_count > 0) * 100, 1),     .groups = 'drop'   ) %>%   arrange(desc(n_tests))  print(\"Quality Metrics by Tumor Type:\") print(quality_metrics)  # Overall quality dashboard overall_quality <- precision_oncology_data %>%   summarise(     total_patients = n(),     actionable_biomarker_rate = round(mean(biomarker_count > 0) * 100, 1),     multiple_biomarker_rate = round(mean(biomarker_count > 1) * 100, 1),     targeted_therapy_eligible = round(mean(primary_treatment != \"Standard Chemotherapy\") * 100, 1),     immunotherapy_eligible = round(mean(immunotherapy_candidate != \"Chemotherapy First\") * 100, 1)   )  cat(\"Overall Precision Oncology Quality Dashboard:\\n\") cat(\"Total patients tested:\", overall_quality$total_patients, \"\\n\") cat(\"Actionable biomarker rate:\", overall_quality$actionable_biomarker_rate, \"%\\n\") cat(\"Multiple biomarker rate:\", overall_quality$multiple_biomarker_rate, \"%\\n\") cat(\"Targeted therapy eligible:\", overall_quality$targeted_therapy_eligible, \"%\\n\") cat(\"Immunotherapy eligible:\", overall_quality$immunotherapy_eligible, \"%\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "comprehensive precision oncology analysis demonstrates complexity clinical value biomarker-guided cancer care. Key findings include: High Actionable Rate: >60% patients actionable biomarkers Improved Outcomes: Biomarker-positive patients show better response rates Cost-Effectiveness: Targeted therapy provides favorable cost-utility ratios Clinical Utility: Significant survival benefit biomarker-guided treatment Quality Assurance: Robust QC metrics ensure reliable testing",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "implementation-recommendations",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Implementation Recommendations",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Comprehensive Testing: Implement broad molecular profiling panels Rapid Turnaround: Achieve <7-day reporting treatment decisions Clinical Integration: Embed recommendations electronic health records Outcome Tracking: Monitor real-world effectiveness biomarker strategies Cost Monitoring: Evaluate economic impact adjust coverage policies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/11-precision-oncology.html",
        "id": "future-directions",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Future Directions",
        "title": "Precision Oncology: Biomarker-Guided Treatment Selection and Outcome Analysis",
        "text": "Liquid Biopsy Integration: Circulating tumor DNA monitoring Artificial Intelligence: Machine learning biomarker interpretation Real-World Evidence: Population-based outcome studies Combination Biomarkers: Multi-analyte predictive models Resistance Monitoring: Dynamic biomarker assessment treatment vignette demonstrates advanced precision oncology workflows using ClinicoPath suite. additional biomarker analysis examples, explore related vignettes ROC analysis survival analysis.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "clinical practice research, evaluating diagnostic test performance typically requires “gold standard” reference test determine true disease status. However, many situations, perfect gold standard test unavailable, expensive, invasive, unethical perform. nogoldstandard module ClinicoPath package provides methods analyzing performance multiple diagnostic tests without requiring gold standard reference. vignette demonstrates use nogoldstandard module : Estimate disease prevalence Calculate sensitivity specificity multiple tests Compute confidence intervals using bootstrap methods Visualize test agreement patterns",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "why-analyze-tests-without-a-gold-standard",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Why analyze tests without a gold standard?",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "perfect reference test exists, researchers typically face challenging options: Use imperfect reference (introducing verification bias) Employ composite reference standards (potentially arbitrary) Exclude subjects without verification (introducing selection bias) Statistical methods “gold standard” analysis offer alternative approach, allowing estimation test performance metrics using patterns agreement disagreement among multiple imperfect tests.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "methods-overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Methods Overview",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "nogoldstandard module implements five different approaches: Latent Class Analysis (LCA): Assumes disease status unobserved (latent) variable models relationship latent variable observed test results. Composite Reference: Creates reference standard considering majority result across tests “true” status. Tests Positive: Considers disease present tests positive (high specificity approach). Test Positive: Considers disease present test positive (high sensitivity approach). Bayesian Analysis: Uses prior distributions EM algorithm estimate parameters, potentially incorporating prior knowledge.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "installation",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Installation",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "nogoldstandard module part ClinicoPath package:",
        "code": "# Install from CRAN install.packages(\"ClinicoPath\")  # Or the development version # install.packages(\"devtools\") devtools::install_github(\"sbalci/ClinicoPath\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "example-data",
        "dir": "Articles",
        "previous_headings": "Basic Usage",
        "what": "Example Data",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Let’s create sample dataset 4 diagnostic tests performed 200 patients:",
        "code": "set.seed(123) n <- 200  # Number of patients  # True disease status (unknown in practice) true_status <- rbinom(n, 1, 0.3)  # 30% prevalence  # Create 4 imperfect tests with different sensitivity/specificity test1 <- ifelse(true_status == 1,                  rbinom(n, 1, 0.90),  # 90% sensitivity                 rbinom(n, 1, 0.10))  # 90% specificity  test2 <- ifelse(true_status == 1,                  rbinom(n, 1, 0.75),  # 75% sensitivity                 rbinom(n, 1, 0.05))  # 95% specificity  test3 <- ifelse(true_status == 1,                  rbinom(n, 1, 0.85),  # 85% sensitivity                 rbinom(n, 1, 0.15))  # 85% specificity  test4 <- ifelse(true_status == 1,                  rbinom(n, 1, 0.70),  # 70% sensitivity                 rbinom(n, 1, 0.05))  # 95% specificity  # Convert to categorical format test1 <- factor(ifelse(test1 == 1, \"pos\", \"neg\")) test2 <- factor(ifelse(test2 == 1, \"pos\", \"neg\")) test3 <- factor(ifelse(test3 == 1, \"pos\", \"neg\")) test4 <- factor(ifelse(test4 == 1, \"pos\", \"neg\"))  # Create data frame data <- data.frame(   caseID = 1:n,   test1 = test1,   test2 = test2,   test3 = test3,   test4 = test4 )  # View the first few rows head(data)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "running-the-analysis",
        "dir": "Articles",
        "previous_headings": "Basic Usage",
        "what": "Running the Analysis",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Now let’s analyze data using Latent Class Analysis method: result contain: Estimated disease prevalence Sensitivity specificity test Test agreement matrix visualization",
        "code": "library(meddecide)  result <- nogoldstandard(   data = data,   test1 = \"test1\",   test1Positive = \"pos\",   test2 = \"test2\",   test2Positive = \"pos\",   test3 = \"test3\",   test3Positive = \"pos\",   test4 = \"test4\",   test4Positive = \"pos\",   test5 = NULL,   method = \"latent_class\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "bootstrap-confidence-intervals",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Bootstrap Confidence Intervals",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "One key features nogoldstandard module ability compute confidence intervals using bootstrap resampling. provides measure uncertainty around estimated parameters.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "understanding-bootstrap-in-nogoldstandard-analysis",
        "dir": "Articles",
        "previous_headings": "Bootstrap Confidence Intervals",
        "what": "Understanding Bootstrap in NoGoldStandard Analysis",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Bootstrap resampling involves: Randomly selecting observations original dataset replacement Running selected analysis method resampled dataset Computing parameter interest (prevalence, sensitivity, specificity) Repeating steps 1-3 many times build distribution Using distribution calculate confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "enabling-bootstrap-with-progress-reporting",
        "dir": "Articles",
        "previous_headings": "Bootstrap Confidence Intervals",
        "what": "Enabling Bootstrap with Progress Reporting",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "enhanced version nogoldstandard module includes detailed progress reporting bootstrap analysis: running analysis, ’ll see progress updates console:",
        "code": "result_with_ci <- nogoldstandard(   data = data,   test1 = \"test1\",   test1Positive = \"pos\",   test2 = \"test2\",   test2Positive = \"pos\",   test3 = \"test3\",   test3Positive = \"pos\",   test4 = \"test4\",   test4Positive = \"pos\",   method = \"latent_class\",   bootstrap = TRUE,     # Enable bootstrap   nboot = 1000,         # Number of bootstrap samples   alpha = 0.05          # For 95% confidence intervals ) === Bootstrap Analysis === Starting bootstrap with 1000 iterations for latent_class method Estimating confidence intervals for prevalence    50/1000 (5.0%) - 50 successful, 0 errors - 12.3 sec elapsed, ~234.7 sec remaining   100/1000 (10.0%) - 100 successful, 0 errors - 24.8 sec elapsed, ~223.2 sec remaining   ...   950/1000 (95.0%) - 942 successful, 8 errors - 236.5 sec elapsed, ~12.5 sec remaining   1000/1000 (100.0%) - 991 successful, 9 errors - 249.3 sec elapsed, ~0.0 sec remaining  === Bootstrap Complete === Total time: 249.3 seconds (4.01 iterations/sec) Successful iterations: 991 (99.1%) Failed iterations: 9 (0.9%) Confidence interval (95.0%): [0.2145, 0.2987]"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "expected-duration-for-bootstrap-analysis",
        "dir": "Articles",
        "previous_headings": "Bootstrap Confidence Intervals",
        "what": "Expected Duration for Bootstrap Analysis",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "time required bootstrap analysis depends several factors: analysis method also affects duration: - Latent Class Analysis: Slowest (multiple model fitting attempts) - Bayesian Analysis: Moderate (iterative EM algorithm) - Composite//Test: Fastest (simple calculations)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "recommended-bootstrap-iterations",
        "dir": "Articles",
        "previous_headings": "Bootstrap Confidence Intervals",
        "what": "Recommended Bootstrap Iterations",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Quick Exploration: 100-500 bootstrap samples Publication-Quality Results: 1,000-2,000 bootstrap samples Critical Applications: 5,000-10,000 bootstrap samples",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "comparing-different-methods",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Comparing Different Methods",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Let’s compare results different analysis methods: Different methods may produce different estimates. general: Latent Class Analysis: Often considered theoretically sound requires assumptions conditional independence Composite Reference: Practical can biased toward majority Tests Positive: Conservative approach (low prevalence, high test specificity) Test Positive: Liberal approach (high prevalence, high test sensitivity) Bayesian Analysis: Flexible can incorporate prior knowledge, requires careful prior specification",
        "code": "# Run analysis with each method methods <- c(\"latent_class\", \"composite\", \"all_positive\", \"any_positive\", \"bayesian\") results <- list()  for (method in methods) {   results[[method]] <- nogoldstandard(     data = data,     test1 = \"test1\",     test1Positive = \"pos\",     test2 = \"test2\",     test2Positive = \"pos\",     test3 = \"test3\",     test3Positive = \"pos\",     test4 = \"test4\",     test4Positive = \"pos\",     method = method   ) }  # Extract prevalence estimates prevalence_estimates <- sapply(results, function(x) {   x$prevalence$asDF()$estimate[1] }) print(prevalence_estimates)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "disease-prevalence",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Disease Prevalence",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "estimated prevalence represents proportion population expected disease. Different methods yield different prevalence estimates: Tests Positive: Typically produces lowest prevalence estimate Test Positive: Typically produces highest prevalence estimate Latent Class Analysis: Usually produces intermediate estimate",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "test-performance",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Test Performance",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "test, module estimates: Sensitivity: probability positive test result patients disease Specificity: probability negative test result patients without disease Sensitivity specificity can used : Compare test performance Inform test selection decisions Design optimal testing strategies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "agreement-plot",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Agreement Plot",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "test agreement plot shows proportion agreement pair tests. visualization helps identify: Tests frequently agree/disagree Potential conditional dependence tests Clusters similar tests",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "handling-missing-data",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Handling Missing Data",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "nogoldstandard module can handle missing test results. enhanced implementation: Skips missing values calculating agreement Uses available data test estimating parameters Properly accounts missing data bootstrap resampling",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "bayesian-analysis-with-prior-information",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Bayesian Analysis with Prior Information",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "prior knowledge disease prevalence test characteristics, Bayesian method can incorporate information:",
        "code": "# Example of Bayesian analysis with informative priors would be shown here # This feature would require customization of the Bayesian method code"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "conditional-dependence",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Conditional Dependence",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "default Latent Class Analysis assumes conditional independence tests given true disease status. assumption violated, results may biased. Extensions handle conditional dependence : Including direct test--test associations model Using two latent classes Applying hierarchical latent class models",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "method-selection",
        "dir": "Articles",
        "previous_headings": "Recommendations for Practice",
        "what": "Method Selection",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Start Latent Class Analysis primary method Compare composite methods check robustness Consider Bayesian analysis prior information available Report results multiple methods transparency",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "bootstrap-settings",
        "dir": "Articles",
        "previous_headings": "Recommendations for Practice",
        "what": "Bootstrap Settings",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Use least 1,000 bootstrap iterations published results time-consuming methods (LCA), start 100 iterations check feasibility Monitor progress enhanced bootstrap implementation Report point estimates confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "validation",
        "dir": "Articles",
        "previous_headings": "Recommendations for Practice",
        "what": "Validation",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "possible, validate results : External validation data Follow-studies Alternative gold standard tests subset patients Results literature clinical expertise",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "the-enhanced-bootstrap-function",
        "dir": "Articles",
        "previous_headings": "Technical Implementation",
        "what": "The Enhanced Bootstrap Function",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "implementation bootstrap function progress reporting:",
        "code": ".calculateBootstrapCI = function(data, method, nboot, alpha, type, test_index = NULL) {     # Simple bootstrap implementation with progress indicators     n <- nrow(data)     boot_results <- numeric(nboot)          # Show starting message     message(\"\\n=== Bootstrap Analysis ===\")     message(sprintf(\"Starting bootstrap with %d iterations for %s method\", nboot, method))     message(sprintf(\"Estimating confidence intervals for %s\", type))     if (!is.null(test_index)) {         message(sprintf(\"Test index: %d\", test_index))     }          # Progress tracking variables     start_time <- Sys.time()     last_update <- start_time     update_interval <- max(1, floor(nboot / 20))  # Update ~20 times during process     success_count <- 0     error_count <- 0          for (b in 1:nboot) {         # Resample data         boot_indices <- sample(n, n, replace = TRUE)         boot_data <- data[boot_indices, ]                  # Run analysis on bootstrap sample         boot_result <- NULL         tryCatch({             if (method == \"latent_class\") {                 boot_result <- private$.runLCA(boot_data, names(data), NULL)             } else if (method == \"composite\") {                 boot_result <- private$.runComposite(boot_data)             } else if (method == \"all_positive\") {                 boot_result <- private$.runAllPositive(boot_data)             } else if (method == \"any_positive\") {                 boot_result <- private$.runAnyPositive(boot_data)             } else if (method == \"bayesian\") {                 boot_result <- private$.runBayesian(boot_data)             }             success_count <- success_count + 1         }, error = function(e) {             # Count errors but continue bootstrap             error_count <- error_count + 1         })                  # Extract relevant statistic         if (!is.null(boot_result)) {             if (type == \"prevalence\") {                 boot_results[b] <- boot_result$prevalence             } else if (type == \"sensitivity\" && !is.null(test_index)) {                 boot_results[b] <- boot_result$sensitivities[test_index]             } else if (type == \"specificity\" && !is.null(test_index)) {                 boot_results[b] <- boot_result$specificities[test_index]             }         } else {             boot_results[b] <- NA         }                  # Show progress updates         current_time <- Sys.time()         if (b %% update_interval == 0 || b == nboot ||              as.numeric(difftime(current_time, last_update, units = \"secs\")) > 10) {             elapsed <- as.numeric(difftime(current_time, start_time, units = \"secs\"))             percent_done <- b / nboot * 100             est_total <- elapsed / percent_done * 100             est_remaining <- est_total - elapsed                          message(sprintf(\"  %d/%d (%.1f%%) - %d successful, %d errors - %.1f sec elapsed, ~%.1f sec remaining\",                            b, nboot, percent_done, success_count, error_count,                           elapsed, est_remaining))                          last_update <- current_time         }     }          # Show final statistics     total_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))     message(\"\\n=== Bootstrap Complete ===\")     message(sprintf(\"Total time: %.1f seconds (%.2f iterations/sec)\",                    total_time, nboot/total_time))     message(sprintf(\"Successful iterations: %d (%.1f%%)\",                    success_count, success_count/nboot*100))     message(sprintf(\"Failed iterations: %d (%.1f%%)\",                    error_count, error_count/nboot*100))          # Calculate percentile CI     boot_results <- boot_results[!is.na(boot_results)]          if (length(boot_results) > 0) {         ci <- quantile(boot_results, c(alpha/2, 1-alpha/2), na.rm=TRUE)         message(sprintf(\"Confidence interval (%.1f%%): [%.4f, %.4f]\",                        (1-alpha)*100, ci[1], ci[2]))         return(list(lower = ci[1], upper = ci[2]))     } else {         message(\"WARNING: No valid bootstrap results obtained. Returning NA.\")         return(list(lower = NA, upper = NA))     } }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "references",
        "dir": "Articles",
        "previous_headings": "",
        "what": "References",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "Hui SL, Walter SD. Estimating error rates diagnostic tests. Biometrics. 1980;36(1):167-171. Joseph L, Gyorkos TW, Coupal L. Bayesian estimation disease prevalence parameters diagnostic tests absence gold standard. J Epidemiol. 1995;141(3):263-272. Albert PS, Dodd LE. cautionary note robustness latent class models estimating diagnostic error without gold standard. Biometrics. 2004;60(2):427-435. Collins J, Huynh M. Estimation diagnostic test accuracy without full verification: review latent class methods. Stat Med. 2014;33(24):4141-4169. Dendukuri N, Joseph L. Bayesian approaches modeling conditional dependence multiple diagnostic tests. Biometrics. 2001;57(1):158-167.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/12-nogoldstandard.html",
        "id": "session-information",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Session Information",
        "title": "Analyzing Diagnostic Tests without a Gold Standard",
        "text": "",
        "code": "sessionInfo()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/13-diagnostic-tests.html",
        "id": "example-data",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Example Data",
        "title": "Diagnostic Test Evaluation",
        "text": "Small example datasets included package. can load using system.file() read.csv().",
        "code": "df_dec <- read.csv(system.file(\"extdata\", \"decision_example.csv\", package = \"meddecide\")) head(df_dec)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/13-diagnostic-tests.html",
        "id": "calculating-diagnostic-metrics",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Calculating Diagnostic Metrics",
        "title": "Diagnostic Test Evaluation",
        "text": "decision() function computes sensitivity, specificity related metrics raw test results. four counts (true positives, false positives, true negatives false negatives) can use decisioncalculator() directly. option fagan = TRUE adds Fagan nomogram illustrate pre-test probability updated diagnostic result. tools help summarise diagnostic performance can combined functions meddecide advanced analysis.",
        "code": "res <- decision(data = df_dec,                 gold = df_dec$gold,                 goldPositive = 1,                 newtest = df_dec$newtest,                 testPositive = 1,                 ci = TRUE) res$ratioTable calc <- decisioncalculator(TP = 90, FN = 10, TN = 80, FP = 20,                            ci = TRUE, fagan = TRUE) calc$ratioTable calc$fagan"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-1-prepare-your-data",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 1: Prepare Your Data",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Required columns: - Rater columns: pathologist’s diagnoses (e.g., Path_01, Path_02, etc.) - Case ID: Unique identifier case Optional columns: - Experience: Years experience level (Junior/Senior) - Training: Training institution - Institution: Current practice location - Specialty: Subspecialty focus - True diagnosis: Gold standard (accuracy analysis)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-2-load-data-in-jamovi",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 2: Load Data in jamovi",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Open jamovi Import CSV file Ensure rater columns set Factor (nominal/ordinal)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-3-run-basic-analysis",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 3: Run Basic Analysis",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Go meddecide → Agreement → Interrater Reliability Move rater columns Raters/Observers box Click Run ✅ Check: Overall agreement 40-90% meaningful style analysis",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-4-enable-diagnostic-style-clustering",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 4: Enable Diagnostic Style Clustering",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Check ✓ Diagnostic Style Clustering (Usubutun Method) Method: Ward’s Linkage Distance: Percentage Agreement Groups: 3 ✅ Expected: See Style Groups (1, 2, 3) assigned pathologist",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-5-add-pathologist-characteristics",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 5: Add Pathologist Characteristics",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Check ✓ Include Rater Characteristics Experience Variable → experience column Training Institution → training column Current Institution → institution column Specialty → specialty column ✅ Expected: Style groups correlate characteristics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "step-6-identify-problem-cases",
        "dir": "Articles",
        "previous_headings": "🚀 Quick Start: 5-Minute Diagnostic Style Analysis",
        "what": "Step 6: Identify Problem Cases",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Check ✓ Identify Discordant Cases ✅ Expected: List cases causing style-based disagreement",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "diagnostic-style-table",
        "dir": "Articles",
        "previous_headings": "📊 Interpreting Results",
        "what": "Diagnostic Style Table",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "🔍 look : - High within-group agreement (>80%): Strong style membership - Similar characteristics within groups: Validates clustering - Clear separation groups: Distinct diagnostic approaches",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "style-summary-table",
        "dir": "Articles",
        "previous_headings": "📊 Interpreting Results",
        "what": "Style Summary Table",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "🔍 Interpretation: - Style 1: Conservative academics - Style 2: Moderate community pathologists - Style 3: Aggressive specialists",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "discordant-cases",
        "dir": "Articles",
        "previous_headings": "📊 Interpreting Results",
        "what": "Discordant Cases",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "🔍 Meaning: - High discord (>0.7): Cases revealing diagnostic philosophy differences - Pattern: Conservative vs. aggressive diagnostic tendencies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "quality-assurance",
        "dir": "Articles",
        "previous_headings": "🎯 Common Applications",
        "what": "Quality Assurance",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Goal: Identify diagnostic outliers Setup: - Include department pathologists - Use routine sign-cases - Focus challenging diagnoses Action Items: - Pathologists unusual styles → additional training - Cases high discord → consensus review - Style patterns → standardized protocols",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "training-evaluation",
        "dir": "Articles",
        "previous_headings": "🎯 Common Applications",
        "what": "Training Evaluation",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Goal: Assess resident diagnostic development Setup: - Compare residents vs. attendings - Track individual residents time - Include mentor information Action Items: - Residents clustering wrong style → mentor reassignment - Persistent style differences → targeted education - Mentor influence patterns → faculty development",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "consensus-development",
        "dir": "Articles",
        "previous_headings": "🎯 Common Applications",
        "what": "Consensus Development",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Goal: Improve diagnostic guidelines Setup: - Select expert panel representing different styles - Include cases showing style disagreements - Document reasoning style differences Action Items: - Style-specific guidelines → comprehensive protocols - High-discord cases → educational materials - Expert disagreements → research priorities",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "distance-metrics",
        "dir": "Articles",
        "previous_headings": "⚙️ Advanced Settings",
        "what": "Distance Metrics",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Percentage Agreement (Default) - ✅ Use : categorical diagnoses - 📊 Measures: Direct diagnostic concordance Correlation - ✅ Use : Ordinal scales (grades, stages) - 📊 Measures: Linear relationship patterns Euclidean - ✅ Use : Quantitative scores - 📊 Measures: Geometric distance",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "clustering-methods",
        "dir": "Articles",
        "previous_headings": "⚙️ Advanced Settings",
        "what": "Clustering Methods",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Ward’s Linkage (Default) - ✅ Use : Compact, similar-sized groups - 🎯 Creates: Tight, meaningful clusters Complete Linkage - ✅ Use : Well-separated distinct groups - 🎯 Creates: tight clusters Average Linkage - ✅ Use : Moderate separation - 🎯 Creates: Balanced clusters",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "number-of-groups",
        "dir": "Articles",
        "previous_headings": "⚙️ Advanced Settings",
        "what": "Number of Groups",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "2 Groups: Conservative vs. Aggressive 3 Groups: Conservative, Moderate, Aggressive (Usubutun standard) 4+ Groups: Subspecialty-specific approaches",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "problem-all-pathologists-in-one-group",
        "dir": "Articles",
        "previous_headings": "🔧 Troubleshooting",
        "what": "Problem: All pathologists in one group",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Causes: - pathologists (<6) - high agreement - Cases easy/difficult Solutions: - Add pathologists - Include challenging cases - Reduce groups 2",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "problem-groups-dont-match-characteristics",
        "dir": "Articles",
        "previous_headings": "🔧 Troubleshooting",
        "what": "Problem: Groups don’t match characteristics",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Causes: - Characteristics don’t influence style - Small sample size - Hidden confounders Solutions: - Add characteristic variables - Increase case numbers - Consider interaction effects",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "problem-poor-within-group-agreement",
        "dir": "Articles",
        "previous_headings": "🔧 Troubleshooting",
        "what": "Problem: Poor within-group agreement",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Causes: - Wrong number groups - High random error - Inappropriate cases Solutions: - Adjust group number - Focus moderate difficulty cases - Exclude technical failures",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "test-datasets",
        "dir": "Articles",
        "previous_headings": "",
        "what": "📚 Test Datasets",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "ClinicoPath includes three test datasets:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "endometrial-pathology",
        "dir": "Articles",
        "previous_headings": "📚 Test Datasets",
        "what": "Endometrial Pathology",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "File: endometrial_diagnostic_styles.csv Cases: 80 endometrial biopsies Pathologists: 15 (various backgrounds) Categories: Benign, EIN, Carcinoma Expected Styles: 3 groups correlating training",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "breast-pathology",
        "dir": "Articles",
        "previous_headings": "📚 Test Datasets",
        "what": "Breast Pathology",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "File: breast_diagnostic_styles.csv Cases: 60 breast biopsies Pathologists: 12 (breast specialists vs. generalists) Categories: Benign, Atypical, DCIS, Invasive Expected Styles: Conservative, Moderate, Aggressive",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "lymphoma-classification",
        "dir": "Articles",
        "previous_headings": "📚 Test Datasets",
        "what": "Lymphoma Classification",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "File: lymphoma_diagnostic_styles.csv Cases: 45 lymphoid lesions Pathologists: 10 hematopathologists Categories: Reactive, DLBCL, Follicular, Marginal Zone, Mantle Cell Expected Styles: -strict, Molecular-heavy, Morphology-first",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "primary-diagnostic-style-literature",
        "dir": "Articles",
        "previous_headings": "📖 Key References",
        "what": "Primary Diagnostic Style Literature",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Usubutun , Mutter GL, Saglam , Dolgun , Ozkan EA, Ince T, Akyol , Bulbul HD, Calay Z, Eren F, Gumurdulu D, Haberal , Ilvan S, Karaveli S, Koyuncuoglu M, Muezzinoglu B, Muftuoglu KH, Ozdemir N, Ozen O, Baykara S, Pestereli E, Ulukus EC, Zekioglu O. (2012). Reproducibility endometrial intraepithelial neoplasia diagnosis good, influenced diagnostic style pathologists. Modern Pathology, 25(6), 877-884. doi: 10.1038/modpathol.2011.220. PMID: 22301705. Elmore JG, et al. (2015). Diagnostic concordance among pathologists interpreting breast biopsy specimens. JAMA, 313(11), 1122-1132.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/14-diagnostic-style-quick-guide.html",
        "id": "ihc-clustering-methods-related-to-ihcstats-function",
        "dir": "Articles",
        "previous_headings": "📖 Key References",
        "what": "IHC Clustering Methods (Related to ihcstats function)",
        "title": "Quick Guide: Diagnostic Style Clustering in jamovi",
        "text": "Sterlacci W, Fiegl M, Juskevicius D, Tzankov . (2020). Cluster Analysis According Immunohistochemistry Robust Tool Non-Small Cell Lung Cancer Reveals Distinct, Immune Signature-defined Subgroup. Applied Immunohistochemistry & Molecular Morphology, 28(4), 274-283. PMID: 31058655. Olsen SH, Thomas DG, Lucas DR. (2006). Cluster analysis immunohistochemical profiles synovial sarcoma, malignant peripheral nerve sheath tumor, Ewing sarcoma. Modern Pathology, 19(5), 659-668. PMID: 16528378. Matsuoka T, Mitomi H, Fukui N, Kanazawa H, Saito T, Hayashi T, Yao T. (2011). Cluster analysis claudin-1 -4, E-cadherin, β-catenin expression colorectal cancers. Journal Surgical Oncology, 103(7), 674-686. PMID: 21360533. Carvalho JC, Wasco MJ, Kunju LP, Thomas DG, Shah RB. (2011). Cluster analysis immunohistochemical profiles delineates CK7, vimentin, S100A1 C-kit (CD117) optimal panel differential diagnosis renal oncocytoma mimics. Histopathology, 58(2), 169-179. PMID: 21323945. 💡 Tip: Start test datasets learn interface, apply data. diagnostic style clustering reveals hidden patterns pathologist decision-making traditional agreement statistics miss.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Diagnostic Style Clustering feature ClinicoPath implements methodology Usubutun et al. (2012) identify diagnostic “schools” “styles” among pathologists. powerful analysis reveals whether pathologists cluster based : Training institution (e.g., different medical schools create distinct diagnostic approaches) Experience level (junior vs. senior pathologists) Geographic region (regional diagnostic preferences) Specialty focus (generalist vs. specialist approaches) Institutional culture (academic vs. community practice patterns)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "clinical-significance",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Clinical Significance",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Understanding diagnostic styles crucial : Quality Assurance: Identifying systematic biases diagnostic patterns Training Programs: Recognizing influence different educational approaches Consensus Development: Understanding certain cases generate disagreement Standardization Efforts: Targeting training reduce style-based variation Case Consultation: Selecting appropriate experts based diagnostic philosophy",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "the-usubutun-2012-study",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "The Usubutun 2012 Study",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "original study analyzed endometrial intraepithelial neoplasia (EIN) diagnoses among 20 pathologists found three distinct diagnostic styles correlated training background diagnostic philosophy. methodology adapted various pathology subspecialties.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "data-requirements",
        "dir": "Articles",
        "previous_headings": "Getting Started",
        "what": "Data Requirements",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "dataset contain: Required: - Multiple rater columns: column represents one pathologist’s diagnoses - Case identifiers: Unique identifier case Optional Recommended: - Pathologist characteristics: Experience, training institution, current institution, specialty - True diagnoses: Gold standard accuracy assessment - Case features: Difficulty level, confounding factors",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "dataset-1-endometrial-pathology-classic-usubutun-study",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough",
        "what": "Dataset 1: Endometrial Pathology (Classic Usubutun Study)",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Let’s demonstrate analysis using synthetic data modeled original study.",
        "code": "# Load the endometrial diagnostic styles dataset library(meddecide) data(\"endometrial_diagnostic_styles\")  # View structure head(endometrial_diagnostic_styles$diagnosis_data) head(endometrial_diagnostic_styles$pathologist_info)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "step-1-basic-agreement-analysis",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 1: Endometrial Pathology (Classic Usubutun Study)",
        "what": "Step 1: Basic Agreement Analysis",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Start standard interrater reliability: jamovi Instructions: 1. Open endometrial_diagnostic_styles.csv file 2. Go meddecide → Agreement → Interrater Reliability 3. Select pathologist columns (Path_01 Path_15) Raters/Observers 4. Check Show Interpretation Guidelines 5. Check Pairwise Rater Analysis Expected Results: - Overall agreement: ~65-75% - Fleiss’ Kappa: 0.60-0.72 (substantial agreement) - Individual pathologist accuracies vary experience",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "step-2-enable-diagnostic-style-clustering",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 1: Endometrial Pathology (Classic Usubutun Study)",
        "what": "Step 2: Enable Diagnostic Style Clustering",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Enable core diagnostic style analysis: jamovi Instructions: 1. Check Diagnostic Style Clustering (Usubutun Method) 2. Set clustering parameters: - Style Clustering Method: Ward’s Linkage (default) - Style Distance Metric: Percentage Agreement (default) - Number Style Groups: 3 (found original study) Expected Results: - 3 distinct diagnostic styles identified - Style 1: Conservative (tend undercall EIN) - Style 2: Moderate (balanced approach) - Style 3: Aggressive (likely diagnose EIN)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "step-3-include-rater-characteristics",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 1: Endometrial Pathology (Classic Usubutun Study)",
        "what": "Step 3: Include Rater Characteristics",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Add pathologist background information: jamovi Instructions: 1. Check Include Rater Characteristics 2. Select characteristic variables: - Experience Variable: experience_level - Training Institution Variable: training_institution - Current Institution Variable: current_institution - Specialty Variable: specialty_focus Expected Results: - Style 1 (Conservative): Predominantly community pathologists, general practice - Style 2 (Moderate): Mix academic community, mid-level experience - Style 3 (Aggressive): Academic specialists, gynecologic pathology focus",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "step-4-identify-discordant-cases",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 1: Endometrial Pathology (Classic Usubutun Study)",
        "what": "Step 4: Identify Discordant Cases",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Find cases distinguish diagnostic styles: jamovi Instructions: 1. Check Identify Discordant Cases Expected Results: - Cases polyps show high inter-style disagreement - Hormonal effect cases distinguish conservative vs. aggressive styles - Poor quality preparations increase random disagreement",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "dataset-2-breast-pathology-diagnostic-styles",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough",
        "what": "Dataset 2: Breast Pathology Diagnostic Styles",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Breast pathology offers distinct diagnostic philosophies around atypia DCIS.",
        "code": "# Load breast diagnostic data data(\"breast_diagnostic_styles\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "key-features",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 2: Breast Pathology Diagnostic Styles",
        "what": "Key Features:",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "4 diagnostic categories: Benign, Atypical, DCIS, Invasive 12 pathologists different training backgrounds Diagnostic philosophies: Conservative, Moderate, Aggressive",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "expected-style-groups",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 2: Breast Pathology Diagnostic Styles",
        "what": "Expected Style Groups:",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Style 1 - Conservative Breast Pathologists: - Tend undercall atypical lesions - Require evidence DCIS diagnosis - Often community-based generalists Style 2 - Moderate Breast Pathologists: - Balanced diagnostic approach - Follow standard guidelines closely - Mix academic community practice Style 3 - Aggressive Breast Pathologists: - liberal atypia diagnosis - Lower threshold DCIS - Often specialist breast pathologists",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "analysis-setup",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 2: Breast Pathology Diagnostic Styles",
        "what": "Analysis Setup:",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "jamovi Instructions: 1. Load breast_diagnostic_styles.csv 2. Select BreastPath_01 BreastPath_12 raters 3. Use true_diagnosis gold standard (optional) 4. Enable diagnostic style clustering 3 groups 5. Include specialty_focus diagnostic_philosophy characteristics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "dataset-3-lymphoma-classification-styles",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough",
        "what": "Dataset 3: Lymphoma Classification Styles",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Hematopathology demonstrates classification approach differences.",
        "code": "# Load lymphoma diagnostic data   data(\"lymphoma_diagnostic_styles\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "key-features-1",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 3: Lymphoma Classification Styles",
        "what": "Key Features:",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "5 diagnostic categories: Reactive, DLBCL, Follicular, Marginal Zone, Mantle Cell 10 hematopathologists different classification approaches Methodological styles: -strict, Molecular-heavy, Morphology-first",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "expected-style-groups-1",
        "dir": "Articles",
        "previous_headings": "Analysis Walkthrough > Dataset 3: Lymphoma Classification Styles",
        "what": "Expected Style Groups:",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Style 1 - Traditional Morphologists: - Heavy reliance histologic features - Conservative molecular classifications - Prefer established diagnostic categories Style 2 - Molecular-Integrated Pathologists: - Emphasize molecular genetic findings - comfortable newer categories - Research-oriented institutions Style 3 - Clinical-Context Pathologists: - Consider clinical presentation heavily - Pragmatic diagnostic approach - Often community-based practice",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "diagnostic-style-table",
        "dir": "Articles",
        "previous_headings": "Understanding the Results",
        "what": "Diagnostic Style Table",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "table shows pathologist’s assigned style group: Interpretation: - Within-Group Agreement: well pathologist agrees others style group - High values (>80%): Strong style group membership - Low values (<70%): May transitional styles",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "style-summary-table",
        "dir": "Articles",
        "previous_headings": "Understanding the Results",
        "what": "Style Summary Table",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Overview diagnostic style group: Interpretation: - Style 1: Conservative senior academics - Style 2: Mixed transitional group - Style 3: Aggressive community-trained pathologists",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "discordant-cases-table",
        "dir": "Articles",
        "previous_headings": "Understanding the Results",
        "what": "Discordant Cases Table",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Cases distinguish different style groups: Interpretation: - High discord scores (>0.7): Cases reveal diagnostic philosophy differences - Pattern analysis: Shows systematic biases style groups",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "dendrogram-plot",
        "dir": "Articles",
        "previous_headings": "Visualization Guide",
        "what": "Dendrogram Plot",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Diagnostic Style Dendrogram shows hierarchical clustering pathologists: Key Features: - Branch height: Distance pathologists/groups - Groupings: Clear separation indicates distinct styles - Outliers: Pathologists don’t fit cleanly groups Interpretation: - Short branches within groups: High similarity within diagnostic styles - Long branches groups: Clear separation diagnostic approaches - Branch order: Pathologists cluster diagnostic similarity, alphabetically",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "style-heatmap",
        "dir": "Articles",
        "previous_headings": "Visualization Guide",
        "what": "Style Heatmap",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Diagnostic Style Heatmap visualizes diagnostic patterns: Key Features: - Rows: Pathologists (grouped style) - Columns: Diagnostic categories - Colors: Frequency diagnosis (blue=low, red=high) - Patterns: Style groups show similar color patterns Interpretation: - Conservative styles: blue aggressive categories (EIN, Carcinoma) - Aggressive styles: red higher-grade categories - Consistent patterns within groups: Confirms style group validity",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "quality-assurance-programs",
        "dir": "Articles",
        "previous_headings": "Clinical Applications",
        "what": "Quality Assurance Programs",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Use Case: Medical center wants identify diagnostic outliers Analysis Approach: 1. Collect routine sign-diagnoses pathologists 2. Run diagnostic style clustering analysis 3. Identify pathologists unusual diagnostic patterns 4. Implement targeted training consultation protocols Expected Outcome: - Detection systematic /-diagnosis - Identification pathologists needing additional training - Development case consultation guidelines",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "training-program-evaluation",
        "dir": "Articles",
        "previous_headings": "Clinical Applications",
        "what": "Training Program Evaluation",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Use Case: Residency program assesses training effectiveness Analysis Approach: 1. Compare diagnostic styles residents vs. attendings 2. Track style evolution throughout residency training 3. Identify influence different faculty mentors 4. Assess correlation board exam performance Expected Outcome: - Documentation training program influence diagnostic approach - Identification mentor-specific diagnostic “signatures” - Curriculum modifications address style biases",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "consensus-conference-planning",
        "dir": "Articles",
        "previous_headings": "Clinical Applications",
        "what": "Consensus Conference Planning",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Use Case: Professional society planning consensus guidelines Analysis Approach: 1. Identify expert pathologists representing different diagnostic styles 2. Select cases demonstrate style-specific disagreements 3. Focus consensus discussion style-distinguishing features 4. Develop guidelines address common style biases Expected Outcome: - effective consensus development - Guidelines address real-world diagnostic variation - Reduced inter-pathologist disagreement",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "custom-distance-metrics",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Custom Distance Metrics",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Choose distance metric based analysis goals: Percentage Agreement (Default): - Best : Categorical diagnoses equal weight - Interpretation: Direct measure diagnostic concordance - Use : Standard agreement analysis Correlation: - Best : Ordinal diagnoses grade/stage relationships - Interpretation: Measures linear diagnostic relationship - Use : Severity/grade assessments Euclidean: - Best : Quantitative diagnostic scores - Interpretation: Geometric distance diagnostic space - Use : Continuous diagnostic measurements",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "clustering-methods",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Clustering Methods",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Select clustering approach based group structure: Ward’s Linkage (Default - Usubutun Method): - Best : Compact, similar-sized groups - Advantage: Minimizes within-group variance - Use : Following original Usubutun methodology Complete Linkage: - Best : Distinct, well-separated groups - Advantage: Creates tight clusters - Use : Clear diagnostic “schools” expected Average Linkage: - Best : Moderate cluster separation - Advantage: Balanced approach - Use : Uncertain group structure",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "optimal-group-number",
        "dir": "Articles",
        "previous_headings": "Advanced Features",
        "what": "Optimal Group Number",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Determining right number style groups: Clinical Guidance: - 2 groups: Conservative vs. Aggressive - 3 groups: Conservative, Moderate, Aggressive (Usubutun finding) - 4+ groups: Subspecialty-specific approaches Statistical Methods: - Dendrogram inspection: Look natural breakpoints - Within-group agreement: Higher values indicate good grouping - Clinical interpretability: Groups make clinical sense",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "issue-all-pathologists-assigned-to-one-style-group",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue: All pathologists assigned to one style group",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Likely Causes: - pathologists (need minimum 6-8) - high agreement (limited style variation) - Inappropriate distance metric Solutions: - Increase number raters - Use challenging cases - Try correlation distance metric - Reduce number style groups 2",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "issue-style-groups-dont-correlate-with-characteristics",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue: Style groups don’t correlate with characteristics",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Likely Causes: - Characteristics don’t actually influence diagnostic style - Sample size small - Confounding variables present Solutions: - Collect additional characteristic variables - Increase case numbers - Focus cases known diagnostic challenges - Consider interaction characteristics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "issue-poor-within-group-agreement",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue: Poor within-group agreement",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Likely Causes: - Inappropriate number style groups - High random diagnostic error - Case mix suitable style analysis Solutions: - Adjust number style groups - Focus cases moderate diagnostic difficulty - Exclude cases technical problems - Use expert consensus gold standard",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "issue-no-discordant-cases-identified",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue: No discordant cases identified",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Likely Causes: - Style groups similar - Cases easy/difficult - Limited diagnostic options Solutions: - Include cases across difficulty spectrum - Ensure adequate sample borderline cases - Use cases known generate disagreement - Lower discordant case threshold",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "study-design-recommendations",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Study Design Recommendations",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Pathologist Selection: - Include range experience levels (junior senior) - Represent different training institutions - Mix practice settings (academic, community, specialty) - Minimum 8-10 pathologists meaningful clustering Case Selection: - Include diagnostic spectrum (benign malignant) - Focus challenging/borderline cases - Avoid cases obvious technical problems - Include 50-100 cases robust analysis - Balance case difficulty levels Data Collection: - Standardize case presentation format - Blind pathologists clinical information (appropriate) - Collect diagnoses independently - Document pathologist characteristics comprehensively",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "analysis-strategy",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Analysis Strategy",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Initial Analysis: 1. Start basic agreement analysis 2. Examine overall diagnostic accuracy 3. Identify obvious outliers problems Style Clustering: 1. Begin 3 groups (Usubutun standard) 2. Use Ward’s linkage percentage agreement 3. Examine dendrogram natural groupings 4. Validate groups characteristic analysis Interpretation: 1. Focus clinically meaningful patterns 2. Consider alternative explanations clustering 3. Validate findings additional cases 4. Discuss results participating pathologists",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "reporting-results",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "Reporting Results",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Essential Elements: - Clear description pathologist characteristics - Justification number style groups - Validation style groups known characteristics - Clinical interpretation style differences - Limitations alternative explanations Visualization: - Include dendrogram showing clustering - Present style heatmap diagnostic patterns - Show characteristic distributions style group - Highlight discordant cases clinical relevance",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "primary-literature",
        "dir": "Articles",
        "previous_headings": "References and Further Reading",
        "what": "Primary Literature",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Usubutun , Mutter GL, Saglam , Dolgun , Ozkan EA, Ince T, Akyol , Bulbul HD, Calay Z, Eren F, Gumurdulu D, Haberal , Ilvan S, Karaveli S, Koyuncuoglu M, Muezzinoglu B, Muftuoglu KH, Ozdemir N, Ozen O, Baykara S, Pestereli E, Ulukus EC, Zekioglu O. (2012). Reproducibility endometrial intraepithelial neoplasia diagnosis good, influenced diagnostic style pathologists. Modern Pathology, 25(6), 877-884. doi: 10.1038/modpathol.2011.220. PMID: 22301705. Allsbrook WC Jr, et al. (2001). Interobserver reproducibility Gleason grading prostatic carcinoma: urologic pathologists. Human Pathology, 32(1), 74-80. Elmore JG, et al. (2015). Diagnostic concordance among pathologists interpreting breast biopsy specimens. JAMA, 313(11), 1122-1132.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "ihc-clustering-and-related-methods",
        "dir": "Articles",
        "previous_headings": "References and Further Reading",
        "what": "IHC Clustering and Related Methods",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Sterlacci W, Fiegl M, Juskevicius D, Tzankov . (2020). Cluster Analysis According Immunohistochemistry Robust Tool Non-Small Cell Lung Cancer Reveals Distinct, Immune Signature-defined Subgroup. Applied Immunohistochemistry & Molecular Morphology, 28(4), 274-283. doi: 10.1097/PAI.0000000000000751. PMID: 31058655. Olsen SH, Thomas DG, Lucas DR. (2006). Cluster analysis immunohistochemical profiles synovial sarcoma, malignant peripheral nerve sheath tumor, Ewing sarcoma. Modern Pathology, 19(5), 659-668. doi: 10.1038/modpathol.3800569. PMID: 16528378. Matsuoka T, Mitomi H, Fukui N, Kanazawa H, Saito T, Hayashi T, Yao T. (2011). Cluster analysis claudin-1 -4, E-cadherin, β-catenin expression colorectal cancers. Journal Surgical Oncology, 103(7), 674-686. doi: 10.1002/jso.21854. PMID: 21360533. Carvalho JC, Wasco MJ, Kunju LP, Thomas DG, Shah RB. (2011). Cluster analysis immunohistochemical profiles delineates CK7, vimentin, S100A1 C-kit (CD117) optimal panel differential diagnosis renal oncocytoma mimics. Histopathology, 58(2), 169-179. doi: 10.1111/j.1365-2559.2011.03753.x. PMID: 21323945. Laas E, Ballester M, Cortez , Graesslin O, Daraï E. (2019). Unsupervised Clustering Immunohistochemical Markers Define High-Risk Endometrial Cancer. Pathology & Oncology Research, 25(2), 461-469. doi: 10.1007/s12253-017-0335-y. PMID: 29264761.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "methodological-references",
        "dir": "Articles",
        "previous_headings": "References and Further Reading",
        "what": "Methodological References",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Ward JH Jr. (1963). Hierarchical grouping optimize objective function. Journal American Statistical Association, 58(301), 236-244. Fleiss JL, et al. (2003). Statistical methods rates proportions. 3rd Edition, John Wiley & Sons.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "clinical-applications-1",
        "dir": "Articles",
        "previous_headings": "References and Further Reading",
        "what": "Clinical Applications",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Kronz JD, et al. (1999). Interobserver agreement classification prostatic adenocarcinoma. Urology, 53(2), 271-276. Robbins P, et al. (1995). Histological grading breast carcinomas: study interobserver agreement. Human Pathology, 26(8), 873-879.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/15-diagnostic-style-clustering.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Diagnostic Style Clustering: Identifying Pathologist 'Schools' and Diagnostic Preferences",
        "text": "Diagnostic Style Clustering feature provides powerful tool understanding patterns diagnostic disagreement among pathologists. identifying diagnostic “schools” “styles,” analysis offers insights : Quality improvement opportunities Training program effectiveness Consensus development priorities Expert consultation strategies methodology, based seminal Usubutun et al. (2012) study, broad applications across pathology subspecialties can inform evidence-based approaches reducing diagnostic variation. Remember diagnostic style differences often reflect legitimate variations clinical judgment rather errors. goal eliminate variation, understand sources ensure diagnostic approaches appropriate, consistent, well-reasoned. technical support questions diagnostic style clustering analysis, please contact ClinicoPath development team refer package documentation.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "introduction-to-co-testing-analysis",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction to Co-Testing Analysis",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "clinical practice, physicians often use multiple diagnostic tests improve diagnostic accuracy. co-testing analysis function ClinicoPath helps clinicians understand combining two diagnostic tests affects post-test probabilities clinical decision-making.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "what-is-co-testing",
        "dir": "Articles",
        "previous_headings": "Introduction to Co-Testing Analysis",
        "what": "What is Co-Testing?",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Co-testing refers simultaneous use two diagnostic tests improve diagnostic performance. approach common : Cancer screening (e.g., mammography + ultrasound) Infectious disease diagnosis (e.g., antigen test + PCR) Cardiac evaluation (e.g., troponin + ECG) Neurological assessment (e.g., MRI + clinical examination)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "post-test-probability",
        "dir": "Articles",
        "previous_headings": "Introduction to Co-Testing Analysis > Key Concepts",
        "what": "Post-Test Probability",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "probability disease obtaining test results, calculated using Bayes’ theorem.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "test-independence",
        "dir": "Articles",
        "previous_headings": "Introduction to Co-Testing Analysis > Key Concepts",
        "what": "Test Independence",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Whether results one test influence results another test, given patient’s true disease status.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "likelihood-ratios",
        "dir": "Articles",
        "previous_headings": "Introduction to Co-Testing Analysis > Key Concepts",
        "what": "Likelihood Ratios",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Positive Likelihood Ratio (PLR): much likely positive result diseased vs. non-diseased patients Negative Likelihood Ratio (NLR): much likely negative result diseased vs. non-diseased patients",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "independent-tests",
        "dir": "Articles",
        "previous_headings": "Understanding Test Independence vs. Dependence",
        "what": "Independent Tests",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Tests conditionally independent result one test doesn’t affect probability test result, given disease status. Mathematical formulation independent tests: - P(Test1+ Test2+ | Disease+) = Sensitivity₁ × Sensitivity₂ - P(Test1+ Test2+ | Disease-) = (1-Specificity₁) × (1-Specificity₂)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "dependent-tests",
        "dir": "Articles",
        "previous_headings": "Understanding Test Independence vs. Dependence",
        "what": "Dependent Tests",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Tests conditionally dependent knowing one test result changes probability test result, even disease status known. tests likely dependent: - tests measure similar biological phenomena - Tests use specimen mechanism - Tests affected confounding factors",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "example-1-covid-19-screening-with-independent-tests",
        "dir": "Articles",
        "previous_headings": "Clinical Examples",
        "what": "Example 1: COVID-19 Screening with Independent Tests",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Let’s analyze scenario use antigen test PCR test COVID-19 screening, assuming independent.",
        "code": "# COVID-19 screening with antigen + PCR (independent) covid_independent <- cotest(   test1_sens = 0.68,    # Antigen test sensitivity   test1_spec = 0.99,    # Antigen test specificity   test2_sens = 0.95,    # PCR test sensitivity   test2_spec = 0.99,    # PCR test specificity   prevalence = 0.05,    # Community prevalence (5%)   indep = TRUE,         # Assume independence   fagan = TRUE,         # Show Fagan nomogram   fnote = TRUE          # Show explanatory footnotes )  print(covid_independent)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "interpretation",
        "dir": "Articles",
        "previous_headings": "Clinical Examples > Example 1: COVID-19 Screening with Independent Tests",
        "what": "Interpretation",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Pre-test probability: 5% (community prevalence) tests positive: Dramatically increases disease probability tests negative: Substantially decreases disease probability Mixed results: Individual test probabilities apply",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "example-2-covid-19-screening-with-dependent-tests",
        "dir": "Articles",
        "previous_headings": "Clinical Examples",
        "what": "Example 2: COVID-19 Screening with Dependent Tests",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Now let’s consider tests account potential dependence (e.g., tests may affected viral load).",
        "code": "# COVID-19 screening with antigen + PCR (dependent) covid_dependent <- cotest(   test1_sens = 0.68,    # Antigen test sensitivity   test1_spec = 0.99,    # Antigen test specificity   test2_sens = 0.95,    # PCR test sensitivity   test2_spec = 0.99,    # PCR test specificity   prevalence = 0.05,    # Community prevalence (5%)   indep = FALSE,        # Account for dependence   cond_dep_pos = 0.15,  # Dependence in COVID+ patients   cond_dep_neg = 0.05,  # Dependence in COVID- patients   fagan = TRUE,         # Show Fagan nomogram   fnote = TRUE          # Show explanatory footnotes )  print(covid_dependent)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "key-differences",
        "dir": "Articles",
        "previous_headings": "Clinical Examples > Example 2: COVID-19 Screening with Dependent Tests",
        "what": "Key Differences",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "accounting dependence, benefit combined testing typically reduced compared independence assumption. : - Positive results less surprising (tests tend agree) - tests provide less independent evidence",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "example-3-cancer-screening-scenario",
        "dir": "Articles",
        "previous_headings": "Clinical Examples",
        "what": "Example 3: Cancer Screening Scenario",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Breast cancer screening using mammography ultrasound high-risk population.",
        "code": "# Breast cancer screening in high-risk women cancer_screening <- cotest(   test1_sens = 0.88,    # Mammography sensitivity   test1_spec = 0.92,    # Mammography specificity   test2_sens = 0.95,    # Ultrasound sensitivity   test2_spec = 0.85,    # Ultrasound specificity   prevalence = 0.08,    # High-risk population (8% prevalence)   indep = FALSE,        # Tests likely dependent   cond_dep_pos = 0.25,  # High dependence in cancer patients   cond_dep_neg = 0.15,  # Moderate dependence in non-cancer patients   fagan = TRUE,   fnote = TRUE )  print(cancer_screening)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "clinical-decision-points",
        "dir": "Articles",
        "previous_headings": "Clinical Examples > Example 3: Cancer Screening Scenario",
        "what": "Clinical Decision Points",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "analysis helps determine: - biopsy: High post-test probability positive tests - reassure: low probability negative tests - use additional testing: Intermediate probabilities",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "example-4-cardiac-biomarkers-in-emergency-department",
        "dir": "Articles",
        "previous_headings": "Clinical Examples",
        "what": "Example 4: Cardiac Biomarkers in Emergency Department",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Evaluating chest pain patients using troponin CK-MB.",
        "code": "# Cardiac biomarkers for myocardial infarction cardiac_biomarkers <- cotest(   test1_sens = 0.92,    # Troponin sensitivity   test1_spec = 0.89,    # Troponin specificity   test2_sens = 0.85,    # CK-MB sensitivity   test2_spec = 0.94,    # CK-MB specificity   prevalence = 0.25,    # ED chest pain patients (25% MI rate)   indep = FALSE,        # Biomarkers likely correlated   cond_dep_pos = 0.30,  # High correlation in MI patients   cond_dep_neg = 0.20,  # Moderate correlation in non-MI patients   fagan = TRUE,   fnote = TRUE )  print(cardiac_biomarkers)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "clinical-application",
        "dir": "Articles",
        "previous_headings": "Clinical Examples > Example 4: Cardiac Biomarkers in Emergency Department",
        "what": "Clinical Application",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "positive: Strong evidence MI, immediate intervention negative: Low MI probability, consider discharge protocols Discordant results: May need additional testing clinical correlation",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "use-independent-model-when",
        "dir": "Articles",
        "previous_headings": "Practical Guidelines for Co-Testing Analysis > When to Use Independent vs. Dependent Models",
        "what": "Use Independent Model when:",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Tests measure completely different biological phenomena Tests use different specimens mechanisms evidence correlation test results Limited information test interactions",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "use-dependent-model-when",
        "dir": "Articles",
        "previous_headings": "Practical Guidelines for Co-Testing Analysis > When to Use Independent vs. Dependent Models",
        "what": "Use Dependent Model when:",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Tests measure similar biological phenomena Tests use specimen Previous studies show correlation tests affected confounding factors",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "estimating-dependence-parameters",
        "dir": "Articles",
        "previous_headings": "Practical Guidelines for Co-Testing Analysis",
        "what": "Estimating Dependence Parameters",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "dependence parameters unknown: Literature Review: Look studies paired testing data Expert Opinion: Consult specialists familiar tests Sensitivity Analysis: Test range plausible values (0.05, 0.1, 0.2, 0.3) Conservative Approach: Use moderate dependence (0.1-0.2) uncertain",
        "code": "# Sensitivity analysis with different dependence levels scenarios <- list(   \"Low Dependence\" = 0.05,   \"Moderate Dependence\" = 0.15,   \"High Dependence\" = 0.30 )  sensitivity_results <- lapply(names(scenarios), function(scenario_name) {   dep_value <- scenarios[[scenario_name]]      result <- cotest(     test1_sens = 0.85,     test1_spec = 0.90,     test2_sens = 0.80,     test2_spec = 0.95,     prevalence = 0.10,     indep = FALSE,     cond_dep_pos = dep_value,     cond_dep_neg = dep_value   )      cat(\"\\n\", scenario_name, \"(ρ =\", dep_value, \"):\\n\")   print(result)      return(result) })"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "impact-of-ignoring-dependence",
        "dir": "Articles",
        "previous_headings": "Practical Guidelines for Co-Testing Analysis",
        "what": "Impact of Ignoring Dependence",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Ignoring conditional dependence exists typically leads : Overestimating benefit combined testing Exaggerating post-test probabilities Overly optimistic assessment diagnostic accuracy Unrealistic confidence intervals",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "sequential-vs--simultaneous-testing",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Sequential vs. Simultaneous Testing",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "function models simultaneous testing, can inform sequential testing strategies:",
        "code": "# First test: High sensitivity screening test first_test <- cotest(   test1_sens = 0.95,    # High sensitivity screening   test1_spec = 0.80,    # Lower specificity acceptable   test2_sens = 0.95,    # Dummy second test (same values)   test2_spec = 0.80,   prevalence = 0.05,   indep = TRUE )  # If first test positive, use confirmatory test confirmatory_test <- cotest(   test1_sens = 0.95,    # Original screening test   test1_spec = 0.80,   test2_sens = 0.85,    # Confirmatory test (different characteristics)   test2_spec = 0.98,    # Higher specificity   prevalence = 0.25,    # Higher prevalence after positive screen   indep = FALSE,   cond_dep_pos = 0.20,   cond_dep_neg = 0.10 )  cat(\"Sequential Testing Strategy:\\n\") cat(\"Step 1 - Screening Test Results:\\n\") print(first_test)  cat(\"\\nStep 2 - Confirmatory Testing (if screen positive):\\n\") print(confirmatory_test)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "cost-effectiveness-considerations",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Cost-Effectiveness Considerations",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Co-testing analysis can inform cost-effectiveness decisions:",
        "code": "# High-cost, high-accuracy test combination high_cost_scenario <- cotest(   test1_sens = 0.98,    # Expensive, highly accurate test 1   test1_spec = 0.99,   test2_sens = 0.96,    # Expensive, highly accurate test 2   test2_spec = 0.99,   prevalence = 0.02,    # Low prevalence setting   indep = TRUE,   fagan = TRUE )  # Moderate-cost, good-accuracy test combination moderate_cost_scenario <- cotest(   test1_sens = 0.85,    # Moderate cost, good accuracy test 1   test1_spec = 0.90,   test2_sens = 0.88,    # Moderate cost, good accuracy test 2   test2_spec = 0.92,   prevalence = 0.02,    # Same prevalence   indep = TRUE,   fagan = TRUE )  cat(\"High-Cost Scenario:\\n\") print(high_cost_scenario)  cat(\"\\nModerate-Cost Scenario:\\n\") print(moderate_cost_scenario)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "clinical-decision-thresholds",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Clinical Decision Thresholds",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Understanding co-testing changes clinical decisions:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "treatment-threshold-analysis",
        "dir": "Articles",
        "previous_headings": "Clinical Decision Thresholds",
        "what": "Treatment Threshold Analysis",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "",
        "code": "# Define clinical scenarios with different action thresholds scenarios <- data.frame(   Clinical_Setting = c(\"Screening\", \"Symptomatic\", \"High_Risk\"),   Prevalence = c(0.01, 0.15, 0.40),   Treatment_Threshold = c(0.05, 0.20, 0.60),   Test_Threshold = c(0.02, 0.08, 0.30) )  for (i in 1:nrow(scenarios)) {   setting <- scenarios[i, ]      cat(\"\\n\", setting$Clinical_Setting, \"Setting:\\n\")   cat(\"Prevalence:\", setting$Prevalence * 100, \"%\\n\")   cat(\"Treatment threshold:\", setting$Treatment_Threshold * 100, \"%\\n\")      result <- cotest(     test1_sens = 0.85,     test1_spec = 0.90,     test2_sens = 0.80,     test2_spec = 0.95,     prevalence = setting$Prevalence,     indep = TRUE   )      print(result) }"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "Key Takeaways",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Co-testing can significantly improve diagnostic accuracy used appropriately Test dependence matters - ignoring can lead overoptimistic results Clinical context crucial - consider prevalence, thresholds, consequences Sensitivity analysis helps understand uncertainty dependence parameters",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "before-analysis",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices > Best Practices",
        "what": "Before Analysis",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Understand biological basis potential test dependence Gather accurate sensitivity specificity data Estimate realistic prevalence population Define clinical decision thresholds",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "during-analysis",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices > Best Practices",
        "what": "During Analysis",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Start independence assumption baseline Test dependence scenarios based biological plausibility Use sensitivity analysis uncertain parameters Consider positive negative test combinations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "after-analysis",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices > Best Practices",
        "what": "After Analysis",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Interpret results clinical context Consider cost-effectiveness implications Validate findings clinical experience Update analysis new data becomes available",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "limitations",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "Limitations",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Assumes binary test results (positive/negative) Requires known test characteristics Dependence parameters may difficult estimate account test timing sequence effects",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/34-cotest-analysis.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "Summary and Best Practices",
        "what": "Conclusion",
        "title": "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making",
        "text": "Co-testing analysis provides quantitative framework understanding multiple diagnostic tests interact influence clinical decision-making. properly accounting test dependence clinical context, analysis can guide informed use diagnostic testing clinical practice. cotest function ClinicoPath makes complex calculations accessible clinicians, providing numerical results visual tools (Fagan nomograms) support evidence-based medical decision-making. vignette demonstrates use cotest function analyzing combined diagnostic tests. information ClinicoPath, visit documentation contact development team.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Screening Test Calculator powerful tool understanding diagnostic test characteristics interact disease prevalence determine clinical value test results. guide demonstrates use Bayes’ theorem clinical practice realistic scenarios sequential testing examples.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "key-learning-objectives",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Key Learning Objectives",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "reading guide, understand: sensitivity, specificity, prevalence affect predictive values screening tests work well (don’t) interpret likelihood ratios clinical practice power sequential testing confirmatory tests Real-world applications across medical specialties",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "what-makes-this-calculator-special",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "What Makes This Calculator Special",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Unlike simple calculators just compute numbers, tool: Provides clinical context real-world scenarios Demonstrates sequential testing showing probabilities update test Includes Fagan nomograms visual probability assessment Offers extensive example datasets multiple medical specialties Validates inputs provides clinical plausibility warnings",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "bayes-theorem-in-medicine",
        "dir": "Articles",
        "previous_headings": "Understanding the Fundamentals",
        "what": "Bayes’ Theorem in Medicine",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "screening calculator applies Bayes’ theorem medical testing: Prior Probability (Prevalence) + Test Result → Posterior Probability (Predictive Value)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "key-formulas",
        "dir": "Articles",
        "previous_headings": "Understanding the Fundamentals > Bayes’ Theorem in Medicine",
        "what": "Key Formulas",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Positive Predictive Value (PPV): Negative Predictive Value (NPV): Likelihood Ratios:",
        "code": "PPV = (Sensitivity × Prevalence) / [(Sensitivity × Prevalence) + (1-Specificity) × (1-Prevalence)] NPV = (Specificity × (1-Prevalence)) / [(Specificity × (1-Prevalence)) + (1-Sensitivity) × Prevalence] Positive LR = Sensitivity / (1-Specificity) Negative LR = (1-Sensitivity) / Specificity"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "loading-the-example-datasets",
        "dir": "Articles",
        "previous_headings": "Example Data and Scenarios",
        "what": "Loading the Example Datasets",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "package includes five comprehensive datasets realistic clinical scenarios:",
        "code": "# Load all screening calculator datasets data(screening_examples) data(prevalence_demo)  data(performance_demo) data(sequential_demo) data(common_tests)  # Display overview of main clinical scenarios kable(screening_examples[1:5, c(\"scenario\", \"setting\", \"sensitivity\", \"specificity\", \"prevalence\", \"ppv\")],        caption = \"Sample Clinical Scenarios\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "covid-19-testing-scenarios",
        "dir": "Articles",
        "previous_headings": "Example Data and Scenarios",
        "what": "COVID-19 Testing Scenarios",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Let’s examine COVID-19 rapid tests perform different settings:",
        "code": "covid_data <- screening_examples[screening_examples$scenario == \"COVID-19 Rapid Test\", ]  kable(covid_data[, c(\"setting\", \"prevalence\", \"ppv\", \"npv\", \"interpretation\")],       caption = \"COVID-19 Rapid Test Performance by Setting\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "key-insights",
        "dir": "Articles",
        "previous_headings": "Example Data and Scenarios > COVID-19 Testing Scenarios",
        "what": "Key Insights:",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Community screening (2% prevalence): 26% positive tests true positives Outbreak testing (15% prevalence): 78% positive tests true positives Symptomatic patients (40% prevalence): 94% positive tests true positives demonstrates critical importance prevalence test interpretation!",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "cancer-screening-examples",
        "dir": "Articles",
        "previous_headings": "Example Data and Scenarios",
        "what": "Cancer Screening Examples",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Mammography shows classic challenge cancer screening: Even good test characteristics (80-85% sensitivity, 88-92% specificity), PPV remains low due low cancer prevalence. explains positive mammograms require tissue confirmation.",
        "code": "mammo_data <- screening_examples[screening_examples$scenario == \"Mammography Screening\", ]  kable(mammo_data[, c(\"setting\", \"prevalence\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\")],       caption = \"Mammography Performance by Age Group\",        digits = 3)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "demonstration-with-fixed-test-performance",
        "dir": "Articles",
        "previous_headings": "Prevalence Effects: The Most Important Concept",
        "what": "Demonstration with Fixed Test Performance",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "# Use the prevalence demo data prevalence_plot_data <- prevalence_demo %>%   select(prevalence, ppv, npv) %>%   tidyr::pivot_longer(cols = c(ppv, npv), names_to = \"metric\", values_to = \"value\")  ggplot(prevalence_plot_data, aes(x = prevalence, y = value, color = metric)) +   geom_line(size = 1.2) +   geom_point(size = 3) +   scale_x_log10(labels = scales::percent) +   scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +   labs(title = \"How Disease Prevalence Affects Predictive Values\",        subtitle = \"Fixed test performance: Sensitivity = 90%, Specificity = 90%\",        x = \"Disease Prevalence (log scale)\",        y = \"Predictive Value\",         color = \"Metric\") +   theme_minimal() +   theme(legend.position = \"bottom\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "critical-clinical-lessons",
        "dir": "Articles",
        "previous_headings": "Prevalence Effects: The Most Important Concept",
        "what": "Critical Clinical Lessons",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "low prevalence settings: Even excellent tests poor PPV NPV remains high across prevalence ranges Screening vs. diagnostic contexts require different interpretation Sequential testing can dramatically improve diagnostic accuracy",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "hiv-testing-example",
        "dir": "Articles",
        "previous_headings": "Sequential Testing: The Power of Multiple Tests",
        "what": "HIV Testing Example",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "HIV testing demonstrates power sequential testing: progression 9% PPV (general population screening) >99% (confirmatory testing) shows sequential testing transforms diagnostic certainty.",
        "code": "hiv_data <- screening_examples[screening_examples$scenario == \"HIV Testing\", ]  kable(hiv_data[, c(\"setting\", \"prevalence\", \"ppv\", \"clinical_action\")],       caption = \"HIV Testing: From Screening to Confirmation\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "mathematical-progression",
        "dir": "Articles",
        "previous_headings": "Sequential Testing: The Power of Multiple Tests",
        "what": "Mathematical Progression",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "# Show how probability evolves through testing sequential_data <- sequential_demo  kable(sequential_data[, c(\"test_sequence\", \"final_probability\")],       caption = \"Disease Probability Evolution Through Sequential Testing\",       digits = 3) ggplot(sequential_data, aes(x = test_sequence, y = final_probability)) +   geom_col(fill = \"steelblue\", alpha = 0.7) +   geom_text(aes(label = paste0(round(final_probability * 100, 1), \"%\")),              vjust = -0.5, size = 4) +   scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +   labs(title = \"Disease Probability After Sequential Testing\",        subtitle = \"Sensitivity = 85%, Specificity = 90%, Initial Prevalence = 10%\",        x = \"Test Sequence Pattern\",        y = \"Final Disease Probability\") +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "evaluating-screening-programs",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications > When to Use the Screening Calculator",
        "what": "1. Evaluating Screening Programs",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Determine appropriate populations screening Calculate expected false positive rates Plan confirmatory testing strategies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "diagnostic-test-interpretation",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications > When to Use the Screening Calculator",
        "what": "2. Diagnostic Test Interpretation",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Understand confidence levels test results Plan sequential testing approaches Counsel patients test limitations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "educational-purposes",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications > When to Use the Screening Calculator",
        "what": "3. Educational Purposes",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Teach Bayes’ theorem concepts Demonstrate prevalence effects Show power confirmatory testing",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "quality-improvement",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications > When to Use the Screening Calculator",
        "what": "4. Quality Improvement",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Evaluate diagnostic pathways Optimize test ordering protocols Reduce unnecessary procedures",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "test-performance-comparison",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications",
        "what": "Test Performance Comparison",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "# Create heatmap showing PPV across different sens/spec combinations ggplot(performance_demo, aes(x = factor(specificity), y = factor(sensitivity), fill = ppv)) +   geom_tile() +   geom_text(aes(label = round(ppv, 2)), color = \"white\", size = 4) +   scale_fill_gradient(low = \"red\", high = \"green\", name = \"PPV\", labels = scales::percent) +   labs(title = \"Positive Predictive Value Heatmap\",        subtitle = \"Fixed prevalence = 10%\",        x = \"Specificity\",         y = \"Sensitivity\") +   theme_minimal()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "reference-test-characteristics",
        "dir": "Articles",
        "previous_headings": "Practical Clinical Applications",
        "what": "Reference Test Characteristics",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "kable(common_tests,        caption = \"Common Clinical Tests: Reference Characteristics\",       col.names = c(\"Test\", \"Sensitivity Range\", \"Specificity Range\", \"Typical Prevalence\", \"Clinical Use\"))"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "basic-setup",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Step-by-Step Guide",
        "what": "1. Basic Setup",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Navigate meddecide → Decision → Screening Test Calculator Sensitivity: True positive rate (0.01 0.99) Specificity: True negative rate (0.01 0.99) Prevalence: Disease prevalence population (0.001 0.999)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "interpretation-options",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Step-by-Step Guide",
        "what": "2. Interpretation Options",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Show 2x Test Repetition: See results two consecutive tests Show 3x Test Repetition: See results three consecutive tests Show Footnotes: Get detailed explanations metric Fagan Nomogram: Visual probability assessment tool",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "results-interpretation",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Step-by-Step Guide",
        "what": "3. Results Interpretation",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Single Test Results: Basic PPV, NPV, likelihood ratios Sequential Testing Tables: Probability evolution multiple tests Clinical Warnings: Alerts unusual parameter combinations Explanatory Text: Detailed guidance clinical examples",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "input-validation-and-warnings",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi",
        "what": "Input Validation and Warnings",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "calculator includes intelligent validation:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "error-conditions",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Input Validation and Warnings",
        "what": "Error Conditions",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Values outside 0-1 range Missing invalid inputs Mathematical impossibilities",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "clinical-warnings",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Input Validation and Warnings",
        "what": "Clinical Warnings",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Sensitivity specificity <50% (unusual clinical tests) Sensitivity specificity >99% (rarely achieved) low prevalence (<0.1%) leading extremely low PPV Combined sensitivity + specificity <100% (poor test performance)",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "fagan-nomograms",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Advanced Features",
        "what": "Fagan Nomograms",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Visual tools probability assessment: - Connect pre-test probability likelihood ratio - Read post-test probability directly nomogram - Available single tests sequential testing scenarios",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "clinical-context",
        "dir": "Articles",
        "previous_headings": "Using the Calculator in jamovi > Advanced Features",
        "what": "Clinical Context",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Built-examples : - COVID-19 testing different populations - Cancer screening across age groups - Cardiac stress testing various risk categories - Infectious disease screening confirmation - Biomarker testing cancer detection",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "coronary-artery-disease-detection",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Scenarios > Multi-Stage Diagnostic Pathways",
        "what": "Coronary Artery Disease Detection",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "# Simulate a typical CAD diagnostic pathway cad_pathway <- data.frame(   Stage = c(\"Pre-test\", \"After Stress Test\", \"After Catheterization\"),   Test = c(\"Clinical Assessment\", \"Exercise Stress Test\", \"Cardiac Catheterization\"),   Prevalence = c(0.25, 0.70, 0.95),   Test_Performance = c(\"N/A\", \"Sens 85%, Spec 75%\", \"Sens 95%, Spec 98%\"),   Clinical_Action = c(\"Risk stratification\", \"Consider catheterization\", \"Treatment planning\") )  kable(cad_pathway, caption = \"Coronary Artery Disease: Multi-Stage Diagnostic Pathway\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "breast-cancer-screening-and-diagnosis",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Scenarios > Multi-Stage Diagnostic Pathways",
        "what": "Breast Cancer Screening and Diagnosis",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "",
        "code": "breast_pathway <- data.frame(   Stage = c(\"Population Screening\", \"Abnormal Mammogram\", \"Tissue Diagnosis\"),   Prevalence = c(\"0.8%\", \"7.2%\", \"92%\"),   PPV = c(\"N/A\", \"7.2%\", \"92%\"),    Next_Step = c(\"Annual mammography\", \"Tissue biopsy\", \"Treatment planning\"),   False_Positive_Rate = c(\"N/A\", \"93%\", \"8%\") )  kable(breast_pathway, caption = \"Breast Cancer: From Screening to Diagnosis\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "outbreak-investigation-scenarios",
        "dir": "Articles",
        "previous_headings": "Advanced Clinical Scenarios",
        "what": "Outbreak Investigation Scenarios",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "disease outbreaks, prevalence changes dramatically:",
        "code": "outbreak_data <- data.frame(   Setting = c(\"Pre-outbreak\", \"Early outbreak\", \"Peak outbreak\", \"Post-outbreak\"),   Estimated_Prevalence = c(0.001, 0.05, 0.20, 0.02),   PPV_Rapid_Test = c(0.08, 0.46, 0.81, 0.26),   Clinical_Strategy = c(\"Standard screening\", \"Enhanced surveillance\", \"Containment focus\", \"Return to baseline\") )  kable(outbreak_data,        caption = \"COVID-19 Testing Strategy by Outbreak Phase\",       digits = 2)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "understanding-likelihood-ratios",
        "dir": "Articles",
        "previous_headings": "Statistical Concepts and Calculations",
        "what": "Understanding Likelihood Ratios",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Likelihood ratios quantify much test result changes disease probability:",
        "code": "lr_guide <- data.frame(   LR_Positive = c(\">10\", \"5-10\", \"2-5\", \"1-2\", \"<1\"),   Evidence_For = c(\"Strong\", \"Moderate\", \"Weak\", \"Minimal\", \"Against\"),   LR_Negative = c(\"<0.1\", \"0.1-0.2\", \"0.2-0.5\", \"0.5-1\", \">1\"),   Evidence_Against = c(\"Strong\", \"Moderate\", \"Weak\", \"Minimal\", \"For\") )  kable(lr_guide, caption = \"Likelihood Ratio Interpretation Guide\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "probability-conversion",
        "dir": "Articles",
        "previous_headings": "Statistical Concepts and Calculations",
        "what": "Probability Conversion",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Converting odds probabilities:",
        "code": "conversion_examples <- data.frame(   Probability = c(0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90),   Odds = c(\"1:99\", \"1:19\", \"1:9\", \"1:3\", \"1:1\", \"3:1\", \"9:1\"),   Clinical_Context = c(\"Rare disease\", \"Uncommon\", \"Screening\", \"Symptomatic\", \"50-50\", \"Likely\", \"Very likely\") )  kable(conversion_examples, caption = \"Probability to Odds Conversion Examples\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "case-study-1-psa-screening-dilemma",
        "dir": "Articles",
        "previous_headings": "Case Studies",
        "what": "Case Study 1: PSA Screening Dilemma",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Scenario: 55-year-old man elevated PSA (4.5 ng/mL) Test Characteristics: - Sensitivity: 70% - Specificity: 80% - Prevalence age group: 3% Calculations:",
        "code": "psa_ppv <- (0.70 * 0.03) / ((0.70 * 0.03) + (0.20 * 0.97)) psa_npv <- (0.80 * 0.97) / ((0.80 * 0.97) + (0.30 * 0.03))  cat(\"PSA Screening Results:\\n\") cat(\"PPV =\", round(psa_ppv * 100, 1), \"%\\n\") cat(\"NPV =\", round(psa_npv * 100, 1), \"%\\n\") cat(\"\\nClinical Interpretation:\\n\") cat(\"- Only\", round(psa_ppv * 100, 1), \"% of positive PSA tests indicate cancer\\n\") cat(\"- Tissue biopsy needed for confirmation\\n\") cat(\"- Consider patient preferences and comorbidities\\n\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "case-study-2-covid-19-contact-tracing",
        "dir": "Articles",
        "previous_headings": "Case Studies",
        "what": "Case Study 2: COVID-19 Contact Tracing",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Scenario: Contact confirmed COVID-19 case, asymptomatic Initial rapid test: Negative Question: confident can don’t COVID-19?",
        "code": "# Scenario parameters covid_sens <- 0.85 covid_spec <- 0.95 covid_prev_contact <- 0.15  # Higher prevalence as a contact  # Calculate NPV covid_npv <- (covid_spec * (1 - covid_prev_contact)) /               ((covid_spec * (1 - covid_prev_contact)) + ((1 - covid_sens) * covid_prev_contact))  cat(\"COVID-19 Contact Tracing:\\n\") cat(\"Negative rapid test NPV =\", round(covid_npv * 100, 1), \"%\\n\") cat(\"Probability of disease despite negative test =\", round((1-covid_npv) * 100, 1), \"%\\n\") cat(\"\\nRecommendation: Consider repeat testing or quarantine period\\n\")"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "confusing-sensitivity-and-specificity",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Common Input Errors",
        "what": "1. Confusing Sensitivity and Specificity",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Sensitivity: often test positive disease present Specificity: often test negative disease absent",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "using-wrong-prevalence",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Common Input Errors",
        "what": "2. Using Wrong Prevalence",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Population prevalence: screening scenarios Clinical prevalence: symptomatic patients Post-test prevalence: sequential testing",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "misinterpreting-results",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Common Input Errors",
        "what": "3. Misinterpreting Results",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "PPV depends heavily prevalence NPV often high even poor tests Likelihood ratios prevalence-independent",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "over-relying-on-screening-tests",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Clinical Pitfalls",
        "what": "1. Over-relying on Screening Tests",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Remember: Low prevalence = Low PPV, even good tests",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "ignoring-pre-test-probability",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Clinical Pitfalls",
        "what": "2. Ignoring Pre-test Probability",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Clinical assessment always inform test interpretation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "stopping-after-one-test",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Clinical Pitfalls",
        "what": "3. Stopping After One Test",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Sequential testing often dramatically improves diagnostic accuracy",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "input-validation-messages",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Technical Issues",
        "what": "Input Validation Messages",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "calculator warn : - Unrealistic test characteristics - Extreme prevalence values - Clinically implausible combinations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "mathematical-edge-cases",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Mistakes > Technical Issues",
        "what": "Mathematical Edge Cases",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Perfect specificity → Infinite positive LR Zero specificity → Infinite negative LR Extreme prevalence → Undefined predictive values",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "before-ordering-tests",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "1. Before Ordering Tests",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Estimate pre-test probability Consider ’ll results Plan positive negative results",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "when-interpreting-results",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "2. When Interpreting Results",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Always consider prevalence population Use likelihood ratios probability updating Consider sequential testing appropriate",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "patient-communication",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "3. Patient Communication",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Explain uncertainty test results Discuss false positive/negative possibilities Involve patients decision-making",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "teaching-bayes-theorem",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Education and Training",
        "what": "1. Teaching Bayes’ Theorem",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Start prevalence effects Use realistic clinical scenarios Demonstrate visual tools (Fagan nomograms)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "quality-improvement-projects",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Education and Training",
        "what": "2. Quality Improvement Projects",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Evaluate current diagnostic pathways Identify opportunities sequential testing Reduce unnecessary procedures",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "research-applications",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Education and Training",
        "what": "3. Research Applications",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Design diagnostic studies Calculate sample sizes test evaluation Interpret published test characteristics",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "test-combinations-and-parallel-testing",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Test Combinations and Parallel Testing",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "multiple tests performed simultaneously:",
        "code": "# Example: Combined testing approach parallel_example <- data.frame(   Strategy = c(\"Test A alone\", \"Test B alone\", \"Either positive\", \"Both positive\"),   Sensitivity = c(0.80, 0.70, 0.94, 0.56),   Specificity = c(0.90, 0.95, 0.86, 0.99),   Clinical_Use = c(\"Standard approach\", \"Alternative test\", \"High sensitivity\", \"High specificity\") )  kable(parallel_example, caption = \"Parallel Testing Strategies\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "bayesian-networks-and-complex-pathways",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Bayesian Networks and Complex Pathways",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "complex diagnostic scenarios: - Multiple risk factors - Multiple test results - Time-dependent probabilities - Cost-effectiveness considerations",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "screening-program-design",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Population Health Applications",
        "what": "Screening Program Design",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Target population selection Expected false positive rates Resource allocation planning Cost-effectiveness analysis",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "outbreak-response",
        "dir": "Articles",
        "previous_headings": "Advanced Topics > Population Health Applications",
        "what": "Outbreak Response",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Testing strategy optimization Contact tracing efficiency Resource allocation surges",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Screening Test Calculator provides comprehensive platform understanding applying Bayesian probability concepts clinical practice. combining rigorous mathematical foundations practical clinical examples, bridges gap statistical theory real-world medical decision-making.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Key Takeaways",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Prevalence crucial: Test performance depends heavily disease prevalence Sequential testing powerful: Multiple tests can dramatically improve diagnostic accuracy Context matters: Screening vs. diagnostic contexts require different interpretation Clinical judgment remains essential: Tests inform don’t replace clinical reasoning",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "next-steps",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Next Steps",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Explore example datasets specialty Practice realistic clinical scenarios Use Fagan nomograms visual probability assessment Incorporate Bayesian thinking clinical practice",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/35-screening-calculator-comprehensive.html",
        "id": "further-reading",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Further Reading",
        "title": "Screening Test Calculator: A Comprehensive Guide",
        "text": "Bayes’ theorem medical diagnosis Diagnostic test evaluation methodology Clinical decision-making uncertainty Evidence-based medicine principles vignette generated using ClinicoPath version 0.0.3.82 2025-07-29.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "introduction",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Introduction",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Sequential testing analysis powerful approach optimizing diagnostic accuracy combining multiple tests systematic ways. guide demonstrates use Sequential Testing Analysis module design, evaluate, optimize diagnostic protocols across various clinical scenarios.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "key-learning-objectives",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "Key Learning Objectives",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "reading guide, understand: three main sequential testing strategies use test characteristics interact different combinations Clinical applications across medical specialties Cost-effectiveness considerations test sequencing interpret apply Fagan nomograms sequential testing Practical implementation clinical decision-making",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "what-makes-sequential-testing-important",
        "dir": "Articles",
        "previous_headings": "Introduction",
        "what": "What Makes Sequential Testing Important",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Sequential testing addresses fundamental challenges clinical diagnosis: Single tests often insufficient complex clinical decisions Balancing sensitivity specificity requires strategic test combinations Cost-effectiveness demands optimal use expensive confirmatory tests Clinical workflows benefit systematic diagnostic protocols Patient outcomes improve accurate diagnostic strategies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "serial-positive-testing-confirmation-strategy",
        "dir": "Articles",
        "previous_headings": "Understanding Sequential Testing Strategies > The Three Core Strategies",
        "what": "1. Serial Positive Testing (Confirmation Strategy)",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Approach: Perform second test first test positive Result interpretation: Positive tests positive Effect: Maximizes specificity, reduces sensitivity Best : - Avoiding false positives consequences serious - Expensive invasive confirmatory tests - High-stakes diagnoses (e.g., cancer, genetic diseases)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "serial-negative-testing-exclusion-strategy",
        "dir": "Articles",
        "previous_headings": "Understanding Sequential Testing Strategies > The Three Core Strategies",
        "what": "2. Serial Negative Testing (Exclusion Strategy)",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Approach: Perform second test first test negative Result interpretation: Positive either test positive Effect: Maximizes sensitivity, reduces specificity Best : - afford miss cases - Screening serious conditions - Complementary tests detecting different disease manifestations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "parallel-testing",
        "dir": "Articles",
        "previous_headings": "Understanding Sequential Testing Strategies > The Three Core Strategies",
        "what": "3. Parallel Testing",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Approach: Perform tests subjects Result interpretation: Positive either test positive Effect: Improves sensitivity, reduces specificity Best : - Emergency situations requiring rapid diagnosis - Comprehensive evaluation protocols - tests quick inexpensive",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "combined-sensitivity-and-specificity",
        "dir": "Articles",
        "previous_headings": "Understanding Sequential Testing Strategies > Mathematical Framework",
        "what": "Combined Sensitivity and Specificity",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Serial Positive Strategy: Serial Negative Strategy: Parallel Strategy:",
        "code": "Combined Sensitivity = Se₁ × Se₂ Combined Specificity = Sp₁ + (1-Sp₁) × Sp₂ Combined Sensitivity = Se₁ + (1-Se₁) × Se₂ Combined Specificity = Sp₁ × Sp₂ Combined Sensitivity = Se₁ + Se₂ - (Se₁ × Se₂) Combined Specificity = Sp₁ × Sp₂"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "loading-the-example-datasets",
        "dir": "Articles",
        "previous_headings": "Example Data and Clinical Scenarios",
        "what": "Loading the Example Datasets",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "package includes comprehensive datasets realistic clinical scenarios:",
        "code": "# Load all sequential testing datasets data(sequential_testing_examples) data(strategy_comparison)  data(cost_effectiveness_examples) data(teaching_examples) data(common_test_combinations)  # Display overview of main clinical scenarios kable(sequential_testing_examples[1:5, c(\"scenario\", \"clinical_setting\", \"strategy\", \"combined_sens\", \"combined_spec\")],        caption = \"Sample Sequential Testing Scenarios\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "covid-19-testing-a-modern-example",
        "dir": "Articles",
        "previous_headings": "Example Data and Clinical Scenarios",
        "what": "COVID-19 Testing: A Modern Example",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Let’s examine COVID-19 testing demonstrates sequential testing principles:",
        "code": "covid_data <- sequential_testing_examples[   sequential_testing_examples$scenario == \"COVID-19 Testing\", ]  kable(covid_data[, c(\"clinical_setting\", \"prevalence\", \"test1_ppv\", \"combined_ppv\", \"strategy_benefit\")],       caption = \"COVID-19 Testing: Impact of Sequential Testing\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "key-insights",
        "dir": "Articles",
        "previous_headings": "Example Data and Clinical Scenarios > COVID-19 Testing: A Modern Example",
        "what": "Key Insights:",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Community screening (2% prevalence): Rapid test alone 26% PPV, combined strategy improves confidence Contact tracing (15% prevalence): Higher prevalence improves PPV significantly Symptomatic patients (40% prevalence): High prevalence leads excellent combined PPV demonstrates prevalence dramatically affects value sequential testing strategies.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "cancer-screening-the-classic-use-case",
        "dir": "Articles",
        "previous_headings": "Example Data and Clinical Scenarios",
        "what": "Cancer Screening: The Classic Use Case",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Cancer screening exemplifies serial positive testing:",
        "code": "cancer_data <- sequential_testing_examples[   grepl(\"Cancer\", sequential_testing_examples$scenario), ]  cancer_summary <- cancer_data %>%   select(scenario, test1_name, test2_name, prevalence, test1_ppv, combined_ppv) %>%   mutate(     ppv_improvement = combined_ppv - test1_ppv,     fold_improvement = combined_ppv / test1_ppv   )  kable(cancer_summary,       caption = \"Cancer Screening: Serial Positive Strategy Benefits\",       digits = 3) cancer_data %>%   select(scenario, test1_ppv, combined_ppv) %>%   pivot_longer(cols = c(test1_ppv, combined_ppv),                 names_to = \"test_stage\", values_to = \"ppv\") %>%   mutate(test_stage = ifelse(test_stage == \"test1_ppv\", \"Screening Test\", \"Combined Strategy\")) %>%   ggplot(aes(x = scenario, y = ppv, fill = test_stage)) +   geom_col(position = \"dodge\") +   scale_y_continuous(labels = scales::percent) +   labs(title = \"Cancer Screening: PPV Improvement Through Sequential Testing\",        x = \"Cancer Type\", y = \"Positive Predictive Value\", fill = \"Test Stage\") +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "comparing-all-three-strategies",
        "dir": "Articles",
        "previous_headings": "Strategy Comparison Analysis",
        "what": "Comparing All Three Strategies",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "# Filter for a specific test combination at different prevalences strategy_subset <- strategy_comparison %>%   filter(test1_sens == 0.90, test1_spec == 0.85,           test2_sens == 0.85, test2_spec == 0.95) %>%   select(strategy, prevalence, combined_sens, combined_spec, combined_ppv, combined_npv)  kable(strategy_subset,        caption = \"Strategy Comparison: Same Tests, Different Approaches\",       digits = 3) strategy_subset %>%   pivot_longer(cols = c(combined_ppv, combined_npv),                 names_to = \"metric\", values_to = \"value\") %>%   mutate(metric = ifelse(metric == \"combined_ppv\", \"PPV\", \"NPV\")) %>%   ggplot(aes(x = prevalence, y = value, color = strategy, linetype = metric)) +   geom_line(size = 1.2) +   geom_point(size = 3) +   scale_y_continuous(labels = scales::percent) +   scale_x_continuous(labels = scales::percent) +   labs(title = \"Sequential Testing Strategies: Performance Across Prevalence\",        x = \"Disease Prevalence\", y = \"Predictive Value\",         color = \"Strategy\", linetype = \"Metric\") +   theme_minimal()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "strategy-selection-guidelines",
        "dir": "Articles",
        "previous_headings": "Strategy Comparison Analysis",
        "what": "Strategy Selection Guidelines",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "guidelines <- data.frame(   Strategy = c(\"Serial Positive\", \"Serial Negative\", \"Parallel\"),   `Primary Goal` = c(\"Minimize false positives\", \"Minimize false negatives\", \"Comprehensive evaluation\"),   `Best When` = c(\"High-stakes diagnosis\", \"Cannot miss cases\", \"Emergency situations\"),   `Trade-off` = c(\"Lower sensitivity\", \"Lower specificity\", \"Higher cost\"),   `Example Use` = c(\"Cancer screening → biopsy\", \"Rare disease screening\", \"MI rule-out in ED\"),   check.names = FALSE )  kable(guidelines, caption = \"Strategy Selection Guidelines\")"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "infectious-disease-testing",
        "dir": "Articles",
        "previous_headings": "Clinical Applications by Specialty",
        "what": "Infectious Disease Testing",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "infectious_data <- sequential_testing_examples[   sequential_testing_examples$scenario %in% c(\"COVID-19 Testing\", \"Tuberculosis Screening\"), ]  infectious_summary <- infectious_data %>%   group_by(scenario, strategy) %>%   summarise(     settings = n(),     avg_sensitivity = mean(combined_sens),     avg_specificity = mean(combined_spec),     avg_ppv = mean(combined_ppv)   )  kable(infectious_summary,        caption = \"Infectious Disease Sequential Testing\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "tb-screening-example",
        "dir": "Articles",
        "previous_headings": "Clinical Applications by Specialty > Infectious Disease Testing",
        "what": "TB Screening Example",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "TB screening demonstrates prevalence affects strategy choice:",
        "code": "tb_data <- sequential_testing_examples[   sequential_testing_examples$scenario == \"Tuberculosis Screening\", ]  ggplot(tb_data, aes(x = prevalence, y = combined_ppv)) +   geom_point(aes(color = clinical_setting), size = 4) +   geom_smooth(method = \"loess\", se = FALSE) +   scale_x_continuous(labels = scales::percent) +   scale_y_continuous(labels = scales::percent) +   labs(title = \"TB Screening: PPV vs Prevalence in Different Populations\",        x = \"TB Prevalence\", y = \"Combined PPV\", color = \"Population\") +   theme_minimal()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "emergency-medicine-parallel-testing",
        "dir": "Articles",
        "previous_headings": "Clinical Applications by Specialty",
        "what": "Emergency Medicine: Parallel Testing",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "emergency_data <- sequential_testing_examples[   sequential_testing_examples$scenario == \"Myocardial Infarction Rule-out\", ]  kable(emergency_data[, c(\"clinical_setting\", \"combined_sens\", \"combined_npv\", \"clinical_impact\")],       caption = \"Emergency Medicine: Parallel Testing for MI Rule-out\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "cardiology-risk-stratification",
        "dir": "Articles",
        "previous_headings": "Clinical Applications by Specialty",
        "what": "Cardiology: Risk Stratification",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "cardiac_data <- sequential_testing_examples[   sequential_testing_examples$scenario == \"Coronary Artery Disease\", ]  cardiac_analysis <- cardiac_data %>%   mutate(     risk_category = case_when(       prevalence < 0.20 ~ \"Low Risk\",       prevalence < 0.30 ~ \"Intermediate Risk\",       TRUE ~ \"High Risk\"     )   )  ggplot(cardiac_analysis, aes(x = combined_sens, y = combined_spec, color = risk_category)) +   geom_point(size = 4) +   scale_x_continuous(labels = scales::percent) +   scale_y_continuous(labels = scales::percent) +   labs(title = \"Cardiac Testing: Sensitivity-Specificity by Risk Category\",        x = \"Combined Sensitivity\", y = \"Combined Specificity\", color = \"Risk Category\") +   theme_minimal()"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "economic-considerations",
        "dir": "Articles",
        "previous_headings": "Cost-Effectiveness Analysis",
        "what": "Economic Considerations",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "data(cost_effectiveness_examples)  # Calculate additional metrics cost_analysis <- cost_effectiveness_examples %>%   mutate(     cost_per_person_serial = serial_total_cost / population_size,     cost_per_person_parallel = parallel_total_cost / population_size,     savings_per_person = cost_savings / population_size,     savings_percent = (cost_savings / parallel_total_cost) * 100   )  kable(cost_analysis[, c(\"scenario\", \"cost_per_person_serial\", \"cost_per_person_parallel\",                         \"savings_percent\", \"cost_per_case_found\")],       caption = \"Cost-Effectiveness of Sequential Testing Strategies\",       digits = 2) cost_comparison <- cost_effectiveness_examples %>%   select(scenario, serial_total_cost, parallel_total_cost) %>%   pivot_longer(cols = c(serial_total_cost, parallel_total_cost),                names_to = \"strategy\", values_to = \"total_cost\") %>%   mutate(strategy = ifelse(grepl(\"serial\", strategy), \"Serial Positive\", \"Parallel\"))  ggplot(cost_comparison, aes(x = scenario, y = total_cost, fill = strategy)) +   geom_col(position = \"dodge\") +   scale_y_continuous(labels = scales::dollar) +   labs(title = \"Cost Comparison: Serial vs Parallel Testing\",        subtitle = \"Based on 1,000 person population\",        x = \"Clinical Scenario\", y = \"Total Testing Cost\", fill = \"Strategy\") +   theme_minimal() +   theme(axis.text.x = element_text(angle = 45, hjust = 1))"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "cost-effectiveness-calculations",
        "dir": "Articles",
        "previous_headings": "Cost-Effectiveness Analysis",
        "what": "Cost-Effectiveness Calculations",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "",
        "code": "# Calculate incremental cost-effectiveness cost_effectiveness_examples %>%   mutate(     diseased_population = population_size * prevalence,     cases_found_serial = diseased_population * test1_sens * test2_sens,     incremental_cost = serial_total_cost - (population_size * test1_cost),     incremental_cases = cases_found_serial - (diseased_population * test1_sens),     icer = ifelse(incremental_cases > 0, incremental_cost / incremental_cases, NA)   ) %>%   select(scenario, incremental_cost, incremental_cases, icer) %>%   kable(caption = \"Incremental Cost-Effectiveness of Adding Second Test\",         digits = 0)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "fagan-nomograms-for-sequential-testing",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Fagan Nomograms for Sequential Testing",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Sequential Fagan nomograms help visualize probability changes multiple testing stages:",
        "code": "# Example: COVID-19 testing progression covid_example <- sequential_testing_examples[1, ]  nomogram_data <- data.frame(   Stage = c(\"Pre-test\", \"After Rapid Test (+)\", \"After RT-PCR (+)\"),   Probability = c(     covid_example$prevalence,     covid_example$test1_ppv,     covid_example$combined_ppv   ),   Test = c(\"Clinical assessment\", \"Rapid antigen\", \"RT-PCR confirmation\"),   LR = c(NA, covid_example$test1_plr, covid_example$test2_plr) )  kable(nomogram_data,        caption = \"Probability Evolution in COVID-19 Sequential Testing\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "population-flow-analysis",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Population Flow Analysis",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Understanding patients flow sequential testing:",
        "code": "# Simulate population flow for breast cancer screening pop_size <- 10000 prevalence <- 0.008 sens1 <- 0.80  # Mammography spec1 <- 0.90 sens2 <- 0.95  # Biopsy spec2 <- 0.98  # Calculate flow diseased <- pop_size * prevalence healthy <- pop_size - diseased  # After mammography mammo_tp <- diseased * sens1 mammo_fp <- healthy * (1 - spec1) mammo_pos <- mammo_tp + mammo_fp  # After biopsy (serial positive strategy) biopsy_tp <- mammo_tp * sens2 biopsy_fp <- mammo_fp * (1 - spec2)  flow_data <- data.frame(   Stage = c(\"Initial Population\", \"Mammography Positive\", \"Biopsy Positive\"),   Total = c(pop_size, mammo_pos, biopsy_tp + biopsy_fp),   `True Positive` = c(diseased, mammo_tp, biopsy_tp),   `False Positive` = c(0, mammo_fp, biopsy_fp),   PPV = c(prevalence, mammo_tp/mammo_pos, biopsy_tp/(biopsy_tp + biopsy_fp)) )  kable(flow_data,        caption = \"Population Flow: Breast Cancer Screening\",       digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "test-independence-vs-dependence",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Test Independence vs Dependence",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "sequential testing analysis assumes test independence, real-world tests may correlated:",
        "code": "correlation_scenarios <- data.frame(   Scenario = c(\"Independent tests\", \"Positively correlated\", \"Negatively correlated\"),   Description = c(     \"Tests detect different disease aspects\",     \"Tests detect similar disease features\",     \"Tests detect complementary aspects\"   ),   `Expected Effect` = c(     \"Standard calculations apply\",     \"Lower combined sensitivity/specificity than predicted\",     \"Higher combined sensitivity/specificity than predicted\"   ),   Example = c(     \"Troponin + ECG for MI\",     \"Two imaging modalities\",     \"Functional + anatomical tests\"   ),   check.names = FALSE )  kable(correlation_scenarios, caption = \"Test Correlation Effects\")"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "basic-setup",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Step-by-Step Guide",
        "what": "1. Basic Setup",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Navigate meddecide → Decision → Sequential Testing Analysis First Test: Name, sensitivity, specificity Second Test: Name, sensitivity, specificity Disease prevalence population",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "strategy-selection",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Step-by-Step Guide",
        "what": "2. Strategy Selection",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Choose appropriate testing strategy: - Test positives first test (Serial positive) - Test negatives first test (Serial negative) - Test subjects tests (Parallel)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "display-options",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Step-by-Step Guide",
        "what": "3. Display Options",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Show Explanations: Detailed strategy explanations Show Calculation Formulas: Step--step mathematics Show Fagan Nomogram: Visual probability progression",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "results-interpretation",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Step-by-Step Guide",
        "what": "4. Results Interpretation",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Summary Table: Combined strategy performance Individual Tests Table: Comparison individual test performance Population Flow Table: Patient flow testing process",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "input-validation-and-warnings",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi",
        "what": "Input Validation and Warnings",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "module includes intelligent validation:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "error-conditions",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Input Validation and Warnings",
        "what": "Error Conditions",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Test characteristics outside 0-1 range Missing test names Invalid prevalence values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "clinical-warnings",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Input Validation and Warnings",
        "what": "Clinical Warnings",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Unusual test characteristics (sensitivity/specificity <50% >99%) Extreme prevalence values Strategy-test mismatches (e.g., low-specificity confirmatory test) Poor test performance combinations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "strategy-specific-guidance",
        "dir": "Articles",
        "previous_headings": "Using the Module in jamovi > Input Validation and Warnings",
        "what": "Strategy-Specific Guidance",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Serial positive: Second test higher specificity Serial negative: Second test higher sensitivity Parallel: Tests complementary",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "strategy-selection-1",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "1. Strategy Selection",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "High-stakes diagnoses: Use serial positive confirmation miss cases: Use serial negative comprehensive screening Emergency situations: Use parallel rapid, sensitive diagnosis",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "test-selection",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "2. Test Selection",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "First test: practical, accessible, cost-effective Second test: complement first test’s weaknesses Consider test correlation independence assumptions",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "prevalence-considerations",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Clinical Practice",
        "what": "3. Prevalence Considerations",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Low prevalence: PPV low even good tests High prevalence: NPV becomes less informative Variable prevalence: Strategy effectiveness changes dramatically",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "protocol-design",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Research and Quality Improvement",
        "what": "1. Protocol Design",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Model different strategies implementation Consider cost-effectiveness alongside diagnostic accuracy Plan different prevalence scenarios",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "performance-monitoring",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Research and Quality Improvement",
        "what": "2. Performance Monitoring",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Track real-world performance vs predictions Monitor test correlation effects Evaluate patient outcomes satisfaction",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "continuous-improvement",
        "dir": "Articles",
        "previous_headings": "Best Practices and Recommendations > For Research and Quality Improvement",
        "what": "3. Continuous Improvement",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Regular review test characteristics Update protocols based new evidence Consider emerging diagnostic technologies",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "case-study-1-optimizing-covid-19-testing-protocol",
        "dir": "Articles",
        "previous_headings": "Case Studies",
        "what": "Case Study 1: Optimizing COVID-19 Testing Protocol",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Challenge: Design testing protocol hospital employee screening Parameters: - Population: 5,000 employees - Expected prevalence: 3% - Available tests: Rapid antigen (Se=85%, Sp=95%), RT-PCR (Se=95%, Sp=99%) - Constraints: Cost, turnaround time, accuracy Analysis: Recommendation: Serial positive strategy balances accuracy, cost, operational feasibility.",
        "code": "# Calculate outcomes for different strategies covid_strategies <- data.frame(   Strategy = c(\"Rapid only\", \"PCR only\", \"Rapid → PCR (pos)\", \"Both parallel\"),   Sensitivity = c(0.85, 0.95, 0.85*0.95, 0.85 + 0.95 - 0.85*0.95),   Specificity = c(0.95, 0.99, 0.95 + (1-0.95)*0.99, 0.95*0.99),   Cost_per_person = c(25, 100, 25 + 0.08*100, 125),   Turnaround_hours = c(0.5, 24, 24, 24) ) %>%   mutate(     PPV = (Sensitivity * 0.03) / (Sensitivity * 0.03 + (1-Specificity) * 0.97),     NPV = (Specificity * 0.97) / (Specificity * 0.97 + (1-Sensitivity) * 0.03)   )  kable(covid_strategies, caption = \"COVID-19 Testing Strategy Comparison\", digits = 3)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "case-study-2-breast-cancer-screening-optimization",
        "dir": "Articles",
        "previous_headings": "Case Studies",
        "what": "Case Study 2: Breast Cancer Screening Optimization",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Challenge: Optimize screening protocol women aged 50-69 Considerations: - Cancer prevalence: 0.8% - Available tests: Digital mammography, 3D tomosynthesis, MRI, biopsy - Goals: Maximize cancer detection, minimize unnecessary procedures",
        "code": "# Compare different screening approaches breast_strategies <- data.frame(   Approach = c(\"2D mammography only\", \"3D tomosynthesis only\", \"2D → biopsy\", \"3D → biopsy\", \"2D + 3D → biopsy\"),   First_test_sens = c(0.80, 0.85, 0.80, 0.85, 0.90),   First_test_spec = c(0.90, 0.92, 0.90, 0.92, 0.88),   Combined_sens = c(0.80, 0.85, 0.76, 0.81, 0.86),   Combined_spec = c(0.90, 0.92, 0.998, 0.998, 0.998),   Biopsies_per_1000 = c(0, 0, 12, 10, 14) ) %>%   mutate(     Cancers_detected_per_1000 = Combined_sens * 8,     PPV = (Combined_sens * 0.008) / (Combined_sens * 0.008 + (1-Combined_spec) * 0.992)   )  kable(breast_strategies, caption = \"Breast Cancer Screening Strategy Analysis\", digits = 3)"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "division-by-zero",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Mathematical Issues",
        "what": "1. Division by Zero",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Occurs perfect test characteristics Module handles gracefully infinite likelihood ratios Clinical interpretation: “Perfect” tests rarely exist practice",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "extreme-prevalence",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Mathematical Issues",
        "what": "2. Extreme Prevalence",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "low prevalence: PPV remains low despite good tests high prevalence: NPV becomes uninformative Solution: Consider prevalence-appropriate strategies",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "test-correlation",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Mathematical Issues",
        "what": "3. Test Correlation",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Independence assumption may hold Real performance may differ predictions Solution: Validate real-world data",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "strategy-selection-confusion",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Clinical Interpretation Challenges",
        "what": "1. Strategy Selection Confusion",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Problem: Unclear strategy use Solution: Focus primary clinical goal (avoid false positives vs false negatives)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "prevalence-estimation",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Clinical Interpretation Challenges",
        "what": "2. Prevalence Estimation",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Problem: Uncertain disease prevalence Solution: Use sensitivity analysis across prevalence ranges",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "test-characteristic-uncertainty",
        "dir": "Articles",
        "previous_headings": "Troubleshooting and Common Issues > Clinical Interpretation Challenges",
        "what": "3. Test Characteristic Uncertainty",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Problem: Published test characteristics may apply population Solution: Use conservative estimates local validation data",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "markov-models-for-sequential-testing",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Markov Models for Sequential Testing",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "complex diagnostic pathways multiple decision points:",
        "code": "markov_states <- data.frame(   State = c(\"Pre-test\", \"Test 1 +\", \"Test 1 -\", \"Test 2 +\", \"Test 2 -\", \"Diagnosed\", \"Not diagnosed\"),   Description = c(     \"Initial clinical presentation\",     \"Positive first test result\",     \"Negative first test result\",      \"Positive second test result\",     \"Negative second test result\",     \"Disease confirmed\",     \"Disease ruled out\"   ),   Transition_probabilities = c(     \"Based on test characteristics\",     \"To Test 2 or final diagnosis\",     \"To Test 2 or discharge\",     \"To final diagnosis\",     \"To discharge or additional testing\",     \"Terminal state\",     \"Terminal state\"   ) )  kable(markov_states, caption = \"Markov Model States for Complex Sequential Testing\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "machine-learning-integration",
        "dir": "Articles",
        "previous_headings": "Advanced Applications",
        "what": "Machine Learning Integration",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Modern sequential testing can incorporate ML predictions:",
        "code": "ml_framework <- data.frame(   Component = c(\"Risk Prediction\", \"Test Selection\", \"Result Integration\", \"Decision Support\"),   Traditional_Approach = c(     \"Fixed prevalence estimates\",     \"Protocol-driven selection\",     \"Rule-based interpretation\",     \"Physician judgment\"   ),   ML_Enhanced_Approach = c(     \"Personalized risk scores\",     \"Adaptive test selection\",     \"Probabilistic integration\",     \"Evidence-based recommendations\"   ),   Benefit = c(     \"More accurate pre-test probabilities\",     \"Optimal test sequences\",     \"Better diagnostic accuracy\",     \"Reduced cognitive load\"   ) )  kable(ml_framework, caption = \"Machine Learning Enhancement of Sequential Testing\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Sequential testing analysis provides systematic framework optimizing diagnostic accuracy strategic test combinations. Sequential Testing Analysis module offers comprehensive tools :",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "key-capabilities",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Key Capabilities",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Strategy Comparison: Evaluate serial positive, serial negative, parallel approaches Clinical Scenarios: Apply real-world medical situations across specialties Cost-Effectiveness: Balance diagnostic accuracy economic considerations Visual Analysis: Use Fagan nomograms population flow diagrams Quality Improvement: Design optimize clinical protocols",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "best-practices-summary",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Best Practices Summary",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Match strategy clinical goals: Confirmation vs exclusion vs comprehensive evaluation Consider prevalence effects: Strategy effectiveness varies dramatically disease prevalence Plan real-world constraints: Cost, time, availability, patient factors Validate assumptions: Test independence population applicability Monitor performance: Track outcomes continuously improve protocols",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/36-sequential-testing-comprehensive.html",
        "id": "future-directions",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Future Directions",
        "title": "Sequential Testing Analysis: A Comprehensive Guide",
        "text": "Integration electronic health records automated risk assessment Real-time adaptive testing protocols based individual patient characteristics Machine learning-enhanced test selection interpretation Cost-effectiveness modeling health economic outcomes Population-level optimization public health screening programs Sequential testing analysis represents critical tool evidence-based diagnostic decision-making, helping clinicians healthcare systems optimize patient care managing resources effectively. vignette generated using ClinicoPath version 0.0.3.82 2025-07-29.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "overview",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Overview",
        "title": "Clinical Prediction Model Builder",
        "text": "modelbuilder function ClinicoPath provides comprehensive clinical prediction model development advanced validation seamless integration Decision Curve Analysis. function specifically designed medical research applications robust prediction models essential clinical decision-making.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "key-features",
        "dir": "Articles",
        "previous_headings": "Overview",
        "what": "Key Features",
        "title": "Clinical Prediction Model Builder",
        "text": "Multiple Model Types: Basic clinical, enhanced clinical, biomarker, custom models Advanced Validation: Cross-validation, bootstrap validation, optimism correction Comprehensive Metrics: AUC, calibration, NRI, IDI, net benefit calculations Missing Data Handling: Complete cases, mean imputation, multiple imputation DCA Integration: Seamless workflow Decision Curve Analysis Clinical Risk Scores: Automatic generation clinical risk scoring systems",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "when-to-use-prediction-model-builder",
        "dir": "Articles",
        "previous_headings": "Overview",
        "what": "When to Use Prediction Model Builder",
        "title": "Clinical Prediction Model Builder",
        "text": "Prediction modeling essential : Risk Stratification: Identify patients high risk adverse outcomes Clinical Decision Support: Provide evidence-based decision aids Biomarker Validation: Assess clinical utility new biomarkers Regulatory Submissions: Develop models FDA/EMA approval Personalized Medicine: Create individualized treatment recommendations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "installation-and-setup",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Installation and Setup",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Load required libraries library(meddecide) library(dplyr) library(pROC) library(ggplot2) library(mice)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "types-of-prediction-models",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models",
        "what": "Types of Prediction Models",
        "title": "Clinical Prediction Model Builder",
        "text": "modelbuilder function supports four types prediction models:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "basic-clinical-models",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models > Types of Prediction Models",
        "what": "1. Basic Clinical Models",
        "title": "Clinical Prediction Model Builder",
        "text": "Purpose: Foundation models using core demographic primary risk factors Variables: Age, sex, primary risk factors (diabetes, hypertension) Use Case: Initial risk assessment, screening tools Advantages: Simple, widely applicable, easy implement",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "enhanced-clinical-models",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models > Types of Prediction Models",
        "what": "2. Enhanced Clinical Models",
        "title": "Clinical Prediction Model Builder",
        "text": "Purpose: Extended models additional clinical variables Variables: Basic predictors plus smoking, cholesterol, BMI, blood pressure Use Case: Comprehensive risk assessment, clinical guidelines Advantages: Better discrimination, clinical relevance",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "biomarker-models",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models > Types of Prediction Models",
        "what": "3. Biomarker Models",
        "title": "Clinical Prediction Model Builder",
        "text": "Purpose: Advanced models incorporating laboratory values Variables: Clinical predictors plus biomarkers (troponin, creatinine) Use Case: Precision medicine, specialized care Advantages: Highest accuracy, novel biomarker validation",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "custom-models",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models > Types of Prediction Models",
        "what": "4. Custom Models",
        "title": "Clinical Prediction Model Builder",
        "text": "Purpose: User-defined variable combinations Variables: combination available predictors Use Case: Research applications, hypothesis testing Advantages: Flexible, tailored specific needs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "model-development-process",
        "dir": "Articles",
        "previous_headings": "Understanding Prediction Models",
        "what": "Model Development Process",
        "title": "Clinical Prediction Model Builder",
        "text": "modelbuilder follows established clinical prediction modeling guidelines: Data Preparation: Validation, missing data handling, variable transformation Model Fitting: Logistic regression convergence monitoring Variable Selection: Stepwise selection AIC/BIC criteria Performance Assessment: Discrimination, calibration, clinical utility Validation: Cross-validation, bootstrap validation, external validation Clinical Implementation: Risk score generation, DCA integration",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "simple-clinical-model",
        "dir": "Articles",
        "previous_headings": "Basic Usage",
        "what": "Simple Clinical Model",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Load example data data(modelbuilder_test_data)  # Build basic clinical model result <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   showModelSummary = TRUE,   showPerformanceMetrics = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "enhanced-clinical-model",
        "dir": "Articles",
        "previous_headings": "Basic Usage",
        "what": "Enhanced Clinical Model",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Build enhanced clinical model result <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"bmi\", \"systolic_bp\"),   buildEnhancedModel = TRUE,   splitData = TRUE,   crossValidation = TRUE,   showROCCurves = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "biomarker-model-with-validation",
        "dir": "Articles",
        "previous_headings": "Basic Usage",
        "what": "Biomarker Model with Validation",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Build biomarker model with comprehensive validation result <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   biomarkerPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                           \"smoking\", \"cholesterol\", \"troponin\", \"creatinine\"),   buildBiomarkerModel = TRUE,   splitData = TRUE,   crossValidation = TRUE,   bootstrapValidation = TRUE,   missingDataMethod = \"multiple_imputation\",   showCalibrationPlots = TRUE,   compareModels = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "missing-data-handling",
        "dir": "Articles",
        "previous_headings": "Advanced Configuration",
        "what": "Missing Data Handling",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Complete cases analysis result_complete <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"troponin\"),   buildBasicModel = TRUE,   missingDataMethod = \"complete_cases\" )  # Multiple imputation result_imputed <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"troponin\"),   buildBasicModel = TRUE,   missingDataMethod = \"multiple_imputation\",   imputationSets = 10 )  # Variable exclusion for high missing rates result_excluded <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"troponin\"),   buildBasicModel = TRUE,   missingDataMethod = \"exclude_missing\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "variable-transformations-and-interactions",
        "dir": "Articles",
        "previous_headings": "Advanced Configuration",
        "what": "Variable Transformations and Interactions",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Include variable transformations result_transformed <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"cholesterol\", \"troponin\"),   buildBasicModel = TRUE,   transformVariables = TRUE,   transformMethod = \"log\" )  # Include interaction terms result_interactions <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"smoking\"),   buildBasicModel = TRUE,   includeInteractions = TRUE,   interactionTerms = \"age*sex, diabetes*smoking\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "stepwise-variable-selection",
        "dir": "Articles",
        "previous_headings": "Advanced Configuration",
        "what": "Stepwise Variable Selection",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Stepwise selection with AIC result_stepwise_aic <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"bmi\", \"systolic_bp\"),   buildEnhancedModel = TRUE,   useStepwise = TRUE,   stepwiseDirection = \"both\",   selectionCriterion = \"aic\" )  # Stepwise selection with BIC result_stepwise_bic <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"bmi\", \"systolic_bp\"),   buildEnhancedModel = TRUE,   useStepwise = TRUE,   stepwiseDirection = \"both\",   selectionCriterion = \"bic\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "validation-methods",
        "dir": "Articles",
        "previous_headings": "Advanced Configuration",
        "what": "Validation Methods",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Cross-validation result_cv <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   crossValidation = TRUE,   cvFolds = 10 )  # Bootstrap validation result_bootstrap <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   bootstrapValidation = TRUE,   bootstrapReps = 1000 )  # Combined validation result_combined <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   crossValidation = TRUE,   bootstrapValidation = TRUE,   cvFolds = 5,   bootstrapReps = 500 )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "application-1-cardiovascular-risk-prediction",
        "dir": "Articles",
        "previous_headings": "Clinical Research Applications",
        "what": "Application 1: Cardiovascular Risk Prediction",
        "title": "Clinical Prediction Model Builder",
        "text": "Clinical Interpretation: - Basic model provides foundation risk assessment - Enhanced model adds lifestyle laboratory factors - Biomarker model incorporates cardiac-specific markers - Model comparison guides clinical implementation",
        "code": "# Cardiovascular risk assessment model cv_risk_model <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",      # Build multiple models for comparison   buildBasicModel = TRUE,   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),      buildEnhancedModel = TRUE,   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"bmi\", \"family_history\"),      buildBiomarkerModel = TRUE,   biomarkerPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                           \"smoking\", \"cholesterol\", \"troponin\", \"creatinine\"),      # Configuration   splitData = TRUE,   crossValidation = TRUE,   missingDataMethod = \"multiple_imputation\",      # Outputs   compareModels = TRUE,   showROCCurves = TRUE,   showCalibrationPlots = TRUE,   generateRiskScore = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "application-2-biomarker-validation-study",
        "dir": "Articles",
        "previous_headings": "Clinical Research Applications",
        "what": "Application 2: Biomarker Validation Study",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Biomarker validation for new cardiac marker biomarker_study <- modelbuilder(   data = biomarker_validation_data,   outcome = \"major_adverse_cardiac_event\",   outcomePositive = \"Yes\",      # Reference clinical model   buildBasicModel = TRUE,   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\", \"chest_pain\"),   basicModelName = \"clinical_model\",      # Biomarker-enhanced model   buildBiomarkerModel = TRUE,   biomarkerPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                           \"chest_pain\", \"new_biomarker\"),   biomarkerModelName = \"biomarker_model\",      # Validation   splitData = TRUE,   crossValidation = TRUE,   calculateNRI = TRUE,   calculateIDI = TRUE,      # Outputs   compareModels = TRUE,   showPerformanceMetrics = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "application-3-personalized-treatment-selection",
        "dir": "Articles",
        "previous_headings": "Clinical Research Applications",
        "what": "Application 3: Personalized Treatment Selection",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Treatment selection model treatment_model <- modelbuilder(   data = treatment_response_data,   outcome = \"treatment_response\",   outcomePositive = \"Responder\",      # Personalized model   buildCustomModel = TRUE,   customPredictors = c(\"age\", \"sex\", \"disease_severity\", \"biomarker_profile\",                        \"genetic_score\", \"comorbidity_index\"),   customModelName = \"personalized_treatment\",      # Advanced options   includeInteractions = TRUE,   interactionTerms = \"age*biomarker_profile, disease_severity*genetic_score\",   transformVariables = TRUE,   useStepwise = TRUE,      # Validation   splitData = TRUE,   crossValidation = TRUE,   bootstrapValidation = TRUE,      # Clinical utility   generateRiskScore = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "application-4-multi-center-model-development",
        "dir": "Articles",
        "previous_headings": "Clinical Research Applications",
        "what": "Application 4: Multi-center Model Development",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Multi-center prediction model multicenter_model <- modelbuilder(   data = multicenter_study_data,   outcome = \"clinical_outcome\",   outcomePositive = \"Yes\",      # Enhanced model with site adjustments   buildEnhancedModel = TRUE,   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"site\"),      # Robust validation   splitData = TRUE,   crossValidation = TRUE,   cvFolds = 10,   bootstrapValidation = TRUE,      # Missing data handling   missingDataMethod = \"multiple_imputation\",   imputationSets = 20,      # Comprehensive outputs   compareModels = TRUE,   showModelSummary = TRUE,   showPerformanceMetrics = TRUE,   showCalibrationPlots = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "model-performance-metrics",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Model Performance Metrics",
        "title": "Clinical Prediction Model Builder",
        "text": "Discrimination Metrics: - AUC (Area Curve): Measures model’s ability distinguish outcomes - AUC > 0.8: Excellent discrimination - AUC 0.7-0.8: Good discrimination - AUC 0.6-0.7: Fair discrimination - AUC < 0.6: Poor discrimination Calibration Metrics: - Calibration Slope: Measures agreement predicted observed probabilities - Slope = 1.0: Perfect calibration - Slope < 1.0: Overfitting (predictions extreme) - Slope > 1.0: Underfitting (predictions conservative) Intercept = 0: systematic bias Intercept > 0: Systematic -prediction Intercept < 0: Systematic -prediction Overall Performance: - Brier Score: Measures overall prediction accuracy (lower better) - Hosmer-Lemeshow Test: Tests goodness fit (p > 0.05 indicates good fit)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "model-comparison",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Model Comparison",
        "title": "Clinical Prediction Model Builder",
        "text": "Interpretation Guidelines: - Higher AUC indicates better discrimination - Calibration slope closer 1.0 indicates better calibration - Lower Brier score indicates better overall performance - Positive NRI indicates net improvement reclassification - Positive IDI indicates improvement discrimination",
        "code": "# Compare multiple models comparison_result <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",      # Build all model types   buildBasicModel = TRUE,   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),      buildEnhancedModel = TRUE,   enhancedPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                          \"smoking\", \"cholesterol\", \"bmi\"),      buildBiomarkerModel = TRUE,   biomarkerPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\",                           \"smoking\", \"cholesterol\", \"troponin\"),      # Comparison settings   compareModels = TRUE,   showPerformanceMetrics = TRUE,   calculateNRI = TRUE,   calculateIDI = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "cross-validation-results",
        "dir": "Articles",
        "previous_headings": "Interpreting Results",
        "what": "Cross-Validation Results",
        "title": "Clinical Prediction Model Builder",
        "text": "Cross-Validation Metrics: - CV AUC: Average AUC across folds - CV AUC (SD): Standard deviation AUC across folds - Optimism: Difference training CV performance - Optimism-Corrected AUC: Training AUC minus optimism Interpretation: - CV AUC provides unbiased estimate future performance - Small SD indicates stable performance across folds - Large optimism indicates overfitting - Optimism-corrected estimates realistic",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "study-design-and-data-quality",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "1. Study Design and Data Quality",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Ensure adequate sample size n_events <- sum(clinical_data$outcome == \"Yes\") n_predictors <- length(predictor_variables) epv <- n_events / n_predictors  # Rule of thumb: EPV should be ≥ 10 if (epv < 10) {   warning(\"Events per variable (EPV) is low. Consider reducing predictors or increasing sample size.\") }  # Check data quality summary(clinical_data)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "variable-selection",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "2. Variable Selection",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Clinical relevance first clinical_predictors <- c(\"age\", \"sex\", \"diabetes\", \"hypertension\")  # Add variables based on clinical knowledge enhanced_predictors <- c(clinical_predictors, \"smoking\", \"cholesterol\", \"family_history\")  # Consider biomarkers last biomarker_predictors <- c(enhanced_predictors, \"troponin\", \"creatinine\", \"bnp\")  # Use stepwise selection judiciously stepwise_model <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   enhancedPredictors = biomarker_predictors,   buildEnhancedModel = TRUE,   useStepwise = TRUE,   selectionCriterion = \"bic\"  # BIC is more conservative than AIC )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "validation-strategy",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "3. Validation Strategy",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Comprehensive validation approach validation_model <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,      # Multiple validation methods   splitData = TRUE,           # Internal validation   crossValidation = TRUE,     # Cross-validation   bootstrapValidation = TRUE, # Bootstrap validation      cvFolds = 10,   bootstrapReps = 1000,      # Performance assessment   showPerformanceMetrics = TRUE,   showCalibrationPlots = TRUE,   compareModels = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "missing-data-strategy",
        "dir": "Articles",
        "previous_headings": "Best Practices",
        "what": "4. Missing Data Strategy",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Assess missing data patterns missing_summary <- clinical_data %>%   summarise_all(~sum(is.na(.))) %>%   gather(variable, missing_count) %>%   mutate(missing_percent = missing_count / nrow(clinical_data) * 100) %>%   arrange(desc(missing_percent))  # Choose appropriate method if (max(missing_summary$missing_percent) < 5) {   # Low missing data: complete cases   method <- \"complete_cases\" } else if (max(missing_summary$missing_percent) < 20) {   # Moderate missing data: multiple imputation   method <- \"multiple_imputation\" } else {   # High missing data: exclude variables   method <- \"exclude_missing\" }  model_missing <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   missingDataMethod = method )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "generating-risk-scores",
        "dir": "Articles",
        "previous_headings": "Clinical Risk Scores",
        "what": "Generating Risk Scores",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Generate clinical risk score risk_score_model <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\", \"smoking\"),   buildBasicModel = TRUE,      # Risk score generation   generateRiskScore = TRUE,   riskScorePoints = \"framingham\"  # or \"simple\" or \"deciles\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "risk-score-implementation",
        "dir": "Articles",
        "previous_headings": "Clinical Risk Scores",
        "what": "Risk Score Implementation",
        "title": "Clinical Prediction Model Builder",
        "text": "Framingham-Style Points: - Age-based scaling - Integer point assignments - Clinically interpretable ranges Simple Integer Weights: - Coefficient-based scaling - Easy calculation - Suitable electronic systems Risk Decile Scoring: - Percentile-based categories - Population-specific ranges - Suitable quality metrics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "clinical-risk-score-example",
        "dir": "Articles",
        "previous_headings": "Clinical Risk Scores",
        "what": "Clinical Risk Score Example",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Example: Cardiovascular Risk Score # Age: 65 years = 2 points # Sex: Male = 3 points # Diabetes: Yes = 4 points # Hypertension: Yes = 2 points # Smoking: Current = 5 points # Total Score: 16 points  # Risk interpretation: # 0-5 points: Low risk (<5%) # 6-10 points: Moderate risk (5-15%) # 11-15 points: High risk (15-30%) # >15 points: Very high risk (>30%)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "dca-preparation",
        "dir": "Articles",
        "previous_headings": "Integration with Decision Curve Analysis",
        "what": "DCA Preparation",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Build models for DCA dca_models <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",      # Multiple models for comparison   buildBasicModel = TRUE,   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   basicModelName = \"clinical_model\",      buildBiomarkerModel = TRUE,   biomarkerPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\", \"troponin\"),   biomarkerModelName = \"biomarker_model\",      # DCA preparation   createPredictions = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "dca-workflow",
        "dir": "Articles",
        "previous_headings": "Integration with Decision Curve Analysis",
        "what": "DCA Workflow",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# After model building, use DCA module # 1. Models create prediction columns automatically # 2. Columns named: [model_name]_prob # 3. Ready for direct use in DCA  # Example DCA setup: # Outcome: cardiovascular_event # Positive outcome: Yes # Prediction models: clinical_model_prob, biomarker_model_prob # Threshold range: 5% to 50%"
    },
    {
        "path": []
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "issue-1-model-non-convergence",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue 1: Model Non-Convergence",
        "title": "Clinical Prediction Model Builder",
        "text": "Problem: Model fitting fails produces warnings Solutions:",
        "code": "# Increase maximum iterations result <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\"),   buildBasicModel = TRUE,   # Convergence handled automatically in enhanced version )  # Check for perfect separation separation_check <- table(clinical_data$perfect_predictor, clinical_data$cardiovascular_event) print(separation_check)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "issue-2-perfect-separation",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue 2: Perfect Separation",
        "title": "Clinical Prediction Model Builder",
        "text": "Problem: One predictor perfectly predicts outcome Solutions:",
        "code": "# The enhanced modelbuilder automatically detects and warns about separation # Remove or combine categories of problematic variables # Use penalized regression (if available)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "issue-3-low-event-rate",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue 3: Low Event Rate",
        "title": "Clinical Prediction Model Builder",
        "text": "Problem: events stable modeling Solutions:",
        "code": "# Check events per variable n_events <- sum(clinical_data$outcome == \"Yes\") n_predictors <- length(predictor_variables) epv <- n_events / n_predictors  if (epv < 10) {   # Reduce number of predictors   essential_predictors <- c(\"age\", \"sex\", \"primary_risk_factor\")      # Or combine outcome categories   # Or collect more data }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "issue-4-high-missing-data",
        "dir": "Articles",
        "previous_headings": "Troubleshooting > Common Issues and Solutions",
        "what": "Issue 4: High Missing Data",
        "title": "Clinical Prediction Model Builder",
        "text": "Problem: Substantial missing data key variables Solutions:",
        "code": "# Use multiple imputation result <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"biomarker\"),   buildBasicModel = TRUE,   missingDataMethod = \"multiple_imputation\",   imputationSets = 20 )  # Or exclude high-missing variables result <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"biomarker\"),   buildBasicModel = TRUE,   missingDataMethod = \"exclude_missing\" )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "statistical-reporting-guidelines",
        "dir": "Articles",
        "previous_headings": "Reporting Results",
        "what": "Statistical Reporting Guidelines",
        "title": "Clinical Prediction Model Builder",
        "text": "reporting prediction model results: Sample size event rate Variable selection method Missing data handling Model fitting procedure Discrimination (AUC 95% CI) Calibration (slope intercept) Overall performance (Brier score) Classification metrics optimal threshold Cross-validation performance Bootstrap validation (performed) Optimism-corrected estimates External validation (available) Decision curve analysis results Net benefit across thresholds Clinical impact assessment",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "example-report-template",
        "dir": "Articles",
        "previous_headings": "Reporting Results",
        "what": "Example Report Template",
        "title": "Clinical Prediction Model Builder",
        "text": "Sample Report Text: “developed clinical prediction model cardiovascular events using logistic regression. model included age, sex, diabetes, hypertension predictors. dataset split training (70%, n=420) validation (30%, n=180) sets. model demonstrated good discrimination (AUC 0.74, 95% CI 0.69-0.79) adequate calibration (slope 0.96, intercept 0.03). Five-fold cross-validation yielded optimism-corrected AUC 0.72. Decision curve analysis showed clinical utility across 10-30% threshold range.”",
        "code": "# Generate comprehensive model report report_model <- modelbuilder(   data = modelbuilder_test_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",      # Model development   buildBasicModel = TRUE,   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),      # Validation   splitData = TRUE,   crossValidation = TRUE,   bootstrapValidation = TRUE,      # Comprehensive outputs   showModelSummary = TRUE,   showPerformanceMetrics = TRUE,   showCalibrationPlots = TRUE,   compareModels = TRUE,   generateRiskScore = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "custom-prediction-models",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Custom Prediction Models",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Complex custom model with interactions custom_model <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",      # Custom variable combination   buildCustomModel = TRUE,   customPredictors = c(\"age\", \"sex\", \"diabetes\", \"cholesterol\",                        \"family_history\", \"exercise\", \"diet_score\"),      # Advanced features   includeInteractions = TRUE,   interactionTerms = \"age*sex, diabetes*cholesterol, family_history*exercise\",   transformVariables = TRUE,   transformMethod = \"polynomial\",      # Variable selection   useStepwise = TRUE,   stepwiseDirection = \"both\",   selectionCriterion = \"bic\" )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "model-updating-and-recalibration",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Model Updating and Recalibration",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Original model original_model <- modelbuilder(   data = original_dataset,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE )  # Updated model with new data updated_model <- modelbuilder(   data = updated_dataset,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,      # Compare to original   compareModels = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "multi-outcome-models",
        "dir": "Articles",
        "previous_headings": "Advanced Topics",
        "what": "Multi-outcome Models",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# Separate models for different outcomes primary_outcome <- modelbuilder(   data = clinical_data,   outcome = \"primary_endpoint\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   basicModelName = \"primary_model\" )  secondary_outcome <- modelbuilder(   data = clinical_data,   outcome = \"secondary_endpoint\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   basicModelName = \"secondary_model\" )"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "model-validation-checklist",
        "dir": "Articles",
        "previous_headings": "Quality Assurance",
        "what": "Model Validation Checklist",
        "title": "Clinical Prediction Model Builder",
        "text": "Sample Size: Adequate events per variable (EPV ≥ 10) Data Quality: Missing data patterns assessed handled Variable Selection: Clinically relevant predictors included Model Fitting: Convergence achieved, separation issues Performance: Discrimination calibration adequate Validation: Cross-validation bootstrap performed Clinical Utility: Decision curve analysis completed Reporting: Transparent methodology results",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "validation-steps",
        "dir": "Articles",
        "previous_headings": "Quality Assurance",
        "what": "Validation Steps",
        "title": "Clinical Prediction Model Builder",
        "text": "",
        "code": "# 1. Data quality assessment summary(clinical_data)  # 2. Model development model_result <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   showModelSummary = TRUE )  # 3. Performance evaluation performance_check <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   showPerformanceMetrics = TRUE,   showCalibrationPlots = TRUE )  # 4. Validation validation_check <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   crossValidation = TRUE,   bootstrapValidation = TRUE )  # 5. Clinical utility utility_check <- modelbuilder(   data = clinical_data,   outcome = \"cardiovascular_event\",   outcomePositive = \"Yes\",   basicPredictors = c(\"age\", \"sex\", \"diabetes\", \"hypertension\"),   buildBasicModel = TRUE,   exportForDCA = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "conclusion",
        "dir": "Articles",
        "previous_headings": "",
        "what": "Conclusion",
        "title": "Clinical Prediction Model Builder",
        "text": "modelbuilder function provides comprehensive toolkit clinical prediction model development. combining robust statistical methods, advanced validation techniques, seamless integration decision analysis, enables researchers : Develop high-quality prediction models Validate model performance rigorously Assess clinical utility effectively Implement models clinical practice",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "key-takeaways",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Key Takeaways",
        "title": "Clinical Prediction Model Builder",
        "text": "Start clinical knowledge selecting predictors Use appropriate validation methods dataset size Handle missing data carefully appropriate methods Assess discrimination calibration performance Evaluate clinical utility decision curve analysis Report methods results transparently reproducibility",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/articles/38-modelbuilder-comprehensive.html",
        "id": "further-reading",
        "dir": "Articles",
        "previous_headings": "Conclusion",
        "what": "Further Reading",
        "title": "Clinical Prediction Model Builder",
        "text": "Steyerberg, E.W. (2019). Clinical Prediction Models. Springer. Harrell, F.E. (2015). Regression Modeling Strategies. Springer. Collins, G.S., et al. (2015). Transparent reporting multivariable prediction model individual prognosis diagnosis (TRIPOD). BMJ, 350, g7594. information updates, visit ClinicoPath documentation. vignette generated using ClinicoPath version 0.0.3.82 2025-07-29.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/authors.html",
        "id": null,
        "dir": "",
        "previous_headings": "",
        "what": "Authors",
        "title": "Authors and Citation",
        "text": "Serdar Balci. Author, maintainer.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/authors.html",
        "id": "citation",
        "dir": "",
        "previous_headings": "",
        "what": "Citation",
        "title": "Authors and Citation",
        "text": "Balci S (2025). meddecide: Medical Decision Analysis Reliability Assessment Tools ClinicoPath jamovi Module. R package version 0.0.3.82, https://github.com/sbalci/ClinicoPathJamoviModule/.",
        "code": "@Manual{,   title = {meddecide: Medical Decision Analysis and Reliability Assessment Tools in ClinicoPath jamovi Module},   author = {Serdar Balci},   year = {2025},   note = {R package version 0.0.3.82},   url = {https://github.com/sbalci/ClinicoPathJamoviModule/}, }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/index.html",
        "id": "meddecide",
        "dir": "",
        "previous_headings": "",
        "what": "Medical Decision Analysis and Reliability Assessment Tools in ClinicoPath jamovi Module",
        "title": "Medical Decision Analysis and Reliability Assessment Tools in ClinicoPath jamovi Module",
        "text": "Functions Medical Decision Making ClinicoPath jamovi Module See https://sbalci.github.io/ClinicoPathJamoviModule/",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/index.html",
        "id": "example-datasets",
        "dir": "",
        "previous_headings": "",
        "what": "Example datasets",
        "title": "Medical Decision Analysis and Reliability Assessment Tools in ClinicoPath jamovi Module",
        "text": "Small CSV files provided inst/extdata illustrate main functions. Use read.csv() together system.file() access files package installed.",
        "code": "# Decision analysis example df_dec <- read.csv(system.file(\"extdata\", \"decision_example.csv\", package = \"meddecide\")) decision(data = df_dec, gold = df_dec$gold, newtest = df_dec$newtest,          goldPositive = 1, testPositive = 1)  # ROC analysis example df_roc <- read.csv(system.file(\"extdata\", \"roc_example.csv\", package = \"meddecide\")) psychopdaROC(data = df_roc, class = df_roc$class, value = df_roc$value)  # Agreement analysis example df_agr <- read.csv(system.file(\"extdata\", \"agreement_example.csv\", package = \"meddecide\")) agreement(data = df_agr)"
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreement.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Interrater Reliability — agreement",
        "text": "",
        "code": "agreement(   data,   vars,   sft = FALSE,   heatmap = TRUE,   heatmapDetails = FALSE,   wght = \"unweighted\",   exct = FALSE,   kripp = FALSE,   krippMethod = \"nominal\",   bootstrap = FALSE,   icc = FALSE,   iccType = \"ICC2\",   pathologyContext = FALSE,   diagnosisVar = NULL,   confidenceLevel = 0.95,   minAgreement = 0.6,   showInterpretation = TRUE,   outlierAnalysis = FALSE,   pairwiseAnalysis = FALSE,   categoryAnalysis = FALSE,   diagnosticStyleAnalysis = FALSE,   styleClusterMethod = \"ward\",   styleDistanceMetric = \"agreement\",   numberOfStyleGroups = 3,   identifyDiscordantCases = FALSE,   raterCharacteristics = FALSE,   experienceVar = NULL,   trainingVar = NULL,   institutionVar = NULL,   specialtyVar = NULL )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreement.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Interrater Reliability — agreement",
        "text": "data data data frame. row represents case/subject, columns represent different raters/observers. vars Variables representing different raters/observers. variable contain ratings/diagnoses  given observer set cases. sft Show frequency tables rater cross-tabulation tables pairwise comparisons. heatmap Show agreement heatmap visualization color-coded agreement levels. heatmapDetails Show detailed heatmap kappa values confidence intervals rater pairs. wght Weighting scheme kappa analysis. Use 'squared' 'equal' ordinal variables. Weighted kappa accounts degree disagreement. exct Use exact method Fleiss' kappa calculation 3 raters. accurate computationally intensive. kripp Calculate Krippendorff's alpha, generalized measure reliability number observers data types. krippMethod Measurement level Krippendorff's alpha calculation. Choose based data type. bootstrap Calculate bootstrap confidence intervals Krippendorff's alpha (1000 bootstrap samples). icc Calculate ICC continuous ordinal data. Appropriate quantitative measurements. iccType Type ICC calculate. Choose based study design measurement model. pathologyContext Enable pathology-specific analysis including diagnostic accuracy metrics clinical interpretation. diagnosisVar Gold standard consensus diagnosis calculating diagnostic accuracy individual raters. confidenceLevel Confidence level confidence intervals (default 95\\ minAgreementMinimum kappa value considered acceptable agreement (default 0.6). showInterpretationDisplay interpretation guidelines kappa values ICC coefficients. outlierAnalysisIdentify cases consistently poor agreement across raters. pairwiseAnalysisDetailed analysis agreement pair raters. categoryAnalysisAnalysis agreement diagnostic category separately. diagnosticStyleAnalysisIdentify diagnostic \"schools\" \"styles\" among pathologists using hierarchical clustering  based diagnostic patterns. reveals whether pathologists cluster experience, training, geographic region, diagnostic philosophy. styleClusterMethodHierarchical clustering method identifying diagnostic styles. Ward's linkage  used original Usubutun et al. 2012 study. styleDistanceMetricDistance metric style clustering. Percentage agreement used original study. numberOfStyleGroupsNumber diagnostic style groups identify. Original study found 3 distinct styles. identifyDiscordantCasesIdentify specific cases distinguish different diagnostic style groups. raterCharacteristicsInclude analysis rater characteristics (experience, training, institution)  relation diagnostic styles. experienceVarVariable indicating years experience experience level rater. trainingVarVariable indicating training institution background rater. institutionVarVariable indicating current practice institution rater. specialtyVarVariable indicating specialty (e.g., generalist vs specialist) rater. results object containing:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "Comprehensive interrater reliability analysis designed pathology applications. Includes Cohen's kappa, Fleiss' kappa, ICC, Krippendorff's alpha, pathology-specific metrics.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "jmvcore::Analysis -> meddecide::agreementBase -> agreementClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::agreementBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "agreementClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "",
        "code": "agreementClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/agreementClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Comprehensive Interrater Reliability Analysis — agreementClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/auc_ci.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Statistical Utility Functions — auc_ci",
        "title": "Statistical Utility Functions — auc_ci",
        "text": "Functions calculating confidence intervals test statistics Calculate AUC confidence intervals Functions calculating confidence intervals test statistics Calculate AUC confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/auc_ci.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Statistical Utility Functions — auc_ci",
        "text": "",
        "code": "auc_ci(auc, n_pos, n_neg, conf_level = 0.95)  auc_ci(auc, n_pos, n_neg, conf_level = 0.95)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/auc_ci.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Statistical Utility Functions — auc_ci",
        "text": "auc Area curve value n_pos Number positive cases n_neg Number negative cases conf_level Confidence level (default 0.95)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/auc_ci.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Statistical Utility Functions — auc_ci",
        "text": "Vector containing lower upper CI bounds Vector containing lower upper CI bounds",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapIDI.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Bootstrap IDI calculation with confidence intervals — bootstrapIDI",
        "title": "Bootstrap IDI calculation with confidence intervals — bootstrapIDI",
        "text": "Calculates Integrated Discrimination Improvement bootstrap confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapIDI.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Bootstrap IDI calculation with confidence intervals — bootstrapIDI",
        "text": "",
        "code": "bootstrapIDI(   new_values,   ref_values,   actual,   direction = \">=\",   n_boot = 1000,   conf_level = 0.95 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapIDI.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Bootstrap IDI calculation with confidence intervals — bootstrapIDI",
        "text": "new_values Test values new test ref_values Test values reference test actual Binary outcome vector (0/1) direction Classification direction (\">=\" \"<=\") n_boot Number bootstrap iterations conf_level Confidence level (default 0.95)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapIDI.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Bootstrap IDI calculation with confidence intervals — bootstrapIDI",
        "text": "List IDI, confidence intervals, p-value",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapNRI.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Bootstrap NRI calculation with confidence intervals — bootstrapNRI",
        "title": "Bootstrap NRI calculation with confidence intervals — bootstrapNRI",
        "text": "Bootstrap NRI calculation confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapNRI.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Bootstrap NRI calculation with confidence intervals — bootstrapNRI",
        "text": "",
        "code": "bootstrapNRI(   new_values,   ref_values,   actual,   direction = \">=\",   thresholds = NULL,   n_boot = 1000,   conf_level = 0.95 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapNRI.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Bootstrap NRI calculation with confidence intervals — bootstrapNRI",
        "text": "new_values Test values new test ref_values Test values reference test actual Binary outcome vector (0/1) direction Classification direction (\">=\" \"<=\") thresholds Risk category thresholds (NULL continuous NRI) n_boot Number bootstrap iterations conf_level Confidence level (default 0.95)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrapNRI.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Bootstrap NRI calculation with confidence intervals — bootstrapNRI",
        "text": "List NRI components confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrap_ci.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Bootstrap confidence intervals for diagnostic metrics — bootstrap_ci",
        "title": "Bootstrap confidence intervals for diagnostic metrics — bootstrap_ci",
        "text": "Bootstrap confidence intervals diagnostic metrics Bootstrap confidence intervals diagnostic metrics",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrap_ci.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Bootstrap confidence intervals for diagnostic metrics — bootstrap_ci",
        "text": "",
        "code": "bootstrap_ci(data, metric, R = 1000)  bootstrap_ci(data, metric, R = 1000)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrap_ci.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Bootstrap confidence intervals for diagnostic metrics — bootstrap_ci",
        "text": "data Data frame containing test results metric Function calculate desired metric R Number bootstrap iterations",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/bootstrap_ci.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Bootstrap confidence intervals for diagnostic metrics — bootstrap_ci",
        "text": "List containing point estimate confidence intervals List containing point estimate confidence intervals",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_auc.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate AUC from sensitivity and specificity — calculate_auc",
        "title": "Calculate AUC from sensitivity and specificity — calculate_auc",
        "text": "Uses formula shown package documentation example: 0.5 * (sens * (1 - spec)) + 0.5 * (1 * (1 - (1 - spec))) + 0.5 * ((1 - sens) * spec). Uses simplified formula approximate AUC sensitivity specificity",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_auc.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate AUC from sensitivity and specificity — calculate_auc",
        "text": "",
        "code": "calculate_auc(sens, spec)  calculate_auc(sens, spec)  calculate_auc(sens, spec)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_auc.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate AUC from sensitivity and specificity — calculate_auc",
        "text": "sens Sensitivity test spec Specificity test",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_auc.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate AUC from sensitivity and specificity — calculate_auc",
        "text": "Area ROC curve Numeric AUC value NA inputs valid. Numeric AUC value NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_nlr.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate negative likelihood ratio — calculate_nlr",
        "title": "Calculate negative likelihood ratio — calculate_nlr",
        "text": "Calculates negative likelihood ratio sensitivity specificity",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_nlr.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate negative likelihood ratio — calculate_nlr",
        "text": "",
        "code": "calculate_nlr(sens, spec)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_nlr.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate negative likelihood ratio — calculate_nlr",
        "text": "sens Sensitivity value spec Specificity value",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_nlr.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate negative likelihood ratio — calculate_nlr",
        "text": "Numeric negative likelihood ratio NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_npv.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate negative predictive value (NPV) — calculate_npv",
        "title": "Calculate negative predictive value (NPV) — calculate_npv",
        "text": "Calculates NPV confusion matrix values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_npv.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate negative predictive value (NPV) — calculate_npv",
        "text": "",
        "code": "calculate_npv(tn, fn)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_npv.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate negative predictive value (NPV) — calculate_npv",
        "text": "tn Number true negatives fn Number false negatives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_npv.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate negative predictive value (NPV) — calculate_npv",
        "text": "Numeric NPV value NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_plr.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate positive likelihood ratio — calculate_plr",
        "title": "Calculate positive likelihood ratio — calculate_plr",
        "text": "Calculates positive likelihood ratio sensitivity specificity",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_plr.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate positive likelihood ratio — calculate_plr",
        "text": "",
        "code": "calculate_plr(sens, spec)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_plr.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate positive likelihood ratio — calculate_plr",
        "text": "sens Sensitivity value spec Specificity value",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_plr.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate positive likelihood ratio — calculate_plr",
        "text": "Numeric positive likelihood ratio NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_ppv.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate positive predictive value (PPV) — calculate_ppv",
        "title": "Calculate positive predictive value (PPV) — calculate_ppv",
        "text": "Calculates PPV confusion matrix values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_ppv.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate positive predictive value (PPV) — calculate_ppv",
        "text": "",
        "code": "calculate_ppv(tp, fp)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_ppv.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate positive predictive value (PPV) — calculate_ppv",
        "text": "tp Number true positives fp Number false positives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_ppv.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate positive predictive value (PPV) — calculate_ppv",
        "text": "Numeric PPV value NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_sensitivity.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate diagnostic sensitivity — calculate_sensitivity",
        "title": "Calculate diagnostic sensitivity — calculate_sensitivity",
        "text": "Utility functions basic diagnostic test statistics. Calculates sensitivity (true positive rate) confusion matrix values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_sensitivity.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate diagnostic sensitivity — calculate_sensitivity",
        "text": "",
        "code": "calculate_sensitivity(tp, fn)  calculate_sensitivity(tp, fn)  calculate_sensitivity(tp, fn)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_sensitivity.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate diagnostic sensitivity — calculate_sensitivity",
        "text": "tp Number true positives fn Number false negatives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_sensitivity.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate diagnostic sensitivity — calculate_sensitivity",
        "text": "Sensitivity proportion Numeric sensitivity value NA inputs valid. Numeric sensitivity value NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_specificity.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Calculate diagnostic specificity — calculate_specificity",
        "title": "Calculate diagnostic specificity — calculate_specificity",
        "text": "Calculates specificity (true negative rate) confusion matrix values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_specificity.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Calculate diagnostic specificity — calculate_specificity",
        "text": "",
        "code": "calculate_specificity(tn, fp)  calculate_specificity(tn, fp)  calculate_specificity(tn, fp)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_specificity.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Calculate diagnostic specificity — calculate_specificity",
        "text": "tn Number true negatives fp Number false positives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/calculate_specificity.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Calculate diagnostic specificity — calculate_specificity",
        "text": "Specificity proportion Numeric specificity value NA inputs valid. Numeric specificity value NA inputs valid",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/clinicopath_startup_message.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Package startup message — clinicopath_startup_message",
        "title": "Package startup message — clinicopath_startup_message",
        "text": "Displays information package author website",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/clinicopath_startup_message.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Package startup message — clinicopath_startup_message",
        "text": "",
        "code": "clinicopath_startup_message()"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/clinicopath_startup_message.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Package startup message — clinicopath_startup_message",
        "text": "Invisible NULL (called side effects)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/computeNRI.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Compute Net Reclassification Index (NRI) — computeNRI",
        "title": "Compute Net Reclassification Index (NRI) — computeNRI",
        "text": "Compute Net Reclassification Index (NRI)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/computeNRI.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Compute Net Reclassification Index (NRI) — computeNRI",
        "text": "",
        "code": "computeNRI(new_values, ref_values, actual, direction = \">=\", thresholds = NULL)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/computeNRI.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Compute Net Reclassification Index (NRI) — computeNRI",
        "text": "new_values Test values new test ref_values Test values reference test actual Binary outcome vector (0/1) direction Classification direction thresholds Risk category thresholds (NULL continuous NRI)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/computeNRI.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Compute Net Reclassification Index (NRI) — computeNRI",
        "text": "List containing NRI components",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decision.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Medical Decision — decision",
        "title": "Medical Decision — decision",
        "text": "Function Medical Decision Analysis. Sensitivity, specificity, positive predictive value, negative predictive value.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decision.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Medical Decision — decision",
        "text": "",
        "code": "decision(   data,   gold,   goldPositive,   newtest,   testPositive,   pp = FALSE,   pprob = 0.3,   od = FALSE,   fnote = FALSE,   ci = FALSE,   fagan = FALSE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decision.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Medical Decision — decision",
        "text": "data data data frame. data frame contain variables specified 'variables' option. gold golden standard variable. goldPositive positive level golden standard variable. newtest new test variable. testPositive positive level new test variable. pp Boolean selection whether show prior probability. Default 'false'. pprob Prior probability (disease prevalence community). Requires value 0.001 0.999, default 0.300. od Boolean selection whether show frequency table. Default 'false'. fnote Boolean selection whether show footnotes. Default 'false'. ci Boolean selection whether show 95\\ Default 'false'. fagan Boolean selection whether show Fagan Nomogram. Default 'false'.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decision.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Medical Decision — decision",
        "text": "results object containing: Tables can converted data frames asDF .data.frame. example: results$cTable$asDF .data.frame(results$cTable)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decision.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Medical Decision — decision",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Medical Decision Analysis — decisionClass",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "Implements comprehensive medical decision analysis including:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "details",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Details",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "module provides tools analyzing diagnostic test performance options various visualization methods statistical comparisons. Sensitivity, specificity predictive values",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "Provide test reference standard data Select analysis options View results tables plots",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "jmvcore::Analysis -> meddecide::decisionBase -> decisionClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::decisionBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "decisionClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "usage-1",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "",
        "code": "decisionClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisionClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Medical Decision Analysis — decisionClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculator.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Medical Decision Calculator — decisioncalculator",
        "title": "Medical Decision Calculator — decisioncalculator",
        "text": "Medical Decision Calculator diagnostic test evaluation four key counts: True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN). Calculates comprehensive diagnostic performance metrics including sensitivity, specificity, positive negative predictive values, likelihood ratios, post-test probabilities. Supports confidence interval estimation Fagan nomogram visualization clinical decision making.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculator.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Medical Decision Calculator — decisioncalculator",
        "text": "",
        "code": "decisioncalculator(   TP = 90,   TN = 80,   FP = 30,   FN = 20,   pp = FALSE,   pprob = 0.3,   fnote = FALSE,   ci = FALSE,   fagan = FALSE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculator.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Medical Decision Calculator — decisioncalculator",
        "text": "TP . TN . FP . FN . pp . pprob Prior probability (disease prevalence community). Requires value 0.001 0.999, default 0.300. fnote . ci . fagan .",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculator.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Medical Decision Calculator — decisioncalculator",
        "text": "results object containing: Tables can converted data frames asDF .data.frame. example: results$cTable$asDF .data.frame(results$cTable)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculator.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Medical Decision Calculator — decisioncalculator",
        "text": "",
        "code": "# Basic diagnostic test evaluation with known counts result1 <- decisioncalculator(   TP = 90,  # True positives   FN = 10,  # False negatives   TN = 80,  # True negatives   FP = 20   # False positives )  # Include 95\\% confidence intervals result2 <- decisioncalculator(   TP = 90, FN = 10, TN = 80, FP = 20,   ci = TRUE )  # Complete analysis with Fagan nomogram result3 <- decisioncalculator(   TP = 90, FN = 10, TN = 80, FP = 20,   ci = TRUE, pp = TRUE, pprob = 0.15, fagan = TRUE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Decision Calculator — decisioncalculatorClass",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "Decision Calculator Decision Calculator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "jmvcore::Analysis -> meddecide::decisioncalculatorBase -> decisioncalculatorClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::decisioncalculatorBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "decisioncalculatorClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "",
        "code": "decisioncalculatorClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncalculatorClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Decision Calculator — decisioncalculatorClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompare.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Compare Medical Decision Tests — decisioncompare",
        "title": "Compare Medical Decision Tests — decisioncompare",
        "text": "Function comparing multiple Medical Decision Tests. Compares sensitivity, specificity, positive predictive value, negative predictive value, metrics different tests golden standard. Includes statistical comparison using McNemar's test confidence intervals differences.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompare.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Compare Medical Decision Tests — decisioncompare",
        "text": "",
        "code": "decisioncompare(   data,   gold,   goldPositive,   test1,   test1Positive,   test2,   test2Positive,   test3,   test3Positive,   pp = FALSE,   pprob = 0.3,   od = FALSE,   fnote = FALSE,   ci = FALSE,   plot = FALSE,   statComp = FALSE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompare.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Compare Medical Decision Tests — decisioncompare",
        "text": "data data data frame. gold . goldPositive . test1 . test1Positive . test2 . test2Positive . test3 . test3Positive . pp . pprob Prior probability (disease prevalence community). Requires value 0.001 0.999, default 0.300. od Boolean selection whether show frequency tables. Default 'false'. fnote . ci . plot . statComp Perform statistical comparison tests (McNemar's test confidence intervals differences).",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompare.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Compare Medical Decision Tests — decisioncompare",
        "text": "results object containing: Tables can converted data frames asDF .data.frame. example: results$cTable1$asDF .data.frame(results$cTable1)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompare.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Compare Medical Decision Tests — decisioncompare",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Compare Medical Decision Tests — decisioncompareClass",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "Compare Medical Decision Tests Compare Medical Decision Tests",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "jmvcore::Analysis -> meddecide::decisioncompareBase -> decisioncompareClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::decisioncompareBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "decisioncompareClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "",
        "code": "decisioncompareClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/decisioncompareClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Compare Medical Decision Tests — decisioncompareClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/is_in_range.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Check if value is within valid range — is_in_range",
        "title": "Check if value is within valid range — is_in_range",
        "text": "Validates value within specified bounds",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/is_in_range.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Check if value is within valid range — is_in_range",
        "text": "",
        "code": "is_in_range(x, min_val, max_val, inclusive = TRUE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/is_in_range.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Check if value is within valid range — is_in_range",
        "text": "x Value check min_val Minimum allowed value max_val Maximum allowed value inclusive Whether bounds inclusive",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/is_in_range.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Check if value is within valid range — is_in_range",
        "text": "Logical indicating value within range",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCI.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "text": "Power Analysis Interobserver Agreement Analysis.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCI.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "text": "",
        "code": "kappaSizeCI(   outcome = \"2\",   kappa0 = 0.6,   kappaL = 0.4,   kappaU = 0.8,   props = \"0.20 , 0.80\",   raters = \"2\",   alpha = 0.05 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCI.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "text": "outcome Number outcome level. kappa0 null hypothesis value kappa. kappaL lower limit kappa. kappaU upper limit kappa. props Proportions outcome level. raters Number raters. alpha significance level.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCI.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "text": "results object containing:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCI.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCI",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "Confidence Interval Approach Number Subjects Required Confidence Interval Approach Number Subjects Required",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "jmvcore::Analysis -> meddecide::kappaSizeCIBase -> kappaSizeCIClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::kappaSizeCIBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "kappaSizeCIClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "",
        "code": "kappaSizeCIClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeCIClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Confidence Interval Approach for the Number of Subjects Required — kappaSizeCIClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedN.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "text": "Lowest Expected Value fixed sample size.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedN.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "text": "",
        "code": "kappaSizeFixedN(   outcome = \"2\",   kappa0 = 0.4,   props = \"0.20 , 0.80\",   raters = \"2\",   alpha = 0.05,   n = 100 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedN.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "text": "outcome Number outcome level. kappa0 Expected value kappa. props Proportions outcome level. raters Number raters. alpha Significance level. n Sample size.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedN.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "text": "results object containing:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedN.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedN",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "Lowest Expected Value fixed sample size Lowest Expected Value fixed sample size",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "jmvcore::Analysis -> meddecide::kappaSizeFixedNBase -> kappaSizeFixedNClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::kappaSizeFixedNBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "kappaSizeFixedNClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "",
        "code": "kappaSizeFixedNClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizeFixedNClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Lowest Expected Value for a fixed sample size — kappaSizeFixedNClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePower.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "text": "Power Analysis Interobserver Agreement Analysis.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePower.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "text": "",
        "code": "kappaSizePower(   outcome = \"2\",   kappa0 = 0.4,   kappa1 = 0.6,   props = \"0.20 , 0.80\",   raters = \"2\",   alpha = 0.05,   power = 0.8 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePower.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "text": "outcome Number outcome level. kappa0 Expected value kappa. kappa1 Expected value kappa. props Proportions outcome level. raters Number raters. alpha Significance level. power Power.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePower.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "text": "results object containing:",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePower.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePower",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "Power Approach Number Subjects Required Power Approach Number Subjects Required",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "jmvcore::Analysis -> meddecide::kappaSizePowerBase -> kappaSizePowerClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::kappaSizePowerBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "kappaSizePowerClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "",
        "code": "kappaSizePowerClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/kappaSizePowerClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Power Approach for the Number of Subjects Required — kappaSizePowerClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/load_required_package.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Load required packages with error handling — load_required_package",
        "title": "Load required packages with error handling — load_required_package",
        "text": "Load required packages error handling",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/load_required_package.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Load required packages with error handling — load_required_package",
        "text": "",
        "code": "load_required_package(package_name, install_if_missing = TRUE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/load_required_package.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Load required packages with error handling — load_required_package",
        "text": "package_name Character string package name install_if_missing Logical, whether install package missing",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/load_required_package.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Load required packages with error handling — load_required_package",
        "text": "Logical indicating success",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/meddecide-package.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Functions for Medical Decision Making in ClinicoPath jamovi Module — meddecide-package",
        "title": "Functions for Medical Decision Making in ClinicoPath jamovi Module — meddecide-package",
        "text": "meddecide meddecide help researchers generate natural language summaries dataset, generate cross tables statistical tests, survival analysis survival tables, survival plots, natural language summaries. documentation, see Website.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/meddecide-package.html",
        "id": "details",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Details",
        "title": "Functions for Medical Decision Making in ClinicoPath jamovi Module — meddecide-package",
        "text": "meddecide",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/meddecide-package.html",
        "id": "author",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Author",
        "title": "Functions for Medical Decision Making in ClinicoPath jamovi Module — meddecide-package",
        "text": "Maintainer: Serdar Balci drserdarbalci@gmail.com (ORCID)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/na-coalescing.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "NA-coalescing operator — na-coalescing",
        "title": "NA-coalescing operator — na-coalescing",
        "text": "NA-coalescing operator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/na-coalescing.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "NA-coalescing operator — na-coalescing",
        "text": "",
        "code": "lhs %|% rhs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandard.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Analysis Without Gold Standard — nogoldstandard",
        "title": "Analysis Without Gold Standard — nogoldstandard",
        "text": "Analysis diagnostic tests without gold standard reference",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandard.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Analysis Without Gold Standard — nogoldstandard",
        "text": "",
        "code": "nogoldstandard(   data,   test1,   test1Positive,   test2,   test2Positive,   test3,   test3Positive,   test4,   test4Positive,   test5,   test5Positive,   method = \"latent_class\",   bootstrap = FALSE,   nboot = 1000,   alpha = 0.05 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandard.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Analysis Without Gold Standard — nogoldstandard",
        "text": "data data data frame. test1 First diagnostic test variable. test1Positive positive level Test 1. test2 Second diagnostic test variable. test2Positive positive level Test 2. test3 Third diagnostic test variable (optional). test3Positive positive level Test 3. test4 Fourth diagnostic test variable (optional). test4Positive positive level Test 4. test5 Fifth diagnostic test variable (optional). test5Positive positive level Test 5. method Method analyzing tests without gold standard. bootstrap Calculate bootstrap confidence intervals. nboot Number bootstrap samples confidence intervals. alpha Alpha level confidence intervals.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandard.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Analysis Without Gold Standard — nogoldstandard",
        "text": "results object containing: Tables can converted data frames asDF .data.frame. example: results$prevalence$asDF .data.frame(results$prevalence)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandard.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Analysis Without Gold Standard — nogoldstandard",
        "text": "",
        "code": "# \\donttest{ # example will be added # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Analysis Without Gold Standard — nogoldstandardClass",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "Analysis Without Gold Standard Analysis Without Gold Standard",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "jmvcore::Analysis -> meddecide::nogoldstandardBase -> nogoldstandardClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::nogoldstandardBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "nogoldstandardClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "",
        "code": "nogoldstandardClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nogoldstandardClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Analysis Without Gold Standard — nogoldstandardClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "Creates Fagan nomograms Bayesian analysis diagnostic testing. Fagan nomogram graphical tool used estimate post-test probabilities pre-test probabilities likelihood ratios. function supports input via sensitivity/specificity directly via likelihood ratios.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "",
        "code": "nomogrammer(   Prevalence,   Sens = NULL,   Spec = NULL,   Plr = NULL,   Nlr = NULL,   Detail = FALSE,   NullLine = FALSE,   LabelSize = (14/5),   Verbose = FALSE )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "Prevalence Prior probability (prevalence) number 0 1. represents probability disease test performed. Sens Model sensitivity number 0 1. probability test positive disease present. Optional Plr/Nlr provided. Spec Model specificity number 0 1. probability test negative disease absent. Optional Plr/Nlr provided. Plr Positive likelihood ratio (calculated Sens Spec provided). Must >= 1. provided along Nlr, takes precedence Sens/Spec. Nlr Negative likelihood ratio (calculated Sens Spec provided). Must 0 1. provided along Plr, takes precedence Sens/Spec. Detail Logical. TRUE, overlays key statistics (prevalence, likelihood ratios, posterior probabilities) onto plot. NullLine Logical. TRUE, adds reference line prior probability LR = 1 illustrate uninformative test. LabelSize Numeric. Controls size text labels plot. Default 14/5 ≈ 2.8. Verbose Logical. TRUE, prints diagnostic metrics console.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "ggplot2 object containing Fagan nomogram. plot shows: Left axis: Prior probability (prevalence) percentages Middle axis: Likelihood ratios Right axis: Posterior probability percentages Red line: Positive test pathway Blue line: Negative test pathway",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "details",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Details",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "Fagan nomogram visually represents Bayes' theorem diagnostic testing: $$Post-test odds = Pre-test odds × Likelihood ratio$$ function accepts either: Sensitivity Specificity (traditional approach) Positive Negative Likelihood Ratios (direct approach) provided, sensitivity/specificity take precedence warning issued. Mathematical relationships: PLR = Sensitivity / (1 - Specificity) NLR = (1 - Sensitivity) / Specificity calculating LRs: Specificity = (PLR - 1) / (PLR - NLR) calculating LRs: Sensitivity = PLR × (1 - Specificity) Post-test probability (+) = (Prevalence × PLR) / ((Prevalence × PLR) + (1 - Prevalence)) Post-test probability (-) = (Prevalence × NLR) / ((Prevalence × NLR) + (1 - Prevalence))",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "note",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Note",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "function used internally decision analysis ClinicoPath jamovi module generating Fagan nomograms.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "references",
        "dir": "Reference",
        "previous_headings": "",
        "what": "References",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "Fagan TJ. Letter: Nomogram Bayes theorem. N Engl J Med. 1975;293(5):257. Based Perl web-implementation: https://araw.mede.uic.edu/cgi-bin/testcalc.pl Authors: .M. Chekroud & . Schwartz, December 2016",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "author",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Author",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "ClinicoPath Development Team",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/nomogrammer.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Fagan Nomogram for Diagnostic Test Analysis — nomogrammer",
        "text": "",
        "code": "# Example 1: Using sensitivity and specificity nomogrammer(Prevalence = 0.3, Sens = 0.9, Spec = 0.8)   # Example 2: Using likelihood ratios directly nomogrammer(Prevalence = 0.3, Plr = 4.5, Nlr = 0.125)   # Example 3: With detailed annotations and null line nomogrammer(Prevalence = 0.1, Sens = 0.95, Spec = 0.85,              Detail = TRUE, NullLine = TRUE, Verbose = TRUE) #>  #> === Fagan Nomogram Results === #> Prevalence = 10%  #> Sensitivity = 95%  #> Specificity = 85%  #> Positive LR = 6.33  #> Negative LR = 0.0588  #> Post-test probability (positive test) = 41%  #> Post-test probability (negative test) = 1%  #> ===============================   # Example 4: Low prevalence scenario (screening test) nomogrammer(Prevalence = 0.01, Sens = 0.99, Spec = 0.95, Detail = TRUE) #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`)."
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/not-in-alt.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Alternative not-in operator — not-in-alt",
        "title": "Alternative not-in operator — not-in-alt",
        "text": "Alternative -operator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/not-in-alt.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Alternative not-in operator — not-in-alt",
        "text": "",
        "code": "lhs %!in% rhs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/not-in.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Not-in operator — not-in",
        "title": "Not-in operator — not-in",
        "text": "-operator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/not-in.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Not-in operator — not-in",
        "text": "",
        "code": "lhs %notin% rhs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/null-coalescing.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Null-coalescing operator — null-coalescing",
        "title": "Null-coalescing operator — null-coalescing",
        "text": "Null-coalescing operator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/null-coalescing.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Null-coalescing operator — null-coalescing",
        "text": "",
        "code": "lhs %||% rhs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/pipe.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Pipe operator — %>%",
        "title": "Pipe operator — %>%",
        "text": "Pipe operator",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/pipe.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Pipe operator — %>%",
        "text": "",
        "code": "lhs %>% rhs"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/print.sensSpecTable.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Print formatted HTML table for sensitivity/specificity results — print.sensSpecTable",
        "title": "Print formatted HTML table for sensitivity/specificity results — print.sensSpecTable",
        "text": "Creates HTML table confusion matrix visualization",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/print.sensSpecTable.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Print formatted HTML table for sensitivity/specificity results — print.sensSpecTable",
        "text": "",
        "code": "# S3 method for class 'sensSpecTable' print(Title, TP, FP, TN, FN)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/print.sensSpecTable.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Print formatted HTML table for sensitivity/specificity results — print.sensSpecTable",
        "text": "Title Title confusion matrix table TP Number true positives FP Number false positives TN Number true negatives FN Number false negatives",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/print.sensSpecTable.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Print formatted HTML table for sensitivity/specificity results — print.sensSpecTable",
        "text": "HTML string containing formatted table",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/prop_to_percent.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Convert proportion to percentage string — prop_to_percent",
        "title": "Convert proportion to percentage string — prop_to_percent",
        "text": "Converts numeric proportion formatted percentage",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/prop_to_percent.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Convert proportion to percentage string — prop_to_percent",
        "text": "",
        "code": "prop_to_percent(x, digits = 1)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/prop_to_percent.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Convert proportion to percentage string — prop_to_percent",
        "text": "x Numeric proportion (0-1) digits Number decimal places",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/prop_to_percent.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Convert proportion to percentage string — prop_to_percent",
        "text": "Character string percentage formatting",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROC.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "ROC Analysis — psychopdaROC",
        "title": "ROC Analysis — psychopdaROC",
        "text": "Receiver Operating Characteristic (ROC) curve analysis optimal cutpoint determination.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROC.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "ROC Analysis — psychopdaROC",
        "text": "",
        "code": "psychopdaROC(   data,   dependentVars,   classVar,   positiveClass,   subGroup,   method = \"maximize_metric\",   metric = \"youden\",   direction = \">=\",   specifyCutScore = \"\",   tol_metric = 0.05,   break_ties = \"mean\",   allObserved = FALSE,   boot_runs = 0,   usePriorPrev = FALSE,   priorPrev = 0.5,   costratioFP = 1,   sensSpecTable = FALSE,   showThresholdTable = FALSE,   maxThresholds = 20,   delongTest = FALSE,   plotROC = TRUE,   combinePlots = TRUE,   cleanPlot = FALSE,   showOptimalPoint = TRUE,   displaySE = FALSE,   smoothing = FALSE,   showConfidenceBands = FALSE,   legendPosition = \"right\",   directLabel = FALSE,   interactiveROC = FALSE,   showCriterionPlot = FALSE,   showPrevalencePlot = FALSE,   showDotPlot = FALSE,   precisionRecallCurve = FALSE,   partialAUC = FALSE,   partialAUCfrom = 0.8,   partialAUCto = 1,   rocSmoothingMethod = \"none\",   bootstrapCI = FALSE,   bootstrapReps = 2000,   quantileCIs = FALSE,   quantiles = \"0.1,0.25,0.5,0.75,0.9\",   compareClassifiers = FALSE,   calculateIDI = FALSE,   calculateNRI = FALSE,   refVar,   nriThresholds = \"\",   idiNriBootRuns = 1000 )"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROC.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "ROC Analysis — psychopdaROC",
        "text": "data data data frame. dependentVars Test variable(s) evaluated classification performance. Multiple variables can selected comparison. classVar Binary classification variable representing true class (gold standard). Must exactly two levels. positiveClass Specifies level class variable treated positive class. subGroup Optional grouping variable stratified analysis.  ROC curves calculated separately group. method Method determining optimal cutpoint. Different methods optimize different aspects classifier performance. metric Metric optimize determining cutpoint.  applies maximize/minimize methods. direction Direction classification relative cutpoint. Use '>=' higher test values indicate positive class. specifyCutScore Specific cutpoint value use method set 'Manual cutpoint'. tol_metric Tolerance metric value multiple cutpoints yield similar performance. Cutpoints within tolerance considered equivalent. break_ties Method handling ties multiple cutpoints achieve metric value. allObserved Display performance metrics observed test values potential cutpoints, just optimal cutpoint. boot_runs Number bootstrap iterations methods using bootstrapping. Set 0 disable bootstrapping. usePriorPrev Use specified prior prevalence instead sample prevalence calculating predictive values. priorPrev Population prevalence use predictive value calculations. used 'Use Prior Prevalence' checked. costratioFP Relative cost false positives compared false negatives. Values > 1 penalize false positives heavily. sensSpecTable Display detailed confusion matrices optimal cutpoints. showThresholdTable Display detailed table performance metrics multiple thresholds. maxThresholds Maximum number threshold values show threshold table. delongTest Perform DeLong's test comparing AUCs multiple test variables. Requires least two test variables. plotROC Display ROC curves visual assessment classifier performance. combinePlots multiple test variables selected, combine ROC curves single plot. cleanPlot Create clean ROC curves without annotations, suitable publications. showOptimalPoint Display optimal cutpoint ROC curve. displaySE Display standard error bands ROC curves (LOESS smoothing applied). smoothing Apply LOESS smoothing ROC curves visualization. showConfidenceBands Display confidence bands around ROC curve. legendPosition Position legend plots multiple ROC curves. directLabel Label curves directly plot instead using legend. interactiveROC Create interactive HTML ROC plot (requires plotROC package). showCriterionPlot Plot showing sensitivity specificity change across different thresholds. showPrevalencePlot Plot showing PPV NPV change disease prevalence. showDotPlot Dot plot showing distribution test values class. precisionRecallCurve Display precision-recall curves alongside ROC curves. partialAUC Calculate AUC specific region ROC curve. partialAUCfrom Lower bound specificity range partial AUC calculation. partialAUCto Upper bound specificity range partial AUC calculation. rocSmoothingMethod Method smoothing ROC curve (requires pROC package). bootstrapCI Calculate bootstrap confidence intervals AUC optimal cutpoints. bootstrapReps Number bootstrap replications confidence interval calculation. quantileCIs Display confidence intervals specific quantiles test variable. quantiles Comma-separated list quantiles (0-1) display confidence intervals. compareClassifiers Perform comprehensive comparison classifier performance metrics. calculateIDI Calculate Integrated Discrimination Improvement model comparison. calculateNRI Calculate Net Reclassification Index model comparison. refVar Reference test variable IDI NRI calculations. variables compared reference. nriThresholds Comma-separated probability thresholds (0-1) defining risk categories NRI. Leave empty continuous NRI. idiNriBootRuns Number bootstrap iterations IDI NRI confidence intervals.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROC.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "ROC Analysis — psychopdaROC",
        "text": "results object containing: Tables can converted data frames asDF .data.frame. example: results$simpleResultsTable$asDF .data.frame(results$simpleResultsTable)",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "Performs sophisticated Receiver Operating Characteristic (ROC) curve analysis optimal cutpoint determination, multiple comparison methods, advanced statistical features including IDI/NRI calculations, DeLong test, comprehensive visualization options.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "psychopdarocResults object containing: resultsTable: Detailed results threshold simpleResultsTable: Summary AUC results confidence intervals sensSpecTable: Confusion matrix optimal cutpoint plotROC: ROC curve visualization delongTest: DeLong test results (requested) idiTable: IDI results confidence intervals (requested) nriTable: NRI results confidence intervals (requested) Additional plots tables based options selected",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "details",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Details",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "function provides extensive ROC analysis toolkit goes beyond basic ROC curve generation. Key features include: Core ROC Analysis: AUC calculation confidence intervals Multiple cutpoint optimization methods (12 different approaches) 16 different optimization metrics (Youden, accuracy, F1, etc.) Bootstrap confidence intervals Manual cutpoint specification Advanced Statistical Methods: DeLong test comparing multiple AUCs IDI (Integrated Discrimination Index) bootstrap CI NRI (Net Reclassification Index) bootstrap CI Partial AUC calculations ROC curve smoothing (multiple methods) Classifier performance comparison Visualization Options: ROC curves (individual combined) Sensitivity/specificity vs threshold plots Predictive value vs prevalence plots Precision-recall curves Dot plots showing class distributions Interactive ROC plots Confidence bands quantile confidence intervals Subgroup Analysis: Stratified analysis grouping variables Cost-benefit optimization custom cost ratios Hospital/site comparisons",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "note",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Note",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "function originally developed Lucas Friesen psychoPDA module. Enhanced version additional features added ClinicoPath module.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "references",
        "dir": "Reference",
        "previous_headings": "",
        "what": "References",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "DeLong, E. R., DeLong, D. M., & Clarke-Pearson, D. L. (1988). Comparing areas two correlated receiver operating characteristic curves: nonparametric approach. Biometrics, 44(3), 837-845. Pencina, M. J., D'Agostino, R. B., D'Agostino, R. B., & Vasan, R. S. (2008). Evaluating added predictive ability new marker: area ROC curve reclassification beyond. Statistics Medicine, 27(2), 157-172. Youden, W. J. (1950). Index rating diagnostic tests. Cancer, 3(1), 32-35.",
        "code": ""
    },
    {
        "path": []
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "super-classes",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Super classes",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "jmvcore::Analysis -> meddecide::psychopdaROCBase -> psychopdaROCClass",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Methods",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "jmvcore::Analysis$.createImage() jmvcore::Analysis$.createImages() jmvcore::Analysis$.createPlotObject() jmvcore::Analysis$.load() jmvcore::Analysis$.render() jmvcore::Analysis$.save() jmvcore::Analysis$.savePart() jmvcore::Analysis$.setCheckpoint() jmvcore::Analysis$.setParent() jmvcore::Analysis$.setReadDatasetHeaderSource() jmvcore::Analysis$.setReadDatasetSource() jmvcore::Analysis$.setResourcesPathSource() jmvcore::Analysis$.setStatePathSource() jmvcore::Analysis$addAddon() jmvcore::Analysis$asProtoBuf() jmvcore::Analysis$asSource() jmvcore::Analysis$check() jmvcore::Analysis$init() jmvcore::Analysis$optionsChangedHandler() jmvcore::Analysis$postInit() jmvcore::Analysis$print() jmvcore::Analysis$readDataset() jmvcore::Analysis$run() jmvcore::Analysis$serialize() jmvcore::Analysis$setError() jmvcore::Analysis$setStatus() jmvcore::Analysis$translate() meddecide::psychopdaROCBase$initialize()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "public-methods",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Public methods",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "psychopdaROCClass$clone()",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "method-clone-",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Method clone()",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "objects class cloneable method.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "",
        "code": "psychopdaROCClass$clone(deep = FALSE)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "deep Whether make deep clone.",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/psychopdaROCClass.html",
        "id": "ref-examples",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Examples",
        "title": "Comprehensive ROC Analysis with Advanced Features — psychopdaROCClass",
        "text": "",
        "code": "if (FALSE) { # \\dontrun{ # Load example medical data data(medical_roc_data)  # Basic ROC analysis result1 <- psychopdaROC(   data = medical_roc_data,   dependentVars = \"biomarker1\",   classVar = \"disease_status\",    positiveClass = \"Disease\" )  # Compare multiple biomarkers with DeLong test result2 <- psychopdaROC(   data = medical_roc_data,   dependentVars = c(\"biomarker1\", \"biomarker2\", \"biomarker3\"),   classVar = \"disease_status\",   positiveClass = \"Disease\",   delongTest = TRUE,   combinePlots = TRUE )  # Advanced analysis with IDI/NRI result3 <- psychopdaROC(   data = medical_roc_data,   dependentVars = c(\"biomarker1\", \"biomarker2\"),   classVar = \"disease_status\",   positiveClass = \"Disease\",    calculateIDI = TRUE,   calculateNRI = TRUE,   refVar = \"biomarker1\",   nriThresholds = \"0.3,0.7\" )  # Cost-benefit optimization result4 <- psychopdaROC(   data = medical_roc_data,   dependentVars = \"biomarker1\",   classVar = \"disease_status\",   positiveClass = \"Disease\",   method = \"oc_cost_ratio\",   costratioFP = 2.5  # False positives cost 2.5x false negatives )  # Subgroup analysis by hospital result5 <- psychopdaROC(   data = medical_roc_data,   dependentVars = \"biomarker1\",   classVar = \"disease_status\",   positiveClass = \"Disease\",   subGroup = \"hospital\" )  # Comprehensive analysis with all features result6 <- psychopdaROC(   data = medical_roc_data,   dependentVars = c(\"biomarker1\", \"biomarker2\"),   classVar = \"disease_status\",   positiveClass = \"Disease\",   method = \"maximize_metric\",   metric = \"youden\",   plotROC = TRUE,   sensSpecTable = TRUE,   showThresholdTable = TRUE,   delongTest = TRUE,   calculateIDI = TRUE,   partialAUC = TRUE,   bootstrapCI = TRUE,   precisionRecallCurve = TRUE,   compareClassifiers = TRUE )  # Financial risk assessment example data(financial_roc_data)  financial_result <- psychopdaROC(   data = financial_roc_data,   dependentVars = c(\"credit_score\", \"income_debt_ratio\", \"employment_score\"),   classVar = \"default_status\",   positiveClass = \"Default\",   direction = \"<=\",  # Lower credit scores indicate higher risk   method = \"oc_cost_ratio\",   costratioFP = 0.1,  # False positives (rejected good clients) cost less   delongTest = TRUE,   subGroup = \"client_type\" )  # Educational assessment example data(education_roc_data)  education_result <- psychopdaROC(   data = education_roc_data,   dependentVars = c(\"exam_score\", \"project_score\", \"peer_score\"),   classVar = \"pass_status\",   positiveClass = \"Pass\",   method = \"maximize_metric\",   metric = \"accuracy\",   calculateIDI = TRUE,   refVar = \"exam_score\",   subGroup = \"class_section\" )  # Manufacturing quality control example data(manufacturing_roc_data)  quality_result <- psychopdaROC(   data = manufacturing_roc_data,    dependentVars = c(\"dimension_score\", \"surface_score\", \"strength_score\"),   classVar = \"quality_status\",   positiveClass = \"Defect\",   method = \"oc_equal_sens_spec\",  # Balanced sensitivity/specificity   plotROC = TRUE,   showCriterionPlot = TRUE,   showDotPlot = TRUE,   subGroup = \"production_line\" ) } # }"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/raw_to_prob.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Convert raw test values to predicted probabilities using ROC curve — raw_to_prob",
        "title": "Convert raw test values to predicted probabilities using ROC curve — raw_to_prob",
        "text": "Maps raw test values probabilities based position ROC curve",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/raw_to_prob.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Convert raw test values to predicted probabilities using ROC curve — raw_to_prob",
        "text": "",
        "code": "raw_to_prob(values, actual, direction = \">=\")"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/raw_to_prob.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Convert raw test values to predicted probabilities using ROC curve — raw_to_prob",
        "text": "values Raw test values actual Binary outcomes (0/1) direction Direction test (\">=\" \"<=\")",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/raw_to_prob.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Convert raw test values to predicted probabilities using ROC curve — raw_to_prob",
        "text": "Vector predicted probabilities",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/safe_divide.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Safe division function — safe_divide",
        "title": "Safe division function — safe_divide",
        "text": "Performs division safe handling division zero",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/safe_divide.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Safe division function — safe_divide",
        "text": "",
        "code": "safe_divide(x, y, na_value = NA_real_)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/safe_divide.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Safe division function — safe_divide",
        "text": "x Numerator y Denominator na_value Value return division zero occurs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/safe_divide.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Safe division function — safe_divide",
        "text": "Result x/y na_value y zero",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/validateROCInputs.html",
        "id": null,
        "dir": "Reference",
        "previous_headings": "",
        "what": "Validate inputs for ROC analysis — validateROCInputs",
        "title": "Validate inputs for ROC analysis — validateROCInputs",
        "text": "Comprehensive validation ROC analysis inputs",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/validateROCInputs.html",
        "id": "ref-usage",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Usage",
        "title": "Validate inputs for ROC analysis — validateROCInputs",
        "text": "",
        "code": "validateROCInputs(x, class_var, pos_class = NULL)"
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/validateROCInputs.html",
        "id": "arguments",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Arguments",
        "title": "Validate inputs for ROC analysis — validateROCInputs",
        "text": "x Test values class_var Classification labels pos_class Positive class label",
        "code": ""
    },
    {
        "path": "https://www.serdarbalci.com/meddecide/reference/validateROCInputs.html",
        "id": "value",
        "dir": "Reference",
        "previous_headings": "",
        "what": "Value",
        "title": "Validate inputs for ROC analysis — validateROCInputs",
        "text": "List validation results cleaned data",
        "code": ""
    }
]